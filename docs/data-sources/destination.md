---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "criblio_destination Data Source - terraform-provider-criblio"
subcategory: ""
description: |-
  Destination DataSource
---

# criblio_destination (Data Source)

Destination DataSource

## Example Usage

```terraform
data "criblio_destination" "my_destination" {
  group_id = "...my_group_id..."
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `group_id` (String) The consumer group to which this instance belongs. Defaults to 'Cribl'.

### Read-Only

- `output_azure_blob` (Attributes) (see [below for nested schema](#nestedatt--output_azure_blob))
- `output_azure_data_explorer` (Attributes) (see [below for nested schema](#nestedatt--output_azure_data_explorer))
- `output_azure_eventhub` (Attributes) (see [below for nested schema](#nestedatt--output_azure_eventhub))
- `output_azure_logs` (Attributes) (see [below for nested schema](#nestedatt--output_azure_logs))
- `output_click_house` (Attributes) (see [below for nested schema](#nestedatt--output_click_house))
- `output_cloudwatch` (Attributes) (see [below for nested schema](#nestedatt--output_cloudwatch))
- `output_confluent_cloud` (Attributes) (see [below for nested schema](#nestedatt--output_confluent_cloud))
- `output_cribl_http` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_http))
- `output_cribl_lake` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_lake))
- `output_cribl_tcp` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_tcp))
- `output_crowdstrike_next_gen_siem` (Attributes) (see [below for nested schema](#nestedatt--output_crowdstrike_next_gen_siem))
- `output_datadog` (Attributes) (see [below for nested schema](#nestedatt--output_datadog))
- `output_dataset` (Attributes) (see [below for nested schema](#nestedatt--output_dataset))
- `output_default` (Attributes) (see [below for nested schema](#nestedatt--output_default))
- `output_devnull` (Attributes) (see [below for nested schema](#nestedatt--output_devnull))
- `output_disk_spool` (Attributes) (see [below for nested schema](#nestedatt--output_disk_spool))
- `output_dl_s3` (Attributes) (see [below for nested schema](#nestedatt--output_dl_s3))
- `output_dynatrace_http` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_http))
- `output_dynatrace_otlp` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_otlp))
- `output_elastic` (Attributes) (see [below for nested schema](#nestedatt--output_elastic))
- `output_elastic_cloud` (Attributes) (see [below for nested schema](#nestedatt--output_elastic_cloud))
- `output_exabeam` (Attributes) (see [below for nested schema](#nestedatt--output_exabeam))
- `output_filesystem` (Attributes) (see [below for nested schema](#nestedatt--output_filesystem))
- `output_google_chronicle` (Attributes) (see [below for nested schema](#nestedatt--output_google_chronicle))
- `output_google_cloud_logging` (Attributes) (see [below for nested schema](#nestedatt--output_google_cloud_logging))
- `output_google_cloud_storage` (Attributes) (see [below for nested schema](#nestedatt--output_google_cloud_storage))
- `output_google_pubsub` (Attributes) (see [below for nested schema](#nestedatt--output_google_pubsub))
- `output_grafana_cloud` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud))
- `output_graphite` (Attributes) (see [below for nested schema](#nestedatt--output_graphite))
- `output_honeycomb` (Attributes) (see [below for nested schema](#nestedatt--output_honeycomb))
- `output_humio_hec` (Attributes) (see [below for nested schema](#nestedatt--output_humio_hec))
- `output_influxdb` (Attributes) (see [below for nested schema](#nestedatt--output_influxdb))
- `output_kafka` (Attributes) (see [below for nested schema](#nestedatt--output_kafka))
- `output_kinesis` (Attributes) (see [below for nested schema](#nestedatt--output_kinesis))
- `output_loki` (Attributes) (see [below for nested schema](#nestedatt--output_loki))
- `output_minio` (Attributes) (see [below for nested schema](#nestedatt--output_minio))
- `output_msk` (Attributes) (see [below for nested schema](#nestedatt--output_msk))
- `output_netflow` (Attributes) (see [below for nested schema](#nestedatt--output_netflow))
- `output_newrelic` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic))
- `output_newrelic_events` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic_events))
- `output_open_telemetry` (Attributes) (see [below for nested schema](#nestedatt--output_open_telemetry))
- `output_prometheus` (Attributes) (see [below for nested schema](#nestedatt--output_prometheus))
- `output_ring` (Attributes) (see [below for nested schema](#nestedatt--output_ring))
- `output_router` (Attributes) (see [below for nested schema](#nestedatt--output_router))
- `output_s3` (Attributes) (see [below for nested schema](#nestedatt--output_s3))
- `output_security_lake` (Attributes) (see [below for nested schema](#nestedatt--output_security_lake))
- `output_sentinel` (Attributes) (see [below for nested schema](#nestedatt--output_sentinel))
- `output_service_now` (Attributes) (see [below for nested schema](#nestedatt--output_service_now))
- `output_signalfx` (Attributes) (see [below for nested schema](#nestedatt--output_signalfx))
- `output_snmp` (Attributes) (see [below for nested schema](#nestedatt--output_snmp))
- `output_sns` (Attributes) (see [below for nested schema](#nestedatt--output_sns))
- `output_splunk` (Attributes) (see [below for nested schema](#nestedatt--output_splunk))
- `output_splunk_hec` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_hec))
- `output_splunk_lb` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_lb))
- `output_sqs` (Attributes) (see [below for nested schema](#nestedatt--output_sqs))
- `output_statsd` (Attributes) (see [below for nested schema](#nestedatt--output_statsd))
- `output_statsd_ext` (Attributes) (see [below for nested schema](#nestedatt--output_statsd_ext))
- `output_sumo_logic` (Attributes) (see [below for nested schema](#nestedatt--output_sumo_logic))
- `output_syslog` (Attributes) (see [below for nested schema](#nestedatt--output_syslog))
- `output_tcpjson` (Attributes) (see [below for nested schema](#nestedatt--output_tcpjson))
- `output_wavefront` (Attributes) (see [below for nested schema](#nestedatt--output_wavefront))
- `output_webhook` (Attributes) (see [below for nested schema](#nestedatt--output_webhook))
- `output_xsiam` (Attributes) (see [below for nested schema](#nestedatt--output_xsiam))

<a id="nestedatt--output_azure_blob"></a>
### Nested Schema for `output_azure_blob`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `auth_type` (String)
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `azure_cloud` (String) The Azure cloud to use. Defaults to Azure Public Cloud.
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `certificate` (Attributes) (see [below for nested schema](#nestedatt--output_azure_blob--certificate))
- `client_id` (String) The service principal's client ID
- `client_text_secret` (String) Select or create a stored text secret
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `connection_string` (String) Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
- `container_name` (String) The Azure Blob Storage container name. Name can include only lowercase letters, numbers, and hyphens. For dynamic container names, enter a JavaScript expression within quotes or backtickss, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myContainer-${C.env["CRIBL_WORKER_ID"]}`.
- `create_container` (Boolean) Create the configured container in Azure Blob Storage if it does not already exist
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`.
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint_suffix` (String) Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_azure_blob--key_value_metadata))
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `stage_path` (String) Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
- `storage_account_name` (String) The name of your Azure storage account
- `storage_class` (String)
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tenant_id` (String) The service principal's tenant ID
- `text_secret` (String) Select or create a stored text secret
- `type` (String)
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_azure_blob--certificate"></a>
### Nested Schema for `output_azure_blob.certificate`

Read-Only:

- `certificate_name` (String) The certificate you registered as credentials for your app in the Azure portal


<a id="nestedatt--output_azure_blob--key_value_metadata"></a>
### Nested Schema for `output_azure_blob.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_azure_data_explorer"></a>
### Nested Schema for `output_azure_data_explorer`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `additional_properties` (Attributes List) Optionally, enter additional configuration properties to send to the ingestion service (see [below for nested schema](#nestedatt--output_azure_data_explorer--additional_properties))
- `certificate` (Attributes) (see [below for nested schema](#nestedatt--output_azure_data_explorer--certificate))
- `client_id` (String) client_id to pass in the OAuth request parameter
- `client_secret` (String) The client secret that you generated for your app in the Azure portal
- `cluster_url` (String) The base URI for your cluster. Typically, `https://<cluster>.<region>.kusto.windows.net`.
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `database` (String) Name of the database containing the table where data will be ingested
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extent_tags` (Attributes List) Strings or tags associated with the extent (ingested data shard) (see [below for nested schema](#nestedatt--output_azure_data_explorer--extent_tags))
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `flush_immediately` (Boolean) Bypass the data management service's aggregation mechanism
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) Format of the output data
- `id` (String) Unique ID for this output
- `ingest_if_not_exists` (Attributes List) Prevents duplicate ingestion by verifying whether an extent with the specified ingest-by tag already exists (see [below for nested schema](#nestedatt--output_azure_data_explorer--ingest_if_not_exists))
- `ingest_mode` (String)
- `ingest_url` (String) The ingestion service URI for your cluster. Typically, `https://ingest-<cluster>.<region>.kusto.windows.net`.
- `is_mapping_obj` (Boolean) Send a JSON mapping object instead of specifying an existing named data mapping
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `mapping_ref` (String) Enter the name of a data mapping associated with your target table. Or, if incoming event and target table fields match exactly, you can leave the field empty.
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `oauth_endpoint` (String) Endpoint used to acquire authentication tokens from Azure
- `oauth_type` (String) The type of OAuth 2.0 client credentials grant flow to use
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_azure_data_explorer--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `report_level` (String) Level of ingestion status reporting. Defaults to FailuresOnly.
- `report_method` (String) Target of the ingestion status reporting. Defaults to Queue.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_azure_data_explorer--response_retry_settings))
- `retain_blob_on_success` (Boolean) Prevent blob deletion after ingestion is complete
- `scope` (String) Scope to pass in the OAuth request parameter
- `stage_path` (String) Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `table` (String) Name of the table to ingest data into
- `tenant_id` (String) Directory ID (tenant identifier) in Azure Active Directory
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_azure_data_explorer--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `validate_database_settings` (Boolean) When saving or starting the Destination, validate the database name and credentials; also validate table name, except when creating a new table. Disable if your Azure app does not have both the Database Viewer and the Table Viewer role.

<a id="nestedatt--output_azure_data_explorer--additional_properties"></a>
### Nested Schema for `output_azure_data_explorer.additional_properties`

Read-Only:

- `key` (String)
- `value` (String)


<a id="nestedatt--output_azure_data_explorer--certificate"></a>
### Nested Schema for `output_azure_data_explorer.certificate`

Read-Only:

- `certificate_name` (String) The certificate you registered as credentials for your app in the Azure portal


<a id="nestedatt--output_azure_data_explorer--extent_tags"></a>
### Nested Schema for `output_azure_data_explorer.extent_tags`

Read-Only:

- `prefix` (String)
- `value` (String)


<a id="nestedatt--output_azure_data_explorer--ingest_if_not_exists"></a>
### Nested Schema for `output_azure_data_explorer.ingest_if_not_exists`

Read-Only:

- `value` (String)


<a id="nestedatt--output_azure_data_explorer--pq_controls"></a>
### Nested Schema for `output_azure_data_explorer.pq_controls`


<a id="nestedatt--output_azure_data_explorer--response_retry_settings"></a>
### Nested Schema for `output_azure_data_explorer.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_azure_data_explorer--timeout_retry_settings"></a>
### Nested Schema for `output_azure_data_explorer.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_azure_eventhub"></a>
### Nested Schema for `output_azure_eventhub`

Read-Only:

- `ack` (Number) Control the number of required acknowledgments
- `authentication_timeout` (Number) Maximum time to wait for Kafka to respond to an authentication request
- `backoff_rate` (Number) Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
- `brokers` (List of String) List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
- `connection_timeout` (Number) Maximum time to wait for a connection to complete successfully
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_event_count` (Number) Maximum number of events in a batch before forcing a flush
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
- `format` (String) Format to use to serialize events before writing to the Event Hubs Kafka brokers
- `id` (String) Unique ID for this output
- `initial_backoff` (Number) Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
- `max_back_off` (Number) The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
- `max_record_size_kb` (Number) Maximum size of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
- `max_retries` (Number) If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_azure_eventhub--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reauthentication_threshold` (Number) Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
- `request_timeout` (Number) Maximum time to wait for Kafka to respond to a request
- `sasl` (Attributes) Authentication parameters to use when connecting to brokers. Using TLS is highly recommended. (see [below for nested schema](#nestedatt--output_azure_eventhub--sasl))
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_azure_eventhub--tls))
- `topic` (String) The name of the Event Hub (Kafka Topic) to publish events. Can be overwritten using field __topicOut.
- `type` (String)

<a id="nestedatt--output_azure_eventhub--pq_controls"></a>
### Nested Schema for `output_azure_eventhub.pq_controls`


<a id="nestedatt--output_azure_eventhub--sasl"></a>
### Nested Schema for `output_azure_eventhub.sasl`

Read-Only:

- `disabled` (Boolean)
- `mechanism` (String)


<a id="nestedatt--output_azure_eventhub--tls"></a>
### Nested Schema for `output_azure_eventhub.tls`

Read-Only:

- `disabled` (Boolean)
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another trusted CA (such as the system's)



<a id="nestedatt--output_azure_logs"></a>
### Nested Schema for `output_azure_logs`

Read-Only:

- `api_url` (String) The DNS name of the Log API endpoint that sends log data to a Log Analytics workspace in Azure Monitor. Defaults to .ods.opinsights.azure.com. @{product} will add a prefix and suffix to construct a URI in this format: <https://<Workspace_ID><your_DNS_name>/api/logs?api-version=<API version>.
- `auth_type` (String) Enter workspace ID and workspace key directly, or select a stored secret
- `compress` (Boolean)
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_azure_logs--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `keypair_secret` (String) Select or create a stored secret that references your access key and secret key
- `log_type` (String) The Log Type of events sent to this LogAnalytics workspace. Defaults to `Cribl`. Use only letters, numbers, and `_` characters, and can't exceed 100 characters. Can be overwritten by event field __logType.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_azure_logs--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `resource_id` (String) Optional Resource ID of the Azure resource to associate the data with. Can be overridden by the __resourceId event field. This ID populates the _ResourceId property, allowing the data to be included in resource-centric queries. If the ID is neither specified nor overridden, resource-centric queries will omit the data.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_azure_logs--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_azure_logs--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `workspace_id` (String) Azure Log Analytics Workspace ID. See Azure Dashboard Workspace > Advanced settings.
- `workspace_key` (String) Azure Log Analytics Workspace Primary or Secondary Shared Key. See Azure Dashboard Workspace > Advanced settings.

<a id="nestedatt--output_azure_logs--extra_http_headers"></a>
### Nested Schema for `output_azure_logs.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_azure_logs--pq_controls"></a>
### Nested Schema for `output_azure_logs.pq_controls`


<a id="nestedatt--output_azure_logs--response_retry_settings"></a>
### Nested Schema for `output_azure_logs.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_azure_logs--timeout_retry_settings"></a>
### Nested Schema for `output_azure_logs.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_click_house"></a>
### Nested Schema for `output_click_house`

Read-Only:

- `async_inserts` (Boolean) Collect data into batches for later processing. Disable to write to a ClickHouse table immediately.
- `auth_header_expr` (String) JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
- `auth_type` (String)
- `column_mappings` (Attributes List) (see [below for nested schema](#nestedatt--output_click_house--column_mappings))
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `credentials_secret` (String) Select or create a secret that references your credentials
- `database` (String)
- `describe_table` (String) Retrieves the table schema from ClickHouse and populates the Column Mapping table
- `description` (String)
- `dump_format_errors_to_disk` (Boolean) Log the most recent event that fails to match the table schema
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_mapping_fields` (List of String) Fields to exclude from sending to ClickHouse
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_click_house--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) Data format to use when sending data to ClickHouse. Defaults to JSON Compact.
- `id` (String) Unique ID for this output
- `login_url` (String) URL for OAuth
- `mapping_type` (String) How event fields are mapped to ClickHouse columns.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `oauth_headers` (Attributes List) Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_click_house--oauth_headers))
- `oauth_params` (Attributes List) Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_click_house--oauth_params))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `password` (String)
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_click_house--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_click_house--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `secret` (String) Secret parameter value to pass in request body
- `secret_param_name` (String) Secret parameter name to pass in request body
- `sql_username` (String) Username for certificate authentication
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `table_name` (String) Name of the ClickHouse table where data will be inserted. Name can contain letters (A-Z, a-z), numbers (0-9), and the character "_", and must start with either a letter or the character "_".
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_click_house--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_click_house--tls))
- `token` (String) Bearer token to include in the authorization header
- `token_attribute_name` (String) Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
- `token_timeout_secs` (Number) How often the OAuth token should be refreshed.
- `type` (String)
- `url` (String) URL of the ClickHouse instance. Example: http://localhost:8123/
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `username` (String)
- `wait_for_async_inserts` (Boolean) Cribl will wait for confirmation that data has been fully inserted into the ClickHouse database before proceeding. Disabling this option can increase throughput, but Cribl won’t be able to verify data has been completely inserted.

<a id="nestedatt--output_click_house--column_mappings"></a>
### Nested Schema for `output_click_house.column_mappings`

Read-Only:

- `column_name` (String) Name of the column in ClickHouse that will store field value
- `column_type` (String) Type of the column in the ClickHouse database
- `column_value_expression` (String) JavaScript expression to compute value to be inserted into ClickHouse table


<a id="nestedatt--output_click_house--extra_http_headers"></a>
### Nested Schema for `output_click_house.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_click_house--oauth_headers"></a>
### Nested Schema for `output_click_house.oauth_headers`

Read-Only:

- `name` (String) OAuth header name
- `value` (String) OAuth header value


<a id="nestedatt--output_click_house--oauth_params"></a>
### Nested Schema for `output_click_house.oauth_params`

Read-Only:

- `name` (String) OAuth parameter name
- `value` (String) OAuth parameter value


<a id="nestedatt--output_click_house--pq_controls"></a>
### Nested Schema for `output_click_house.pq_controls`


<a id="nestedatt--output_click_house--response_retry_settings"></a>
### Nested Schema for `output_click_house.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_click_house--timeout_retry_settings"></a>
### Nested Schema for `output_click_house.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_click_house--tls"></a>
### Nested Schema for `output_click_house.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_cloudwatch"></a>
### Nested Schema for `output_cloudwatch`

Read-Only:

- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `aws_api_key` (String)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `enable_assume_role` (Boolean) Use Assume Role credentials to access CloudWatchLogs
- `endpoint` (String) CloudWatchLogs service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to CloudWatchLogs-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
- `id` (String) Unique ID for this output
- `log_group_name` (String) CloudWatch log group to associate events with
- `log_stream_name` (String) Prefix for CloudWatch log stream name. This prefix will be used to generate a unique log stream name per cribl instance, for example: myStream_myHost_myOutputId
- `max_queue_size` (Number) Maximum number of queued batches before blocking
- `max_record_size_kb` (Number) Maximum size (KB) of each individual record before compression. For non compressible data 1MB is the max recommended size
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_cloudwatch--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Region where the CloudWatchLogs is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)

<a id="nestedatt--output_cloudwatch--pq_controls"></a>
### Nested Schema for `output_cloudwatch.pq_controls`



<a id="nestedatt--output_confluent_cloud"></a>
### Nested Schema for `output_confluent_cloud`

Read-Only:

- `ack` (Number) Control the number of required acknowledgments.
- `authentication_timeout` (Number) Maximum time to wait for Kafka to respond to an authentication request
- `backoff_rate` (Number) Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
- `brokers` (List of String) List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092.
- `compression` (String) Codec to use to compress the data before sending to Kafka
- `connection_timeout` (Number) Maximum time to wait for a connection to complete successfully
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_event_count` (Number) The maximum number of events you want the Destination to allow in a batch before forcing a flush
- `flush_period_sec` (Number) The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
- `format` (String) Format to use to serialize events before writing to Kafka.
- `id` (String) Unique ID for this output
- `initial_backoff` (Number) Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
- `kafka_schema_registry` (Attributes) (see [below for nested schema](#nestedatt--output_confluent_cloud--kafka_schema_registry))
- `max_back_off` (Number) The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
- `max_record_size_kb` (Number) Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
- `max_retries` (Number) If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_confluent_cloud--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protobuf_library_id` (String) Select a set of Protobuf definitions for the events you want to send
- `reauthentication_threshold` (Number) Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
- `request_timeout` (Number) Maximum time to wait for Kafka to respond to a request
- `sasl` (Attributes) Authentication parameters to use when connecting to brokers. Using TLS is highly recommended. (see [below for nested schema](#nestedatt--output_confluent_cloud--sasl))
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_confluent_cloud--tls))
- `topic` (String) The topic to publish events to. Can be overridden using the __topicOut field.
- `type` (String)

<a id="nestedatt--output_confluent_cloud--kafka_schema_registry"></a>
### Nested Schema for `output_confluent_cloud.kafka_schema_registry`

Read-Only:

- `auth` (Attributes) Credentials to use when authenticating with the schema registry using basic HTTP authentication (see [below for nested schema](#nestedatt--output_confluent_cloud--kafka_schema_registry--auth))
- `connection_timeout` (Number) Maximum time to wait for a Schema Registry connection to complete successfully
- `default_key_schema_id` (Number) Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
- `default_value_schema_id` (Number) Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
- `disabled` (Boolean)
- `max_retries` (Number) Maximum number of times to try fetching schemas from the Schema Registry
- `request_timeout` (Number) Maximum time to wait for the Schema Registry to respond to a request
- `schema_registry_url` (String) URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_confluent_cloud--kafka_schema_registry--tls))

<a id="nestedatt--output_confluent_cloud--kafka_schema_registry--auth"></a>
### Nested Schema for `output_confluent_cloud.kafka_schema_registry.auth`

Read-Only:

- `credentials_secret` (String) Select or create a secret that references your credentials
- `disabled` (Boolean)


<a id="nestedatt--output_confluent_cloud--kafka_schema_registry--tls"></a>
### Nested Schema for `output_confluent_cloud.kafka_schema_registry.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_confluent_cloud--pq_controls"></a>
### Nested Schema for `output_confluent_cloud.pq_controls`


<a id="nestedatt--output_confluent_cloud--sasl"></a>
### Nested Schema for `output_confluent_cloud.sasl`

Read-Only:

- `disabled` (Boolean)
- `mechanism` (String)


<a id="nestedatt--output_confluent_cloud--tls"></a>
### Nested Schema for `output_confluent_cloud.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_cribl_http"></a>
### Nested Schema for `output_cribl_http`

Read-Only:

- `compression` (String) Codec to use to compress the data before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_fields` (List of String) Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_cribl_http--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs. If this setting is disabled, consider enabling round-robin DNS.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_http--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_cribl_http--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_http--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_http--tls))
- `token_ttl_minutes` (Number) The number of minutes before the internally generated authentication token expires. Valid values are between 1 and 60.
- `type` (String)
- `url` (String) URL of a Cribl Worker to send events to, such as http://localhost:10200
- `urls` (Attributes List) (see [below for nested schema](#nestedatt--output_cribl_http--urls))
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_cribl_http--extra_http_headers"></a>
### Nested Schema for `output_cribl_http.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_cribl_http--pq_controls"></a>
### Nested Schema for `output_cribl_http.pq_controls`


<a id="nestedatt--output_cribl_http--response_retry_settings"></a>
### Nested Schema for `output_cribl_http.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_cribl_http--timeout_retry_settings"></a>
### Nested Schema for `output_cribl_http.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_cribl_http--tls"></a>
### Nested Schema for `output_cribl_http.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.


<a id="nestedatt--output_cribl_http--urls"></a>
### Nested Schema for `output_cribl_http.urls`

Read-Only:

- `url` (String) URL of a Cribl Worker to send events to, such as http://localhost:10200
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability



<a id="nestedatt--output_cribl_lake"></a>
### Nested Schema for `output_cribl_lake`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `aws_authentication_method` (String)
- `aws_secret_key` (String) Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Lake dataset to send the data to.
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_assume_role` (Boolean) Use Assume Role credentials to access S3
- `endpoint` (String) S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String)
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `kms_key_id` (String) ID or ARN of the KMS customer-managed key to use for encryption
- `max_closing_files_to_backpressure` (Number) Maximum number of files that can be waiting for upload before backpressure is applied
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the S3 bucket is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `server_side_encryption` (String)
- `signature_version` (String) Signature version to use for signing S3 requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file


<a id="nestedatt--output_cribl_tcp"></a>
### Nested Schema for `output_cribl_tcp`

Read-Only:

- `compression` (String) Codec to use to compress the data before sending
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_fields` (List of String) Fields to exclude from the event. By default, all internal fields except `__output` are sent. Example: `cribl_pipe`, `c*`. Wildcards supported.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `host` (String) The hostname of the receiver
- `hosts` (Attributes List) Set of hosts to load-balance data to (see [below for nested schema](#nestedatt--output_cribl_tcp--hosts))
- `id` (String) Unique ID for this output
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Use load-balanced destinations
- `log_failed_requests` (Boolean) Use to troubleshoot issues with sending data
- `max_concurrent_senders` (Number) Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) The port to connect to on the provided host
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_tcp--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_cribl_tcp--tls))
- `token_ttl_minutes` (Number) The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_cribl_tcp--hosts"></a>
### Nested Schema for `output_cribl_tcp.hosts`

Read-Only:

- `host` (String) The hostname of the receiver
- `port` (Number) The port to connect to on the provided host
- `servername` (String) Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
- `tls` (String) Whether to inherit TLS configs from group setting or disable TLS
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability


<a id="nestedatt--output_cribl_tcp--pq_controls"></a>
### Nested Schema for `output_cribl_tcp.pq_controls`


<a id="nestedatt--output_cribl_tcp--tls"></a>
### Nested Schema for `output_cribl_tcp.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_crowdstrike_next_gen_siem"></a>
### Nested Schema for `output_crowdstrike_next_gen_siem`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_crowdstrike_next_gen_siem--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_crowdstrike_next_gen_siem--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_crowdstrike_next_gen_siem--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_crowdstrike_next_gen_siem--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String)
- `type` (String)
- `url` (String) URL provided from a CrowdStrike data connector. 
Example: https://ingest.<region>.crowdstrike.com/api/ingest/hec/<connection-id>/v1/services/collector
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_crowdstrike_next_gen_siem--extra_http_headers"></a>
### Nested Schema for `output_crowdstrike_next_gen_siem.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_crowdstrike_next_gen_siem--pq_controls"></a>
### Nested Schema for `output_crowdstrike_next_gen_siem.pq_controls`


<a id="nestedatt--output_crowdstrike_next_gen_siem--response_retry_settings"></a>
### Nested Schema for `output_crowdstrike_next_gen_siem.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_crowdstrike_next_gen_siem--timeout_retry_settings"></a>
### Nested Schema for `output_crowdstrike_next_gen_siem.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_datadog"></a>
### Nested Schema for `output_datadog`

Read-Only:

- `allow_api_key_from_events` (Boolean) Allow API key to be set from the event's '__agent_api_key' field
- `api_key` (String) Organization's API key in Datadog
- `auth_type` (String) Enter API key directly, or select a stored secret
- `batch_by_tags` (Boolean) Batch events by API key and the ddtags field on the event. When disabled, batches events only by API key. If incoming events have high cardinality in the ddtags field, disabling this setting may improve Destination performance.
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `content_type` (String) The content type to use when sending logs
- `custom_url` (String)
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_datadog--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `host` (String) Name of the host to send with logs. When you send logs as JSON objects, the event's 'host' field (if set) will override this value.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `message` (String) Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_datadog--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_datadog--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `send_counters_as_count` (Boolean) If not enabled, Datadog will transform 'counter' metrics to 'gauge'. [Learn more about Datadog metrics types.](https://docs.datadoghq.com/metrics/types/?tab=count)
- `service` (String) Name of the service to send with logs. When you send logs as JSON objects, the event's '__service' field (if set) will override this value.
- `severity` (String) Default value for message severity. When you send logs as JSON objects, the event's '__severity' field (if set) will override this value.
- `site` (String) Datadog site to which events should be sent
- `source` (String) Name of the source to send with logs. When you send logs as JSON objects, the event's 'source' field (if set) will override this value.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tags` (List of String) List of tags to send with logs, such as 'env:prod' and 'env_staging:east'
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_datadog--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_datadog--extra_http_headers"></a>
### Nested Schema for `output_datadog.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_datadog--pq_controls"></a>
### Nested Schema for `output_datadog.pq_controls`


<a id="nestedatt--output_datadog--response_retry_settings"></a>
### Nested Schema for `output_datadog.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_datadog--timeout_retry_settings"></a>
### Nested Schema for `output_datadog.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_dataset"></a>
### Nested Schema for `output_dataset`

Read-Only:

- `api_key` (String) A 'Log Write Access' API key for the DataSet account
- `auth_type` (String) Enter API key directly, or select a stored secret
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_url` (String)
- `default_severity` (String) Default value for event severity. If the `sev` or `__severity` fields are set on an event, the first one matching will override this value.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_fields` (List of String) Fields to exclude from the event if the Message field is either unspecified or refers to an object. Ignored if the Message field is a string. If empty, we send all non-internal fields.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_dataset--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `message_field` (String) Name of the event field that contains the message or attributes to send. If not specified, all of the event's non-internal fields will be sent as attributes.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_dataset--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_dataset--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `server_host_field` (String) Name of the event field that contains the `serverHost` identifier. If not specified, defaults to `cribl_<outputId>`.
- `site` (String) DataSet site to which events should be sent
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_dataset--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `timestamp_field` (String) Name of the event field that contains the timestamp. If not specified, defaults to `ts`, `_time`, or `Date.now()`, in that order.
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_dataset--extra_http_headers"></a>
### Nested Schema for `output_dataset.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_dataset--pq_controls"></a>
### Nested Schema for `output_dataset.pq_controls`


<a id="nestedatt--output_dataset--response_retry_settings"></a>
### Nested Schema for `output_dataset.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_dataset--timeout_retry_settings"></a>
### Nested Schema for `output_dataset.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_default"></a>
### Nested Schema for `output_default`

Read-Only:

- `default_id` (String) ID of the default output. This will be used whenever a nonexistent/deleted output is referenced.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)


<a id="nestedatt--output_devnull"></a>
### Nested Schema for `output_devnull`

Read-Only:

- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)


<a id="nestedatt--output_disk_spool"></a>
### Nested Schema for `output_disk_spool`

Read-Only:

- `compress` (String) Data compression format. Default is gzip.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `max_data_size` (String) Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
- `max_data_time` (String) Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized within the time-buckets. If blank, the event's __partition property is used and otherwise, events go directly into the time-bucket directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `time_window` (String) Time period for grouping spooled events. Default is 10m.
- `type` (String)


<a id="nestedatt--output_dl_s3"></a>
### Nested Schema for `output_dl_s3`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `aws_api_key` (String) This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String) Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_assume_role` (Boolean) Use Assume Role credentials to access S3
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint` (String) S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_dl_s3--key_value_metadata))
- `kms_key_id` (String) ID or ARN of the KMS customer-managed key to use for encryption
- `max_closing_files_to_backpressure` (Number) Maximum number of files that can be waiting for upload before backpressure is applied
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partitioning_fields` (List of String) List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the S3 bucket is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `server_side_encryption` (String)
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `signature_version` (String) Signature version to use for signing S3 requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_dl_s3--key_value_metadata"></a>
### Nested Schema for `output_dl_s3.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_dynatrace_http"></a>
### Nested Schema for `output_dynatrace_http`

Read-Only:

- `active_gate_domain` (String) ActiveGate domain with Log analytics collector module enabled. For example https://{activeGate-domain}:9999/e/{environment-id}/api/v2/logs/ingest.
- `auth_type` (String)
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `endpoint` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `environment_id` (String) ID of the environment to send to
- `extra_http_headers` (Attributes List) Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields). (see [below for nested schema](#nestedatt--output_dynatrace_http--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) How to format events before sending. Defaults to JSON. Plaintext is not currently supported.
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `method` (String) The method to use when sending events
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_http--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_dynatrace_http--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `telemetry_type` (String)
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_http--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) Bearer token to include in the authorization header
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) URL to send events to. Can be overwritten by an event's __url field.
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_dynatrace_http--extra_http_headers"></a>
### Nested Schema for `output_dynatrace_http.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_dynatrace_http--pq_controls"></a>
### Nested Schema for `output_dynatrace_http.pq_controls`


<a id="nestedatt--output_dynatrace_http--response_retry_settings"></a>
### Nested Schema for `output_dynatrace_http.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_dynatrace_http--timeout_retry_settings"></a>
### Nested Schema for `output_dynatrace_http.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_dynatrace_otlp"></a>
### Nested Schema for `output_dynatrace_otlp`

Read-Only:

- `auth_token_name` (String)
- `compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `endpoint` (String) The endpoint where Dynatrace events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
- `endpoint_type` (String) Select the type of Dynatrace endpoint configured
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_dynatrace_otlp--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `http_compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `http_logs_endpoint_override` (String) If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_metrics_endpoint_override` (String) If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_traces_endpoint_override` (String) If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `keep_alive_time` (Number) How often the sender should ping the peer to keep the connection open
- `max_payload_size_kb` (Number) Maximum size (in KB) of the request body. The maximum payload size is 4 MB. If this limit is exceeded, the entire OTLP message is dropped
- `metadata` (Attributes List) List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'. (see [below for nested schema](#nestedatt--output_dynatrace_otlp--metadata))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `otlp_version` (String) The version of OTLP Protobuf definitions to use when structuring data to send
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_otlp--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Select a transport option for Dynatrace
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_dynatrace_otlp--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_dynatrace_otlp--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token_secret` (String) Select or create a stored text secret
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_dynatrace_otlp--extra_http_headers"></a>
### Nested Schema for `output_dynatrace_otlp.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_dynatrace_otlp--metadata"></a>
### Nested Schema for `output_dynatrace_otlp.metadata`

Read-Only:

- `key` (String)
- `value` (String)


<a id="nestedatt--output_dynatrace_otlp--pq_controls"></a>
### Nested Schema for `output_dynatrace_otlp.pq_controls`


<a id="nestedatt--output_dynatrace_otlp--response_retry_settings"></a>
### Nested Schema for `output_dynatrace_otlp.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_dynatrace_otlp--timeout_retry_settings"></a>
### Nested Schema for `output_dynatrace_otlp.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_elastic"></a>
### Nested Schema for `output_elastic`

Read-Only:

- `auth` (Attributes) (see [below for nested schema](#nestedatt--output_elastic--auth))
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `doc_type` (String) Document type to use for events. Can be overwritten by an event's __type field.
- `elastic_pipeline` (String) Optional Elasticsearch destination pipeline
- `elastic_version` (String) Optional Elasticsearch version, used to format events. If not specified, will auto-discover version.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_elastic--extra_http_headers))
- `extra_params` (Attributes List) (see [below for nested schema](#nestedatt--output_elastic--extra_params))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `include_doc_id` (Boolean) Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
- `index` (String) Index or data stream to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_elastic--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_elastic--response_retry_settings))
- `retry_partial_errors` (Boolean) Retry failed events when a bulk request to Elastic is successful, but the response body returns an error for one or more events in the batch
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_elastic--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `url` (String) The Cloud ID or URL to an Elastic cluster to send events to. Example: http://elastic:9200/_bulk
- `urls` (Attributes List) (see [below for nested schema](#nestedatt--output_elastic--urls))
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `write_action` (String) Action to use when writing events. Must be set to `Create` when writing to a data stream.

<a id="nestedatt--output_elastic--auth"></a>
### Nested Schema for `output_elastic.auth`

Read-Only:

- `auth_type` (String) Enter credentials directly, or select a stored secret
- `disabled` (Boolean)


<a id="nestedatt--output_elastic--extra_http_headers"></a>
### Nested Schema for `output_elastic.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_elastic--extra_params"></a>
### Nested Schema for `output_elastic.extra_params`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_elastic--pq_controls"></a>
### Nested Schema for `output_elastic.pq_controls`


<a id="nestedatt--output_elastic--response_retry_settings"></a>
### Nested Schema for `output_elastic.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_elastic--timeout_retry_settings"></a>
### Nested Schema for `output_elastic.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_elastic--urls"></a>
### Nested Schema for `output_elastic.urls`

Read-Only:

- `url` (String) The URL to an Elastic node to send events to. Example: http://elastic:9200/_bulk
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability



<a id="nestedatt--output_elastic_cloud"></a>
### Nested Schema for `output_elastic_cloud`

Read-Only:

- `auth` (Attributes) (see [below for nested schema](#nestedatt--output_elastic_cloud--auth))
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `elastic_pipeline` (String) Optional Elastic Cloud Destination pipeline
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_elastic_cloud--extra_http_headers))
- `extra_params` (Attributes List) Extra parameters to use in HTTP requests (see [below for nested schema](#nestedatt--output_elastic_cloud--extra_params))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `include_doc_id` (Boolean) Include the `document_id` field when sending events to an Elastic TSDS (time series data stream)
- `index` (String) Data stream or index to send events to. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be overwritten by an event's __index field.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_elastic_cloud--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_elastic_cloud--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_elastic_cloud--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `url` (String) Enter Cloud ID of the Elastic Cloud environment to send events to

<a id="nestedatt--output_elastic_cloud--auth"></a>
### Nested Schema for `output_elastic_cloud.auth`

Read-Only:

- `auth_type` (String) Enter credentials directly, or select a stored secret
- `disabled` (Boolean)


<a id="nestedatt--output_elastic_cloud--extra_http_headers"></a>
### Nested Schema for `output_elastic_cloud.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_elastic_cloud--extra_params"></a>
### Nested Schema for `output_elastic_cloud.extra_params`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_elastic_cloud--pq_controls"></a>
### Nested Schema for `output_elastic_cloud.pq_controls`


<a id="nestedatt--output_elastic_cloud--response_retry_settings"></a>
### Nested Schema for `output_elastic_cloud.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_elastic_cloud--timeout_retry_settings"></a>
### Nested Schema for `output_elastic_cloud.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_exabeam"></a>
### Nested Schema for `output_exabeam`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `aws_api_key` (String) HMAC access key. Can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
- `aws_secret_key` (String) HMAC secret. Can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
- `bucket` (String) Name of the destination bucket. A constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a JavaScript Global Variable: `myBucket-${C.vars.myVar}`.
- `collector_instance_id` (String) ID of the Exabeam Collector where data should be sent. Example: 11112222-3333-4444-5555-666677778888
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `encoded_configuration` (String) Enter an encoded string containing Exabeam configurations
- `endpoint` (String) Google Cloud Storage service endpoint
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the bucket is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `signature_version` (String) Signature version to use for signing Google Cloud Storage requests
- `site_id` (String) Exabeam site ID. If left blank, @{product} will use the value of the Exabeam site name.
- `site_name` (String) Constant or JavaScript expression to create an Exabeam site name. Values that aren't successfully evaluated will be treated as string constants.
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timezone_offset` (String)
- `type` (String)


<a id="nestedatt--output_filesystem"></a>
### Nested Schema for `output_filesystem`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Final destination for the output files
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_filesystem--key_value_metadata))
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `stage_path` (String) Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_filesystem--key_value_metadata"></a>
### Nested Schema for `output_filesystem.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_google_chronicle"></a>
### Nested Schema for `output_google_chronicle`

Read-Only:

- `api_key` (String) Organization's API key in Google SecOps
- `api_key_secret` (String) Select or create a stored text secret
- `api_version` (String)
- `authentication_method` (String)
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_labels` (Attributes List) Custom labels to be added to every batch (see [below for nested schema](#nestedatt--output_google_chronicle--custom_labels))
- `customer_id` (String) Unique identifier (UUID) corresponding to a particular SecOps instance. Provided by your SecOps representative.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_google_chronicle--extra_http_headers))
- `extra_log_types` (Attributes List) Custom log types. If the value "Custom" is selected in the setting "Default log type" above, the first custom log type in this table will be automatically selected as default log type. (see [below for nested schema](#nestedatt--output_google_chronicle--extra_log_types))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `log_format_type` (String)
- `log_text_field` (String) Name of the event field that contains the log text to send. If not specified, Stream sends a JSON representation of the whole event.
- `log_type` (String) Default log type value to send to SecOps. Can be overwritten by event field __logType.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `namespace` (String) User-configured environment namespace to identify the data domain the logs originated from. Use namespace as a tag to identify the appropriate data domain for indexing and enrichment functionality. Can be overwritten by event field __namespace.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_google_chronicle--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Regional endpoint to send events to
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_google_chronicle--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `service_account_credentials` (String) Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
- `service_account_credentials_secret` (String) Select or create a stored text secret
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_google_chronicle--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned.

<a id="nestedatt--output_google_chronicle--custom_labels"></a>
### Nested Schema for `output_google_chronicle.custom_labels`

Read-Only:

- `key` (String)
- `value` (String)


<a id="nestedatt--output_google_chronicle--extra_http_headers"></a>
### Nested Schema for `output_google_chronicle.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_google_chronicle--extra_log_types"></a>
### Nested Schema for `output_google_chronicle.extra_log_types`

Read-Only:

- `description` (String)
- `log_type` (String)


<a id="nestedatt--output_google_chronicle--pq_controls"></a>
### Nested Schema for `output_google_chronicle.pq_controls`


<a id="nestedatt--output_google_chronicle--response_retry_settings"></a>
### Nested Schema for `output_google_chronicle.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_google_chronicle--timeout_retry_settings"></a>
### Nested Schema for `output_google_chronicle.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_google_cloud_logging"></a>
### Nested Schema for `output_google_cloud_logging`

Read-Only:

- `cache_fill_bytes_expression` (String) A JavaScript expression that evaluates to the HTTP request cache fill bytes as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `cache_hit_expression` (String) A JavaScript expression that evaluates to the HTTP request cache hit as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `cache_lookup_expression` (String) A JavaScript expression that evaluates to the HTTP request cache lookup as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `cache_validated_expression` (String) A JavaScript expression that evaluates to the HTTP request cache validated with origin server as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `concurrency` (Number) Maximum number of ongoing requests before blocking.
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_expression` (String) A JavaScript expression that evaluates to the log entry source location file as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
- `first_expression` (String) A JavaScript expression that evaluates to the log entry operation first flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
- `function_expression` (String) A JavaScript expression that evaluates to the log entry source location function as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
- `google_auth_method` (String) Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
- `id` (String) Unique ID for this output
- `id_expression` (String) A JavaScript expression that evaluates to the log entry operation ID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
- `index_expression` (String) A JavaScript expression that evaluates to the log entry log split index as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
- `insert_id_expression` (String) JavaScript expression to compute the value of the insert ID field.
- `last_expression` (String) A JavaScript expression that evaluates to the log entry operation last flag as a boolean. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
- `latency_expression` (String) A JavaScript expression that evaluates to the HTTP request latency, formatted as <seconds>.<nanoseconds>s (for example, 1.23s). See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `line_expression` (String) A JavaScript expression that evaluates to the log entry source location line as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentrysourcelocation) for details.
- `log_labels` (Attributes List) Labels to apply to the log entry (see [below for nested schema](#nestedatt--output_google_cloud_logging--log_labels))
- `log_location_expression` (String) JavaScript expression to compute the value of the folder ID with which log entries should be associated.
- `log_location_type` (String)
- `log_name_expression` (String) JavaScript expression to compute the value of the log name.
- `max_payload_events` (Number) Max number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `payload_expression` (String) JavaScript expression to compute the value of the payload. Must evaluate to a JavaScript object value. If an invalid value is encountered it will result in the default value instead. Defaults to the entire event.
- `payload_format` (String) Format to use when sending payload. Defaults to Text.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_google_cloud_logging--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `producer_expression` (String) A JavaScript expression that evaluates to the log entry operation producer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logentryoperation) for details.
- `protocol_expression` (String) A JavaScript expression that evaluates to the HTTP request protocol as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `referer_expression` (String) A JavaScript expression that evaluates to the HTTP request referer as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `remote_ip_expression` (String) A JavaScript expression that evaluates to the HTTP request remote IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `request_method_expression` (String) A JavaScript expression that evaluates to the HTTP request method as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `request_size_expression` (String) A JavaScript expression that evaluates to the HTTP request size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `request_url_expression` (String) A JavaScript expression that evaluates to the HTTP request URL as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `resource_type_expression` (String) JavaScript expression to compute the value of the managed resource type field. Must evaluate to one of the valid values [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types). Defaults to "global".
- `resource_type_labels` (Attributes List) Labels to apply to the managed resource. These must correspond to the valid labels for the specified resource type (see [here](https://cloud.google.com/logging/docs/api/v2/resource-list#resource-types)). Otherwise, they will be dropped by Google Cloud Logging. (see [below for nested schema](#nestedatt--output_google_cloud_logging--resource_type_labels))
- `response_size_expression` (String) A JavaScript expression that evaluates to the HTTP response size as a string, in int64 format. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `secret` (String) Select or create a stored text secret
- `server_ip_expression` (String) A JavaScript expression that evaluates to the HTTP request server IP as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `service_account_credentials` (String) Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
- `severity_expression` (String) JavaScript expression to compute the value of the severity field. Must evaluate to one of the severity values supported by Google Cloud Logging [here](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logseverity) (case insensitive). Defaults to "DEFAULT".
- `span_id_expression` (String) A JavaScript expression that evaluates to the ID of the cloud trace span associated with the current operation in which the log is being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
- `status_expression` (String) A JavaScript expression that evaluates to the HTTP request method as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_req_per_sec` (Number) Maximum number of requests to limit to per second.
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it.
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `total_splits_expression` (String) A JavaScript expression that evaluates to the log entry log split total splits as a number. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
- `trace_expression` (String) A JavaScript expression that evaluates to the REST resource name of the trace being written as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
- `trace_sampled_expression` (String) A JavaScript expression that evaluates to the the sampling decision of the span associated with the log entry. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry) for details.
- `type` (String)
- `uid_expression` (String) A JavaScript expression that evaluates to the log entry log split UID as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#logsplit) for details.
- `user_agent_expression` (String) A JavaScript expression that evaluates to the HTTP request user agent as a string. See the [documentation](https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#httprequest) for details.

<a id="nestedatt--output_google_cloud_logging--log_labels"></a>
### Nested Schema for `output_google_cloud_logging.log_labels`

Read-Only:

- `label` (String) Label name
- `value_expression` (String) JavaScript expression to compute the label's value.


<a id="nestedatt--output_google_cloud_logging--pq_controls"></a>
### Nested Schema for `output_google_cloud_logging.pq_controls`


<a id="nestedatt--output_google_cloud_logging--resource_type_labels"></a>
### Nested Schema for `output_google_cloud_logging.resource_type_labels`

Read-Only:

- `label` (String) Label name
- `value_expression` (String) JavaScript expression to compute the label's value.



<a id="nestedatt--output_google_cloud_storage"></a>
### Nested Schema for `output_google_cloud_storage`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `aws_api_key` (String) HMAC access key. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_ACCESS_KEY}`.
- `aws_authentication_method` (String)
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String) HMAC secret. This value can be a constant or a JavaScript expression, such as `${C.env.GCS_SECRET}`.
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example of referencing a Global Variable: `myBucket-${C.vars.myVar}`.
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint` (String) Google Cloud Storage service endpoint
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_google_cloud_storage--key_value_metadata))
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the bucket is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `signature_version` (String) Signature version to use for signing Google Cloud Storage requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_google_cloud_storage--key_value_metadata"></a>
### Nested Schema for `output_google_cloud_storage.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_google_pubsub"></a>
### Nested Schema for `output_google_pubsub`

Read-Only:

- `batch_size` (Number) The maximum number of items the Google API should batch before it sends them to the topic.
- `batch_timeout` (Number) The maximum amount of time, in milliseconds, that the Google API should wait to send a batch (if the Batch size is not reached).
- `create_topic` (Boolean) If enabled, create topic if it does not exist.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (String) Maximum time to wait before sending a batch (when batch size limit is not reached). Parsed as JSON.
- `google_auth_method` (String) Choose Auto to use Google Application Default Credentials (ADC), Manual to enter Google service account credentials directly, or Secret to select or create a stored secret that references Google service account credentials.
- `id` (String) Unique ID for this output
- `max_in_progress` (Number) The maximum number of in-progress API requests before backpressure is applied.
- `max_queue_size` (Number) Maximum number of queued batches before blocking.
- `max_record_size_kb` (Number) Maximum size (KB) of batches to send.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `ordered_delivery` (Boolean) If enabled, send events in the order they were added to the queue. For this to work correctly, the process receiving events must have ordering enabled.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_google_pubsub--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Region to publish messages to. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
- `secret` (String) Select or create a stored text secret
- `service_account_credentials` (String) Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `topic_name` (String) ID of the topic to send events to.
- `type` (String)

<a id="nestedatt--output_google_pubsub--pq_controls"></a>
### Nested Schema for `output_google_pubsub.pq_controls`



<a id="nestedatt--output_grafana_cloud"></a>
### Nested Schema for `output_grafana_cloud`

Read-Only:

- `output_grafana_cloud_grafana_cloud1` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1))
- `output_grafana_cloud_grafana_cloud2` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2))

<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1`

Read-Only:

- `compress` (Boolean) Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
- `concurrency` (Number) Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `id` (String) Unique ID for this output
- `labels` (Attributes List) List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}' (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--labels))
- `loki_auth` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--loki_auth))
- `loki_url` (String) The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `message` (String) Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
- `message_format` (String) Format to use when sending logs to Loki (Protobuf or JSON)
- `metric_rename_expr` (String) JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `prometheus_auth` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--prometheus_auth))
- `prometheus_url` (String) The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--extra_http_headers"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--labels"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.labels`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--loki_auth"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.loki_auth`

Read-Only:

- `auth_type` (String)
- `credentials_secret` (String) Select or create a secret that references your credentials
- `password` (String) Password (API key in Grafana Cloud domain) for authentication
- `text_secret` (String) Select or create a stored text secret
- `token` (String) Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
- `username` (String) Username for authentication


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--pq_controls"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.pq_controls`


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--prometheus_auth"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.prometheus_auth`

Read-Only:

- `auth_type` (String)
- `credentials_secret` (String) Select or create a secret that references your credentials
- `password` (String) Password (API key in Grafana Cloud domain) for authentication
- `text_secret` (String) Select or create a stored text secret
- `token` (String) Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
- `username` (String) Username for authentication


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--response_retry_settings"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud1--timeout_retry_settings"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud1.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2`

Read-Only:

- `compress` (Boolean) Compress the payload body before sending. Applies only to JSON payloads; the Protobuf variant for both Prometheus and Loki are snappy-compressed by default.
- `concurrency` (Number) Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki and Prometheus to complain about entries being delivered out of order.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `id` (String) Unique ID for this output
- `labels` (Attributes List) List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}' (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--labels))
- `loki_auth` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--loki_auth))
- `loki_url` (String) The endpoint to send logs to, such as https://logs-prod-us-central1.grafana.net
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki and Prometheus to complain about entries being delivered out of order.
- `message` (String) Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
- `message_format` (String) Format to use when sending logs to Loki (Protobuf or JSON)
- `metric_rename_expr` (String) JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `prometheus_auth` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--prometheus_auth))
- `prometheus_url` (String) The remote_write endpoint to send Prometheus metrics to, such as https://prometheus-blocks-prod-us-central1.grafana.net/api/prom/push
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--extra_http_headers"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--labels"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.labels`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--loki_auth"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.loki_auth`

Read-Only:

- `auth_type` (String)
- `credentials_secret` (String) Select or create a secret that references your credentials
- `password` (String) Password (API key in Grafana Cloud domain) for authentication
- `text_secret` (String) Select or create a stored text secret
- `token` (String) Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
- `username` (String) Username for authentication


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--pq_controls"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.pq_controls`


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--prometheus_auth"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.prometheus_auth`

Read-Only:

- `auth_type` (String)
- `credentials_secret` (String) Select or create a secret that references your credentials
- `password` (String) Password (API key in Grafana Cloud domain) for authentication
- `text_secret` (String) Select or create a stored text secret
- `token` (String) Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
- `username` (String) Username for authentication


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--response_retry_settings"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_grafana_cloud--output_grafana_cloud_grafana_cloud2--timeout_retry_settings"></a>
### Nested Schema for `output_grafana_cloud.output_grafana_cloud_grafana_cloud2.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)




<a id="nestedatt--output_graphite"></a>
### Nested Schema for `output_graphite`

Read-Only:

- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
- `host` (String) The hostname of the destination.
- `id` (String) Unique ID for this output
- `mtu` (Number) When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) Destination port.
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_graphite--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Protocol to use when communicating with the destination.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_graphite--pq_controls"></a>
### Nested Schema for `output_graphite.pq_controls`



<a id="nestedatt--output_honeycomb"></a>
### Nested Schema for `output_honeycomb`

Read-Only:

- `auth_type` (String) Enter API key directly, or select a stored secret
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `dataset` (String) Name of the dataset to send events to – e.g., observability
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_honeycomb--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_honeycomb--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_honeycomb--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `team` (String) Team API key where the dataset belongs
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_honeycomb--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_honeycomb--extra_http_headers"></a>
### Nested Schema for `output_honeycomb.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_honeycomb--pq_controls"></a>
### Nested Schema for `output_honeycomb.pq_controls`


<a id="nestedatt--output_honeycomb--response_retry_settings"></a>
### Nested Schema for `output_honeycomb.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_honeycomb--timeout_retry_settings"></a>
### Nested Schema for `output_honeycomb.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_humio_hec"></a>
### Nested Schema for `output_humio_hec`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_humio_hec--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) When set to JSON, the event is automatically formatted with required fields before sending. When set to Raw, only the event's `_raw` value is sent.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_humio_hec--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_humio_hec--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_humio_hec--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) CrowdStrike Falcon LogScale authentication token
- `type` (String)
- `url` (String) URL to a CrowdStrike Falcon LogScale endpoint to send events to. Examples: https://cloud.us.humio.com/api/v1/ingest/hec for JSON and https://cloud.us.humio.com/api/v1/ingest/hec/raw for raw
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_humio_hec--extra_http_headers"></a>
### Nested Schema for `output_humio_hec.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_humio_hec--pq_controls"></a>
### Nested Schema for `output_humio_hec.pq_controls`


<a id="nestedatt--output_humio_hec--response_retry_settings"></a>
### Nested Schema for `output_humio_hec.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_humio_hec--timeout_retry_settings"></a>
### Nested Schema for `output_humio_hec.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_influxdb"></a>
### Nested Schema for `output_influxdb`

Read-Only:

- `auth_header_expr` (String) JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
- `auth_type` (String) InfluxDB authentication type
- `bucket` (String) Bucket to write to.
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `credentials_secret` (String) Select or create a secret that references your credentials
- `database` (String) Database to write to.
- `description` (String)
- `dynamic_value_field_name` (Boolean) Enabling this will pull the value field from the metric name. E,g, 'db.query.user' will use 'db.query' as the measurement and 'user' as the value field.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_influxdb--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `login_url` (String) URL for OAuth
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `oauth_headers` (Attributes List) Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_influxdb--oauth_headers))
- `oauth_params` (Attributes List) Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_influxdb--oauth_params))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `org` (String) Organization ID for this bucket.
- `password` (String)
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_influxdb--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_influxdb--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `secret` (String) Secret parameter value to pass in request body
- `secret_param_name` (String) Secret parameter name to pass in request body
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_influxdb--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `timestamp_precision` (String) Sets the precision for the supplied Unix time values. Defaults to milliseconds.
- `token` (String) Bearer token to include in the authorization header
- `token_attribute_name` (String) Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
- `token_timeout_secs` (Number) How often the OAuth token should be refreshed.
- `type` (String)
- `url` (String) URL of an InfluxDB cluster to send events to, e.g., http://localhost:8086/write
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `use_v2_api` (Boolean) The v2 API can be enabled with InfluxDB versions 1.8 and later.
- `username` (String)
- `value_field_name` (String) Name of the field in which to store the metric when sending to InfluxDB. If dynamic generation is enabled and fails, this will be used as a fallback.

<a id="nestedatt--output_influxdb--extra_http_headers"></a>
### Nested Schema for `output_influxdb.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_influxdb--oauth_headers"></a>
### Nested Schema for `output_influxdb.oauth_headers`

Read-Only:

- `name` (String) OAuth header name
- `value` (String) OAuth header value


<a id="nestedatt--output_influxdb--oauth_params"></a>
### Nested Schema for `output_influxdb.oauth_params`

Read-Only:

- `name` (String) OAuth parameter name
- `value` (String) OAuth parameter value


<a id="nestedatt--output_influxdb--pq_controls"></a>
### Nested Schema for `output_influxdb.pq_controls`


<a id="nestedatt--output_influxdb--response_retry_settings"></a>
### Nested Schema for `output_influxdb.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_influxdb--timeout_retry_settings"></a>
### Nested Schema for `output_influxdb.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_kafka"></a>
### Nested Schema for `output_kafka`

Read-Only:

- `ack` (Number) Control the number of required acknowledgments.
- `authentication_timeout` (Number) Maximum time to wait for Kafka to respond to an authentication request
- `backoff_rate` (Number) Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
- `brokers` (List of String) Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
- `compression` (String) Codec to use to compress the data before sending to Kafka
- `connection_timeout` (Number) Maximum time to wait for a connection to complete successfully
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_event_count` (Number) The maximum number of events you want the Destination to allow in a batch before forcing a flush
- `flush_period_sec` (Number) The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
- `format` (String) Format to use to serialize events before writing to Kafka.
- `id` (String) Unique ID for this output
- `initial_backoff` (Number) Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
- `kafka_schema_registry` (Attributes) (see [below for nested schema](#nestedatt--output_kafka--kafka_schema_registry))
- `max_back_off` (Number) The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
- `max_record_size_kb` (Number) Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
- `max_retries` (Number) If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_kafka--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protobuf_library_id` (String) Select a set of Protobuf definitions for the events you want to send
- `reauthentication_threshold` (Number) Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
- `request_timeout` (Number) Maximum time to wait for Kafka to respond to a request
- `sasl` (Attributes) Authentication parameters to use when connecting to brokers. Using TLS is highly recommended. (see [below for nested schema](#nestedatt--output_kafka--sasl))
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_kafka--tls))
- `topic` (String) The topic to publish events to. Can be overridden using the __topicOut field.
- `type` (String)

<a id="nestedatt--output_kafka--kafka_schema_registry"></a>
### Nested Schema for `output_kafka.kafka_schema_registry`

Read-Only:

- `auth` (Attributes) Credentials to use when authenticating with the schema registry using basic HTTP authentication (see [below for nested schema](#nestedatt--output_kafka--kafka_schema_registry--auth))
- `connection_timeout` (Number) Maximum time to wait for a Schema Registry connection to complete successfully
- `default_key_schema_id` (Number) Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
- `default_value_schema_id` (Number) Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
- `disabled` (Boolean)
- `max_retries` (Number) Maximum number of times to try fetching schemas from the Schema Registry
- `request_timeout` (Number) Maximum time to wait for the Schema Registry to respond to a request
- `schema_registry_url` (String) URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_kafka--kafka_schema_registry--tls))

<a id="nestedatt--output_kafka--kafka_schema_registry--auth"></a>
### Nested Schema for `output_kafka.kafka_schema_registry.auth`

Read-Only:

- `credentials_secret` (String) Select or create a secret that references your credentials
- `disabled` (Boolean)


<a id="nestedatt--output_kafka--kafka_schema_registry--tls"></a>
### Nested Schema for `output_kafka.kafka_schema_registry.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_kafka--pq_controls"></a>
### Nested Schema for `output_kafka.pq_controls`


<a id="nestedatt--output_kafka--sasl"></a>
### Nested Schema for `output_kafka.sasl`

Read-Only:

- `disabled` (Boolean)
- `mechanism` (String)


<a id="nestedatt--output_kafka--tls"></a>
### Nested Schema for `output_kafka.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_kinesis"></a>
### Nested Schema for `output_kinesis`

Read-Only:

- `as_ndjson` (Boolean) Batch events into a single record as NDJSON
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `aws_api_key` (String)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `compression` (String) Compression type to use for records
- `concurrency` (Number) Maximum number of ongoing put requests before blocking.
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `enable_assume_role` (Boolean) Use Assume Role credentials to access Kinesis stream
- `endpoint` (String) Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
- `id` (String) Unique ID for this output
- `max_record_size_kb` (Number) Maximum size (KB) of each individual record before compression. For uncompressed or non-compressible data 1MB is the max recommended size
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_kinesis--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Region where the Kinesis stream is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `signature_version` (String) Signature version to use for signing Kinesis stream requests
- `stream_name` (String) Kinesis stream name to send events to.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `use_list_shards` (Boolean) Provides higher stream rate limits, improving delivery speed and reliability by minimizing throttling. See the [ListShards API](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html) documentation for details.

<a id="nestedatt--output_kinesis--pq_controls"></a>
### Nested Schema for `output_kinesis.pq_controls`



<a id="nestedatt--output_loki"></a>
### Nested Schema for `output_loki`

Read-Only:

- `auth_type` (String)
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking. Warning: Setting this value > 1 can cause Loki to complain about entries being delivered out of order.
- `credentials_secret` (String) Select or create a secret that references your credentials
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_loki--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Maximum time between requests. Small values can reduce the payload size below the configured 'Max record size' and 'Max events per request'. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
- `id` (String) Unique ID for this output
- `labels` (Attributes List) List of labels to send with logs. Labels define Loki streams, so use static labels to avoid proliferating label value combinations and streams. Can be merged and/or overridden by the event's __labels field. Example: '__labels: {host: "cribl.io", level: "error"}' (see [below for nested schema](#nestedatt--output_loki--labels))
- `max_payload_events` (Number) Maximum number of events to include in the request body. Defaults to 0 (unlimited). Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body. Warning: Setting this too low can increase the number of ongoing requests (depending on the value of 'Request concurrency'); this can cause Loki to complain about entries being delivered out of order.
- `message` (String) Name of the event field that contains the message to send. If not specified, Stream sends a JSON representation of the whole event.
- `message_format` (String) Format to use when sending logs to Loki (Protobuf or JSON)
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `password` (String) Password (API key in Grafana Cloud domain) for authentication
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_loki--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_loki--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as labels to generated logs.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_loki--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) Bearer token to include in the authorization header. In Grafana Cloud, this is generally built by concatenating the username and the API key, separated by a colon. Example: <your-username>:<your-api-key>
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) The endpoint to send logs to
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `username` (String) Username for authentication

<a id="nestedatt--output_loki--extra_http_headers"></a>
### Nested Schema for `output_loki.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_loki--labels"></a>
### Nested Schema for `output_loki.labels`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_loki--pq_controls"></a>
### Nested Schema for `output_loki.pq_controls`


<a id="nestedatt--output_loki--response_retry_settings"></a>
### Nested Schema for `output_loki.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_loki--timeout_retry_settings"></a>
### Nested Schema for `output_loki.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_minio"></a>
### Nested Schema for `output_minio`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `aws_api_key` (String) This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String) Secret key. This value can be a constant or a JavaScript expression, such as `${C.env.SOME_SECRET}`).
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination MinIO bucket. This value can be a constant or a JavaScript expression that can only be evaluated at init time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Root directory to prepend to path before uploading. Enter a constant, or a JavaScript expression enclosed in quotes or backticks.
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint` (String) MinIO service url (e.g. http://minioHost:9000)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_minio--key_value_metadata))
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the MinIO service/cluster is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates)
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `server_side_encryption` (String) Server-side encryption for uploaded objects
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `signature_version` (String) Signature version to use for signing MinIO requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_minio--key_value_metadata"></a>
### Nested Schema for `output_minio.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_msk"></a>
### Nested Schema for `output_msk`

Read-Only:

- `ack` (Number) Control the number of required acknowledgments.
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `authentication_timeout` (Number) Maximum time to wait for Kafka to respond to an authentication request
- `aws_api_key` (String)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `backoff_rate` (Number) Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
- `brokers` (List of String) Enter each Kafka bootstrap server you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
- `compression` (String) Codec to use to compress the data before sending to Kafka
- `connection_timeout` (Number) Maximum time to wait for a connection to complete successfully
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `enable_assume_role` (Boolean) Use Assume Role credentials to access MSK
- `endpoint` (String) MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_event_count` (Number) The maximum number of events you want the Destination to allow in a batch before forcing a flush
- `flush_period_sec` (Number) The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
- `format` (String) Format to use to serialize events before writing to Kafka.
- `id` (String) Unique ID for this output
- `initial_backoff` (Number) Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
- `kafka_schema_registry` (Attributes) (see [below for nested schema](#nestedatt--output_msk--kafka_schema_registry))
- `max_back_off` (Number) The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
- `max_record_size_kb` (Number) Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
- `max_retries` (Number) If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_msk--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protobuf_library_id` (String) Select a set of Protobuf definitions for the events you want to send
- `reauthentication_threshold` (Number) Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backward from the moment when credentials are set to expire.
- `region` (String) Region where the MSK cluster is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `request_timeout` (Number) Maximum time to wait for Kafka to respond to a request
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `signature_version` (String) Signature version to use for signing MSK cluster requests
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_msk--tls))
- `topic` (String) The topic to publish events to. Can be overridden using the __topicOut field.
- `type` (String)

<a id="nestedatt--output_msk--kafka_schema_registry"></a>
### Nested Schema for `output_msk.kafka_schema_registry`

Read-Only:

- `auth` (Attributes) Credentials to use when authenticating with the schema registry using basic HTTP authentication (see [below for nested schema](#nestedatt--output_msk--kafka_schema_registry--auth))
- `connection_timeout` (Number) Maximum time to wait for a Schema Registry connection to complete successfully
- `default_key_schema_id` (Number) Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
- `default_value_schema_id` (Number) Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
- `disabled` (Boolean)
- `max_retries` (Number) Maximum number of times to try fetching schemas from the Schema Registry
- `request_timeout` (Number) Maximum time to wait for the Schema Registry to respond to a request
- `schema_registry_url` (String) URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_msk--kafka_schema_registry--tls))

<a id="nestedatt--output_msk--kafka_schema_registry--auth"></a>
### Nested Schema for `output_msk.kafka_schema_registry.auth`

Read-Only:

- `credentials_secret` (String) Select or create a secret that references your credentials
- `disabled` (Boolean)


<a id="nestedatt--output_msk--kafka_schema_registry--tls"></a>
### Nested Schema for `output_msk.kafka_schema_registry.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_msk--pq_controls"></a>
### Nested Schema for `output_msk.pq_controls`


<a id="nestedatt--output_msk--tls"></a>
### Nested Schema for `output_msk.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_netflow"></a>
### Nested Schema for `output_netflow`

Read-Only:

- `description` (String)
- `dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every datagram sent will incur a DNS lookup.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `hosts` (Attributes List) One or more NetFlow destinations to forward events to (see [below for nested schema](#nestedatt--output_netflow--hosts))
- `id` (String) Unique ID for this output
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)

<a id="nestedatt--output_netflow--hosts"></a>
### Nested Schema for `output_netflow.hosts`

Read-Only:

- `host` (String) Destination host
- `port` (Number) Destination port, default is 2055



<a id="nestedatt--output_newrelic"></a>
### Nested Schema for `output_newrelic`

Read-Only:

- `api_key` (String) New Relic API key. Can be overridden using __newRelic_apiKey field.
- `auth_type` (String) Enter API key directly, or select a stored secret
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_url` (String)
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_newrelic--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `log_type` (String) Name of the logtype to send with events, e.g.: observability, access_log. The event's 'sourcetype' field (if set) will override this value.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `message_field` (String) Name of field to send as log message value. If not present, event will be serialized and sent as JSON.
- `metadata` (Attributes List) Fields to add to events from this input (see [below for nested schema](#nestedatt--output_newrelic--metadata))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Which New Relic region endpoint to use.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_newrelic--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_newrelic--extra_http_headers"></a>
### Nested Schema for `output_newrelic.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_newrelic--metadata"></a>
### Nested Schema for `output_newrelic.metadata`

Read-Only:

- `name` (String)
- `value` (String) JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)


<a id="nestedatt--output_newrelic--pq_controls"></a>
### Nested Schema for `output_newrelic.pq_controls`


<a id="nestedatt--output_newrelic--response_retry_settings"></a>
### Nested Schema for `output_newrelic.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_newrelic--timeout_retry_settings"></a>
### Nested Schema for `output_newrelic.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_newrelic_events"></a>
### Nested Schema for `output_newrelic_events`

Read-Only:

- `account_id` (String) New Relic account ID
- `api_key` (String) New Relic API key. Can be overridden using __newRelic_apiKey field.
- `auth_type` (String) Enter API key directly, or select a stored secret
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_url` (String)
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `event_type` (String) Default eventType to use when not present in an event. For more information, see [here](https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/#reserved-words).
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_newrelic_events--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic_events--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Which New Relic region endpoint to use.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_newrelic_events--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_newrelic_events--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_newrelic_events--extra_http_headers"></a>
### Nested Schema for `output_newrelic_events.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_newrelic_events--pq_controls"></a>
### Nested Schema for `output_newrelic_events.pq_controls`


<a id="nestedatt--output_newrelic_events--response_retry_settings"></a>
### Nested Schema for `output_newrelic_events.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_newrelic_events--timeout_retry_settings"></a>
### Nested Schema for `output_newrelic_events.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_open_telemetry"></a>
### Nested Schema for `output_open_telemetry`

Read-Only:

- `auth_header_expr` (String) JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
- `auth_type` (String) OpenTelemetry authentication type
- `compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `credentials_secret` (String) Select or create a secret that references your credentials
- `description` (String)
- `endpoint` (String) The endpoint where OTel events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets). Unspecified ports will default to 4317, unless the endpoint is an HTTPS-based URL or TLS is enabled, in which case 443 will be used.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_open_telemetry--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `http_compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `http_logs_endpoint_override` (String) If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_metrics_endpoint_override` (String) If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_traces_endpoint_override` (String) If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `keep_alive_time` (Number) How often the sender should ping the peer to keep the connection open
- `login_url` (String) URL for OAuth
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `metadata` (Attributes List) List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'. (see [below for nested schema](#nestedatt--output_open_telemetry--metadata))
- `oauth_headers` (Attributes List) Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_open_telemetry--oauth_headers))
- `oauth_params` (Attributes List) Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_open_telemetry--oauth_params))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `otlp_version` (String) The version of OTLP Protobuf definitions to use when structuring data to send
- `password` (String)
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_open_telemetry--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Select a transport option for OpenTelemetry
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_open_telemetry--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `secret` (String) Secret parameter value to pass in request body
- `secret_param_name` (String) Secret parameter name to pass in request body
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_open_telemetry--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_open_telemetry--tls))
- `token` (String) Bearer token to include in the authorization header
- `token_attribute_name` (String) Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
- `token_timeout_secs` (Number) How often the OAuth token should be refreshed.
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `username` (String)

<a id="nestedatt--output_open_telemetry--extra_http_headers"></a>
### Nested Schema for `output_open_telemetry.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_open_telemetry--metadata"></a>
### Nested Schema for `output_open_telemetry.metadata`

Read-Only:

- `key` (String)
- `value` (String)


<a id="nestedatt--output_open_telemetry--oauth_headers"></a>
### Nested Schema for `output_open_telemetry.oauth_headers`

Read-Only:

- `name` (String) OAuth header name
- `value` (String) OAuth header value


<a id="nestedatt--output_open_telemetry--oauth_params"></a>
### Nested Schema for `output_open_telemetry.oauth_params`

Read-Only:

- `name` (String) OAuth parameter name
- `value` (String) OAuth parameter value


<a id="nestedatt--output_open_telemetry--pq_controls"></a>
### Nested Schema for `output_open_telemetry.pq_controls`


<a id="nestedatt--output_open_telemetry--response_retry_settings"></a>
### Nested Schema for `output_open_telemetry.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_open_telemetry--timeout_retry_settings"></a>
### Nested Schema for `output_open_telemetry.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_open_telemetry--tls"></a>
### Nested Schema for `output_open_telemetry.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.



<a id="nestedatt--output_prometheus"></a>
### Nested Schema for `output_prometheus`

Read-Only:

- `auth_header_expr` (String) JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
- `auth_type` (String) Remote Write authentication type
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `credentials_secret` (String) Select or create a secret that references your credentials
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_prometheus--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `login_url` (String) URL for OAuth
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `metric_rename_expr` (String) JavaScript expression that can be used to rename metrics. For example, name.replace(/\./g, '_') will replace all '.' characters in a metric's name with the supported '_' character. Use the 'name' global variable to access the metric's name. You can access event fields' values via __e.<fieldName>.
- `metrics_flush_period_sec` (Number) How frequently metrics metadata is sent out. Value cannot be smaller than the base Flush period set above.
- `oauth_headers` (Attributes List) Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_prometheus--oauth_headers))
- `oauth_params` (Attributes List) Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_prometheus--oauth_params))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `password` (String)
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_prometheus--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_prometheus--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `secret` (String) Secret parameter value to pass in request body
- `secret_param_name` (String) Secret parameter name to pass in request body
- `send_metadata` (Boolean) Generate and send metadata (`type` and `metricFamilyName`) requests
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions to generated metrics.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_prometheus--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) Bearer token to include in the authorization header
- `token_attribute_name` (String) Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
- `token_timeout_secs` (Number) How often the OAuth token should be refreshed.
- `type` (String)
- `url` (String) The endpoint to send metrics to
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `username` (String)

<a id="nestedatt--output_prometheus--extra_http_headers"></a>
### Nested Schema for `output_prometheus.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_prometheus--oauth_headers"></a>
### Nested Schema for `output_prometheus.oauth_headers`

Read-Only:

- `name` (String) OAuth header name
- `value` (String) OAuth header value


<a id="nestedatt--output_prometheus--oauth_params"></a>
### Nested Schema for `output_prometheus.oauth_params`

Read-Only:

- `name` (String) OAuth parameter name
- `value` (String) OAuth parameter value


<a id="nestedatt--output_prometheus--pq_controls"></a>
### Nested Schema for `output_prometheus.pq_controls`


<a id="nestedatt--output_prometheus--response_retry_settings"></a>
### Nested Schema for `output_prometheus.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_prometheus--timeout_retry_settings"></a>
### Nested Schema for `output_prometheus.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_ring"></a>
### Nested Schema for `output_ring`

Read-Only:

- `compress` (String)
- `description` (String)
- `dest_path` (String) Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `format` (String) Format of the output data.
- `id` (String) Unique ID for this output
- `max_data_size` (String) Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
- `max_data_time` (String) Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `partition_expr` (String) JS expression to define how files are partitioned and organized. If left blank, Cribl Stream will fallback on event.__partition.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)


<a id="nestedatt--output_router"></a>
### Nested Schema for `output_router`

Read-Only:

- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `pipeline` (String) Pipeline to process data before sending out to this output
- `rules` (Attributes List) Event routing rules (see [below for nested schema](#nestedatt--output_router--rules))
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)

<a id="nestedatt--output_router--rules"></a>
### Nested Schema for `output_router.rules`

Read-Only:

- `description` (String) Description of this rule's purpose
- `filter` (String) JavaScript expression to select events to send to output
- `final` (Boolean) Flag to control whether to stop the event from being checked against other rules
- `output` (String) Output to send matching events to



<a id="nestedatt--output_s3"></a>
### Nested Schema for `output_s3`

Read-Only:

- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `aws_api_key` (String) This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String) Secret key. This value can be a constant or a JavaScript expression. Example: `${C.env.SOME_SECRET}`)
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
- `compress` (String) Data compression format to apply to HTTP content before it is delivered
- `compression_level` (String) Compression level to apply before moving files to final destination
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `dest_path` (String) Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_assume_role` (Boolean) Use Assume Role credentials to access S3
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint` (String) S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `file_name_suffix` (String) JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
- `format` (String) Format of the output data
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_s3--key_value_metadata))
- `kms_key_id` (String) ID or ARN of the KMS customer-managed key to use for encryption
- `max_closing_files_to_backpressure` (Number) Maximum number of files that can be waiting for upload before backpressure is applied
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `partition_expr` (String) JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the S3 bucket is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `server_side_encryption` (String)
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `signature_version` (String) Signature version to use for signing S3 requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_s3--key_value_metadata"></a>
### Nested Schema for `output_s3.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_security_lake"></a>
### Nested Schema for `output_security_lake`

Read-Only:

- `account_id` (String) ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
- `add_id_to_stage_path` (Boolean) Add the Output ID value to staging location
- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `automatic_schema` (Boolean) Automatically calculate the schema based on the events of each Parquet file generated
- `aws_api_key` (String) This value can be a constant or a JavaScript expression (`${C.env.SOME_ACCESS_KEY}`)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `base_file_name` (String) JavaScript expression to define the output filename prefix (can be constant)
- `bucket` (String) Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myBucket-${C.vars.myVar}`
- `custom_source` (String) Name of the custom source configured in Amazon Security Lake
- `deadletter_enabled` (Boolean) If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
- `deadletter_path` (String) Storage location for files that fail to reach their final destination after maximum retries are exceeded
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `empty_dir_cleanup_sec` (Number) How frequently, in seconds, to clean up empty directories
- `enable_assume_role` (Boolean) Use Assume Role credentials to access S3
- `enable_page_checksum` (Boolean) Parquet tools can use the checksum of a Parquet page to verify data integrity
- `enable_statistics` (Boolean) Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
- `enable_write_page_index` (Boolean) One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
- `endpoint` (String) Amazon Security Lake service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `header_line` (String) If set, this line will be written to the beginning of each output file
- `id` (String) Unique ID for this output
- `key_value_metadata` (Attributes List) The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001" (see [below for nested schema](#nestedatt--output_security_lake--key_value_metadata))
- `kms_key_id` (String) ID or ARN of the KMS customer-managed key to use for encryption
- `max_closing_files_to_backpressure` (Number) Maximum number of files that can be waiting for upload before backpressure is applied
- `max_concurrent_file_parts` (Number) Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
- `max_file_idle_time_sec` (Number) Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
- `max_file_open_time_sec` (Number) Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
- `max_file_size_mb` (Number) Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
- `max_open_files` (Number) Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
- `max_retry_num` (Number) The maximum number of times a file will attempt to move to its final destination before being dead-lettered
- `object_acl` (String) Object ACL to assign to uploaded objects
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `on_disk_full_backpressure` (String) How to handle events when disk space is below the global 'Min free disk space' limit
- `parquet_data_page_version` (String) Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
- `parquet_page_size` (String) Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
- `parquet_row_group_length` (Number) The number of rows that every group will contain. The final group can contain a smaller number of rows.
- `parquet_schema` (String) To add a new schema, navigate to Processing > Knowledge > Parquet Schemas
- `parquet_version` (String) Determines which data types are supported and how they are represented
- `pipeline` (String) Pipeline to process data before sending out to this output
- `region` (String) Region where the Amazon Security Lake is located.
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `remove_empty_dirs` (Boolean) Remove empty staging directories after moving files
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `server_side_encryption` (String)
- `should_log_invalid_rows` (Boolean) Log up to 3 rows that @{product} skips due to data mismatch
- `signature_version` (String) Signature version to use for signing Amazon Security Lake requests
- `stage_path` (String) Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant and stable storage.
- `storage_class` (String) Storage class to select for uploaded objects
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards. These fields are added as dimensions and labels to generated metrics and logs, respectively.
- `type` (String)
- `verify_permissions` (Boolean) Disable if you can access files within the bucket but not the bucket itself
- `write_high_water_mark` (Number) Buffer size used to write to a file

<a id="nestedatt--output_security_lake--key_value_metadata"></a>
### Nested Schema for `output_security_lake.key_value_metadata`

Read-Only:

- `key` (String)
- `value` (String)



<a id="nestedatt--output_sentinel"></a>
### Nested Schema for `output_sentinel`

Read-Only:

- `advanced_content_type` (String) HTTP content-type header value
- `auth_type` (String)
- `client_id` (String) JavaScript expression to compute the Client ID for the Azure application. Can be a constant.
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_content_type` (String) Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
- `custom_drop_when_null` (Boolean) Whether to drop events when the source expression evaluates to null
- `custom_event_delimiter` (String) Delimiter string to insert between individual events. Defaults to newline character.
- `custom_payload_expression` (String) Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
- `custom_source_expression` (String) Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
- `dce_endpoint` (String) Data collection endpoint (DCE) URL. In the format: `https://<Endpoint-Name>-<Identifier>.<Region>.ingest.monitor.azure.com`
- `dcr_id` (String) Immutable ID for the Data Collection Rule (DCR)
- `description` (String)
- `endpoint_url_configuration` (String) Enter the data collection endpoint URL or the individual ID
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields). (see [below for nested schema](#nestedatt--output_sentinel--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String)
- `format_event_code` (String) Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
- `format_payload_code` (String) Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `login_url` (String) URL for OAuth
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size (KB) of the request body (defaults to the API's maximum limit of 1000 KB)
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_sentinel--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_sentinel--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `scope` (String) Scope to pass in the OAuth request
- `secret` (String) Secret parameter value to pass in request body
- `stream_name` (String) The name of the stream (Sentinel table) in which to store the events
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_sentinel--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) URL to send events to. Can be overwritten by an event's __url field.
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_sentinel--extra_http_headers"></a>
### Nested Schema for `output_sentinel.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_sentinel--pq_controls"></a>
### Nested Schema for `output_sentinel.pq_controls`


<a id="nestedatt--output_sentinel--response_retry_settings"></a>
### Nested Schema for `output_sentinel.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_sentinel--timeout_retry_settings"></a>
### Nested Schema for `output_sentinel.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_service_now"></a>
### Nested Schema for `output_service_now`

Read-Only:

- `auth_token_name` (String)
- `compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `endpoint` (String) The endpoint where ServiceNow events will be sent. Enter any valid URL or an IP address (IPv4 or IPv6; enclose IPv6 addresses in square brackets)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_service_now--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `http_compress` (String) Type of compression to apply to messages sent to the OpenTelemetry endpoint
- `http_logs_endpoint_override` (String) If you want to send logs to the default `{endpoint}/v1/logs` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_metrics_endpoint_override` (String) If you want to send metrics to the default `{endpoint}/v1/metrics` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `http_traces_endpoint_override` (String) If you want to send traces to the default `{endpoint}/v1/traces` endpoint, leave this field empty; otherwise, specify the desired endpoint
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `keep_alive_time` (Number) How often the sender should ping the peer to keep the connection open
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `metadata` (Attributes List) List of key-value pairs to send with each gRPC request. Value supports JavaScript expressions that are evaluated just once, when the destination gets started. To pass credentials as metadata, use 'C.Secret'. (see [below for nested schema](#nestedatt--output_service_now--metadata))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `otlp_version` (String) The version of OTLP Protobuf definitions to use when structuring data to send
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_service_now--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Select a transport option for OpenTelemetry
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_service_now--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_service_now--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_service_now--tls))
- `token_secret` (String) Select or create a stored text secret
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_service_now--extra_http_headers"></a>
### Nested Schema for `output_service_now.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_service_now--metadata"></a>
### Nested Schema for `output_service_now.metadata`

Read-Only:

- `key` (String)
- `value` (String)


<a id="nestedatt--output_service_now--pq_controls"></a>
### Nested Schema for `output_service_now.pq_controls`


<a id="nestedatt--output_service_now--response_retry_settings"></a>
### Nested Schema for `output_service_now.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_service_now--timeout_retry_settings"></a>
### Nested Schema for `output_service_now.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_service_now--tls"></a>
### Nested Schema for `output_service_now.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.



<a id="nestedatt--output_signalfx"></a>
### Nested Schema for `output_signalfx`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_signalfx--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_signalfx--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `realm` (String) SignalFx realm name, e.g. "us0". For a complete list of available SignalFx realm names, please check [here](https://docs.splunk.com/observability/en/get-started/service-description.html#sd-regions).
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_signalfx--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_signalfx--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) SignalFx API access token (see [here](https://docs.signalfx.com/en/latest/admin-guide/tokens.html#working-with-access-tokens))
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_signalfx--extra_http_headers"></a>
### Nested Schema for `output_signalfx.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_signalfx--pq_controls"></a>
### Nested Schema for `output_signalfx.pq_controls`


<a id="nestedatt--output_signalfx--response_retry_settings"></a>
### Nested Schema for `output_signalfx.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_signalfx--timeout_retry_settings"></a>
### Nested Schema for `output_signalfx.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_snmp"></a>
### Nested Schema for `output_snmp`

Read-Only:

- `description` (String)
- `dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if all destinations are IP addresses. A value of 0 means every trap sent will incur a DNS lookup.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `hosts` (Attributes List) One or more SNMP destinations to forward traps to (see [below for nested schema](#nestedatt--output_snmp--hosts))
- `id` (String) Unique ID for this output
- `pipeline` (String) Pipeline to process data before sending out to this output
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)

<a id="nestedatt--output_snmp--hosts"></a>
### Nested Schema for `output_snmp.hosts`

Read-Only:

- `host` (String) Destination host
- `port` (Number) Destination port, default is 162



<a id="nestedatt--output_sns"></a>
### Nested Schema for `output_sns`

Read-Only:

- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `aws_api_key` (String)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `enable_assume_role` (Boolean) Use Assume Role credentials to access SNS
- `endpoint` (String) SNS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SNS-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `id` (String) Unique ID for this output
- `max_retries` (Number) Maximum number of retries before the output returns an error. Note that not all errors are retryable. The retries use an exponential backoff policy.
- `message_group_id` (String) Messages in the same group are processed in a FIFO manner. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_sns--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `region` (String) Region where the SNS is located
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `signature_version` (String) Signature version to use for signing SNS requests
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `topic_arn` (String) The ARN of the SNS topic to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. E.g., 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`
- `type` (String)

<a id="nestedatt--output_sns--pq_controls"></a>
### Nested Schema for `output_sns.pq_controls`



<a id="nestedatt--output_splunk"></a>
### Nested Schema for `output_splunk`

Read-Only:

- `auth_token` (String) Shared secret token to use when establishing a connection to a Splunk indexer.
- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (String) Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `enable_ack` (Boolean) Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
- `enable_multi_metrics` (Boolean) Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `host` (String) The hostname of the receiver
- `id` (String) Unique ID for this output
- `log_failed_requests` (Boolean) Use to troubleshoot issues with sending data
- `max_failed_health_checks` (Number) Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
- `max_s2_sversion` (String) The highest S2S protocol version to advertise during handshake
- `nested_fields` (String) How to serialize nested fields into index-time fields
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) The port to connect to on the provided host
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_splunk--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_splunk--tls))
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_splunk--pq_controls"></a>
### Nested Schema for `output_splunk.pq_controls`


<a id="nestedatt--output_splunk--tls"></a>
### Nested Schema for `output_splunk.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_splunk_hec"></a>
### Nested Schema for `output_splunk_hec`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `enable_multi_metrics` (Boolean) Output metrics in multiple-metric format, supported in Splunk 8.0 and above to allow multiple metrics in a single event.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_splunk_hec--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `next_queue` (String) In the Splunk app, define which Splunk processing queue to send the events after HEC processing.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_hec--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_splunk_hec--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `tcp_routing` (String) In the Splunk app, set the value of _TCP_ROUTING for events that do not have _ctrl._TCP_ROUTING set.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_hec--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) Splunk HEC authentication token
- `type` (String)
- `url` (String) URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
- `urls` (Attributes List) (see [below for nested schema](#nestedatt--output_splunk_hec--urls))
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_splunk_hec--extra_http_headers"></a>
### Nested Schema for `output_splunk_hec.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_splunk_hec--pq_controls"></a>
### Nested Schema for `output_splunk_hec.pq_controls`


<a id="nestedatt--output_splunk_hec--response_retry_settings"></a>
### Nested Schema for `output_splunk_hec.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_splunk_hec--timeout_retry_settings"></a>
### Nested Schema for `output_splunk_hec.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_splunk_hec--urls"></a>
### Nested Schema for `output_splunk_hec.urls`

Read-Only:

- `url` (String) URL to a Splunk HEC endpoint to send events to, e.g., http://localhost:8088/services/collector/event
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability



<a id="nestedatt--output_splunk_lb"></a>
### Nested Schema for `output_splunk_lb`

Read-Only:

- `auth_token` (String) Shared secret token to use when establishing a connection to a Splunk indexer.
- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (String) Controls whether the sender should send compressed data to the server. Select 'Disabled' to reject compressed connections or 'Always' to ignore server's configuration and send compressed data.
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `enable_ack` (Boolean) Check if indexer is shutting down and stop sending data. This helps minimize data loss during shutdown.
- `enable_multi_metrics` (Boolean) Output metrics in multiple-metric format in a single event. Supported in Splunk 8.0 and above.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `hosts` (Attributes List) Set of Splunk indexers to load-balance data to. (see [below for nested schema](#nestedatt--output_splunk_lb--hosts))
- `id` (String) Unique ID for this output
- `indexer_discovery` (Boolean) Automatically discover indexers in indexer clustering environment.
- `indexer_discovery_configs` (Attributes) List of configurations to set up indexer discovery in Splunk Indexer clustering environment. (see [below for nested schema](#nestedatt--output_splunk_lb--indexer_discovery_configs))
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `log_failed_requests` (Boolean) Use to troubleshoot issues with sending data
- `max_concurrent_senders` (Number) Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
- `max_failed_health_checks` (Number) Maximum number of times healthcheck can fail before we close connection. If set to 0 (disabled), and the connection to Splunk is forcibly closed, some data loss might occur.
- `max_s2_sversion` (String) The highest S2S protocol version to advertise during handshake
- `nested_fields` (String) How to serialize nested fields into index-time fields
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_lb--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `sender_unhealthy_time_allowance` (Number) How long (in milliseconds) each LB endpoint can report blocked before the Destination reports unhealthy, blocking the sender. (Grace period for fluctuations.) Use 0 to disable; max 1 minute.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_splunk_lb--tls))
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_splunk_lb--hosts"></a>
### Nested Schema for `output_splunk_lb.hosts`

Read-Only:

- `host` (String) The hostname of the receiver
- `port` (Number) The port to connect to on the provided host
- `servername` (String) Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
- `tls` (String) Whether to inherit TLS configs from group setting or disable TLS
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability


<a id="nestedatt--output_splunk_lb--indexer_discovery_configs"></a>
### Nested Schema for `output_splunk_lb.indexer_discovery_configs`

Read-Only:

- `auth_token` (String) Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
- `auth_tokens` (Attributes List) Tokens required to authenticate to cluster manager for indexer discovery (see [below for nested schema](#nestedatt--output_splunk_lb--indexer_discovery_configs--auth_tokens))
- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `master_uri` (String) Full URI of Splunk cluster manager (scheme://host:port). Example: https://managerAddress:8089
- `refresh_interval_sec` (Number) Time interval, in seconds, between two consecutive indexer list fetches from cluster manager
- `reject_unauthorized` (Boolean) During indexer discovery, reject cluster manager certificates that are not authorized by the system's CA. Disable to allow untrusted (for example, self-signed) certificates.
- `site` (String) Clustering site of the indexers from where indexers need to be discovered. In case of single site cluster, it defaults to 'default' site.
- `text_secret` (String) Select or create a stored text secret

<a id="nestedatt--output_splunk_lb--indexer_discovery_configs--auth_tokens"></a>
### Nested Schema for `output_splunk_lb.indexer_discovery_configs.auth_tokens`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate



<a id="nestedatt--output_splunk_lb--pq_controls"></a>
### Nested Schema for `output_splunk_lb.pq_controls`


<a id="nestedatt--output_splunk_lb--tls"></a>
### Nested Schema for `output_splunk_lb.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_sqs"></a>
### Nested Schema for `output_sqs`

Read-Only:

- `assume_role_arn` (String) Amazon Resource Name (ARN) of the role to assume
- `assume_role_external_id` (String) External ID to use when assuming role
- `aws_account_id` (String) SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
- `aws_api_key` (String)
- `aws_authentication_method` (String) AWS authentication method. Choose Auto to use IAM roles.
- `aws_secret` (String) Select or create a stored secret that references your access key and secret key
- `aws_secret_key` (String)
- `create_queue` (Boolean) Create queue if it does not exist.
- `description` (String)
- `duration_seconds` (Number) Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
- `enable_assume_role` (Boolean) Use Assume Role credentials to access SQS
- `endpoint` (String) SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
- `id` (String) Unique ID for this output
- `max_in_progress` (Number) The maximum number of in-progress API requests before backpressure is applied.
- `max_queue_size` (Number) Maximum number of queued batches before blocking.
- `max_record_size_kb` (Number) Maximum size (KB) of batches to send. Per the SQS spec, the max allowed value is 256 KB.
- `message_group_id` (String) This parameter applies only to FIFO queues. The tag that specifies that a message belongs to a specific message group. Messages that belong to the same message group are processed in a FIFO manner. Use event field __messageGroupId to override this value.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_sqs--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `queue_name` (String) The name, URL, or ARN of the SQS queue to send events to. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
- `queue_type` (String) The queue type used (or created). Defaults to Standard.
- `region` (String) AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
- `reject_unauthorized` (Boolean) Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
- `reuse_connections` (Boolean) Reuse connections between requests, which can improve performance
- `signature_version` (String) Signature version to use for signing SQS requests
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `type` (String)

<a id="nestedatt--output_sqs--pq_controls"></a>
### Nested Schema for `output_sqs.pq_controls`



<a id="nestedatt--output_statsd"></a>
### Nested Schema for `output_statsd`

Read-Only:

- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
- `host` (String) The hostname of the destination.
- `id` (String) Unique ID for this output
- `mtu` (Number) When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) Destination port.
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_statsd--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Protocol to use when communicating with the destination.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_statsd--pq_controls"></a>
### Nested Schema for `output_statsd.pq_controls`



<a id="nestedatt--output_statsd_ext"></a>
### Nested Schema for `output_statsd_ext`

Read-Only:

- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every batch sent will incur a DNS lookup.
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `flush_period_sec` (Number) When protocol is TCP, specifies how often buffers should be flushed, resulting in records sent to the destination.
- `host` (String) The hostname of the destination.
- `id` (String) Unique ID for this output
- `mtu` (Number) When protocol is UDP, specifies the maximum size of packets sent to the destination. Also known as the MTU for the network path to the destination system.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) Destination port.
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_statsd_ext--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) Protocol to use when communicating with the destination.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_statsd_ext--pq_controls"></a>
### Nested Schema for `output_statsd_ext.pq_controls`



<a id="nestedatt--output_sumo_logic"></a>
### Nested Schema for `output_sumo_logic`

Read-Only:

- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `custom_category` (String) Override the source category configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceCategory field.
- `custom_source` (String) Override the source name configured on the Sumo Logic HTTP collector. This can also be overridden at the event level with the __sourceName field.
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_sumo_logic--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) Preserve the raw event format instead of JSONifying it
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_sumo_logic--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_sumo_logic--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_sumo_logic--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) Sumo Logic HTTP collector URL to which events should be sent
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_sumo_logic--extra_http_headers"></a>
### Nested Schema for `output_sumo_logic.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_sumo_logic--pq_controls"></a>
### Nested Schema for `output_sumo_logic.pq_controls`


<a id="nestedatt--output_sumo_logic--response_retry_settings"></a>
### Nested Schema for `output_sumo_logic.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_sumo_logic--timeout_retry_settings"></a>
### Nested Schema for `output_sumo_logic.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_syslog"></a>
### Nested Schema for `output_syslog`

Read-Only:

- `app_name` (String) Default name for device or application that originated the message. Defaults to Cribl, but will be overwritten by value of __appname if set.
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `facility` (Number) Default value for message facility. Will be overwritten by value of __facility if set. Defaults to user.
- `host` (String) The hostname of the receiver
- `id` (String) Unique ID for this output
- `load_balanced` (Boolean) For optimal performance, enable load balancing even if you have one hostname, as it can expand to multiple IPs.  If this setting is disabled, consider enabling round-robin DNS.
- `log_failed_requests` (Boolean) Use to troubleshoot issues with sending data
- `max_record_size` (Number) Maximum size of syslog messages. Make sure this value is less than or equal to the MTU to avoid UDP packet fragmentation.
- `message_format` (String) The syslog message format depending on the receiver's support
- `octet_count_framing` (Boolean) Prefix messages with the byte count of the message. If disabled, no prefix will be set, and the message will be appended with a \n.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) The port to connect to on the provided host
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_syslog--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `protocol` (String) The network protocol to use for sending out syslog messages
- `severity` (Number) Default value for message severity. Will be overwritten by value of __severity if set. Defaults to notice.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `timestamp_format` (String) Timestamp format to use when serializing event's time field
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_syslog--tls))
- `type` (String)
- `udp_dns_resolve_period_sec` (Number) How often to resolve the destination hostname to an IP address. Ignored if the destination is an IP address. A value of 0 means every message sent will incur a DNS lookup.
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_syslog--pq_controls"></a>
### Nested Schema for `output_syslog.pq_controls`


<a id="nestedatt--output_syslog--tls"></a>
### Nested Schema for `output_syslog.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_tcpjson"></a>
### Nested Schema for `output_tcpjson`

Read-Only:

- `auth_token` (String) Optional authentication token to include as part of the connection header
- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compression` (String) Codec to use to compress the data before sending
- `connection_timeout` (Number) Amount of time (milliseconds) to wait for the connection to establish before retrying
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `host` (String) The hostname of the receiver
- `hosts` (Attributes List) Set of hosts to load-balance data to (see [below for nested schema](#nestedatt--output_tcpjson--hosts))
- `id` (String) Unique ID for this output
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Use load-balanced destinations
- `log_failed_requests` (Boolean) Use to troubleshoot issues with sending data
- `max_concurrent_senders` (Number) Maximum number of concurrent connections (per Worker Process). A random set of IPs will be picked on every DNS resolution period. Use 0 for unlimited.
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `port` (Number) The port to connect to on the provided host
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_tcpjson--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `send_header` (Boolean) Upon connection, send a header-like record containing the auth token and other metadata.This record will not contain an actual event – only subsequent records will.
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `throttle_rate_per_sec` (String) Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_tcpjson--tls))
- `token_ttl_minutes` (Number) The number of minutes before the internally generated authentication token expires, valid values between 1 and 60
- `type` (String)
- `write_timeout` (Number) Amount of time (milliseconds) to wait for a write to complete before assuming connection is dead

<a id="nestedatt--output_tcpjson--hosts"></a>
### Nested Schema for `output_tcpjson.hosts`

Read-Only:

- `host` (String) The hostname of the receiver
- `port` (Number) The port to connect to on the provided host
- `servername` (String) Servername to use if establishing a TLS connection. If not specified, defaults to connection host (if not an IP); otherwise, uses the global TLS settings.
- `tls` (String) Whether to inherit TLS configs from group setting or disable TLS
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability


<a id="nestedatt--output_tcpjson--pq_controls"></a>
### Nested Schema for `output_tcpjson.pq_controls`


<a id="nestedatt--output_tcpjson--tls"></a>
### Nested Schema for `output_tcpjson.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `reject_unauthorized` (Boolean) Reject certificates that are not authorized by a CA in the CA certificate path, or by another 
                    trusted CA (such as the system's). Defaults to Enabled. Overrides the toggle from Advanced Settings, when also present.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.



<a id="nestedatt--output_wavefront"></a>
### Nested Schema for `output_wavefront`

Read-Only:

- `auth_type` (String) Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `domain` (String) WaveFront domain name, e.g. "longboard"
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_wavefront--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_wavefront--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_wavefront--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_wavefront--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) WaveFront API authentication token (see [here](https://docs.wavefront.com/wavefront_api.html#generating-an-api-token))
- `type` (String)
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_wavefront--extra_http_headers"></a>
### Nested Schema for `output_wavefront.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_wavefront--pq_controls"></a>
### Nested Schema for `output_wavefront.pq_controls`


<a id="nestedatt--output_wavefront--response_retry_settings"></a>
### Nested Schema for `output_wavefront.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_wavefront--timeout_retry_settings"></a>
### Nested Schema for `output_wavefront.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)



<a id="nestedatt--output_webhook"></a>
### Nested Schema for `output_webhook`

Read-Only:

- `advanced_content_type` (String) HTTP content-type header value
- `auth_header_expr` (String) JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
- `auth_type` (String) Authentication method to use for the HTTP request
- `compress` (Boolean) Compress the payload body before sending
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `credentials_secret` (String) Select or create a secret that references your credentials
- `custom_content_type` (String) Content type to use for request. Defaults to application/x-ndjson. Any content types set in Advanced Settings > Extra HTTP headers will override this entry.
- `custom_drop_when_null` (Boolean) Whether to drop events when the source expression evaluates to null
- `custom_event_delimiter` (String) Delimiter string to insert between individual events. Defaults to newline character.
- `custom_payload_expression` (String) Expression specifying how to format the payload for each batch. To reference the events to send, use the `${events}` variable. Example expression: `{ "items" : [${events}] }` would send the batch inside a JSON object.
- `custom_source_expression` (String) Expression to evaluate on events to generate output. Example: `raw=${_raw}`. See [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook#custom-format) for other examples. If empty, the full event is sent as stringified JSON.
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `extra_http_headers` (Attributes List) Headers to add to all events. You can also add headers dynamically on a per-event basis in the __headers field, as explained in [Cribl Docs](https://docs.cribl.io/stream/destinations-webhook/#internal-fields). (see [below for nested schema](#nestedatt--output_webhook--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `format` (String) How to format events before sending out
- `format_event_code` (String) Custom JavaScript code to format incoming event data accessible through the __e variable. The formatted content is added to (__e['__eventOut']) if available. Otherwise, the original event is serialized as JSON. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
- `format_payload_code` (String) Optional JavaScript code to format the payload sent to the Destination. The payload, containing a batch of formatted events, is accessible through the __e['payload'] variable. The formatted payload is returned in the __e['__payloadOut'] variable. Caution: This function is evaluated in an unprotected context, allowing you to execute almost any JavaScript code.
- `id` (String) Unique ID for this output
- `keep_alive` (Boolean) Disable to close the connection immediately after sending the outgoing request
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
- `login_url` (String) URL for OAuth
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `method` (String) The method to use when sending events
- `oauth_headers` (Attributes List) Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_webhook--oauth_headers))
- `oauth_params` (Attributes List) Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request. (see [below for nested schema](#nestedatt--output_webhook--oauth_params))
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `password` (String)
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_webhook--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_webhook--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `secret` (String) Secret parameter value to pass in request body
- `secret_param_name` (String) Secret parameter name to pass in request body
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_webhook--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `tls` (Attributes) (see [below for nested schema](#nestedatt--output_webhook--tls))
- `token` (String) Bearer token to include in the authorization header
- `token_attribute_name` (String) Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
- `token_timeout_secs` (Number) How often the OAuth token should be refreshed.
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) URL of a webhook endpoint to send events to, such as http://localhost:10200
- `urls` (Attributes List) (see [below for nested schema](#nestedatt--output_webhook--urls))
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.
- `username` (String)

<a id="nestedatt--output_webhook--extra_http_headers"></a>
### Nested Schema for `output_webhook.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_webhook--oauth_headers"></a>
### Nested Schema for `output_webhook.oauth_headers`

Read-Only:

- `name` (String) OAuth header name
- `value` (String) OAuth header value


<a id="nestedatt--output_webhook--oauth_params"></a>
### Nested Schema for `output_webhook.oauth_params`

Read-Only:

- `name` (String) OAuth parameter name
- `value` (String) OAuth parameter value


<a id="nestedatt--output_webhook--pq_controls"></a>
### Nested Schema for `output_webhook.pq_controls`


<a id="nestedatt--output_webhook--response_retry_settings"></a>
### Nested Schema for `output_webhook.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_webhook--timeout_retry_settings"></a>
### Nested Schema for `output_webhook.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_webhook--tls"></a>
### Nested Schema for `output_webhook.tls`

Read-Only:

- `ca_path` (String) Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
- `cert_path` (String) Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
- `certificate_name` (String) The name of the predefined certificate
- `disabled` (Boolean)
- `max_version` (String)
- `min_version` (String)
- `passphrase` (String) Passphrase to use to decrypt private key
- `priv_key_path` (String) Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
- `servername` (String) Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.


<a id="nestedatt--output_webhook--urls"></a>
### Nested Schema for `output_webhook.urls`

Read-Only:

- `url` (String) URL of a webhook endpoint to send events to, such as http://localhost:10200
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability



<a id="nestedatt--output_xsiam"></a>
### Nested Schema for `output_xsiam`

Read-Only:

- `auth_type` (String) Enter a token directly, or provide a secret referencing a token
- `concurrency` (Number) Maximum number of ongoing requests before blocking
- `description` (String)
- `dns_resolve_period_sec` (Number) The interval in which to re-resolve any hostnames and pick up destinations from A records
- `environment` (String) Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
- `exclude_self` (Boolean) Exclude all IPs of the current host from the list of any resolved hostnames
- `extra_http_headers` (Attributes List) Headers to add to all events (see [below for nested schema](#nestedatt--output_xsiam--extra_http_headers))
- `failed_request_logging_mode` (String) Data to log when a request fails. All headers are redacted by default, unless listed as safe headers below.
- `flush_period_sec` (Number) Maximum time between requests. Small values could cause the payload size to be smaller than the configured Body size limit.
- `id` (String) Unique ID for this output
- `load_balance_stats_period_sec` (Number) How far back in time to keep traffic stats for load balancing purposes
- `load_balanced` (Boolean) Enable for optimal performance. Even if you have one hostname, it can expand to multiple IPs. If disabled, consider enabling round-robin DNS.
- `max_payload_events` (Number) Maximum number of events to include in the request body. Default is 0 (unlimited).
- `max_payload_size_kb` (Number) Maximum size, in KB, of the request body
- `on_backpressure` (String) How to handle events when all receivers are exerting backpressure
- `pipeline` (String) Pipeline to process data before sending out to this output
- `pq_compress` (String) Codec to use to compress the persisted data
- `pq_controls` (Attributes) (see [below for nested schema](#nestedatt--output_xsiam--pq_controls))
- `pq_max_file_size` (String) The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.)
- `pq_max_size` (String) The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
- `pq_mode` (String) In Error mode, PQ writes events to the filesystem if the Destination is unavailable. In Backpressure mode, PQ writes events to the filesystem when it detects backpressure from the Destination. In Always On mode, PQ always writes events to the filesystem.
- `pq_on_backpressure` (String) How to handle events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
- `pq_path` (String) The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
- `reject_unauthorized` (Boolean) Reject certificates not authorized by a CA in the CA certificate path or by another trusted CA (such as the system's). 
        Enabled by default. When this setting is also present in TLS Settings (Client Side), 
        that value will take precedence.
- `response_honor_retry_after_header` (Boolean) Honor any Retry-After header that specifies a delay (in seconds) no longer than 180 seconds after the retry request. @{product} limits the delay to 180 seconds, even if the Retry-After header specifies a longer delay. When enabled, takes precedence over user-configured retry options. When disabled, all Retry-After headers are ignored.
- `response_retry_settings` (Attributes List) Automatically retry after unsuccessful response status codes, such as 429 (Too Many Requests) or 503 (Service Unavailable) (see [below for nested schema](#nestedatt--output_xsiam--response_retry_settings))
- `safe_headers` (List of String) List of headers that are safe to log in plain text
- `streamtags` (List of String) Tags for filtering and grouping in @{product}
- `system_fields` (List of String) Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
- `text_secret` (String) Select or create a stored text secret
- `throttle_rate_req_per_sec` (Number) Maximum number of requests to limit to per second
- `timeout_retry_settings` (Attributes) (see [below for nested schema](#nestedatt--output_xsiam--timeout_retry_settings))
- `timeout_sec` (Number) Amount of time, in seconds, to wait for a request to complete before canceling it
- `token` (String) XSIAM authentication token
- `total_memory_limit_kb` (Number) Maximum total size of the batches waiting to be sent. If left blank, defaults to 5 times the max body size (if set). If 0, no limit is enforced.
- `type` (String)
- `url` (String) XSIAM endpoint URL to send events to, such as https://api-{tenant external URL}/logs/v1/event
- `urls` (Attributes List) (see [below for nested schema](#nestedatt--output_xsiam--urls))
- `use_round_robin_dns` (Boolean) Enable round-robin DNS lookup. When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned. For optimal performance, consider enabling this setting for non-load balanced destinations.

<a id="nestedatt--output_xsiam--extra_http_headers"></a>
### Nested Schema for `output_xsiam.extra_http_headers`

Read-Only:

- `name` (String)
- `value` (String)


<a id="nestedatt--output_xsiam--pq_controls"></a>
### Nested Schema for `output_xsiam.pq_controls`


<a id="nestedatt--output_xsiam--response_retry_settings"></a>
### Nested Schema for `output_xsiam.response_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `http_status` (Number) The HTTP response status code that will trigger retries
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).


<a id="nestedatt--output_xsiam--timeout_retry_settings"></a>
### Nested Schema for `output_xsiam.timeout_retry_settings`

Read-Only:

- `backoff_rate` (Number) Base for exponential backoff. A value of 2 (default) means Cribl Stream will retry after 2 seconds, then 4 seconds, then 8 seconds, etc.
- `initial_backoff` (Number) How long, in milliseconds, Cribl Stream should wait before initiating backoff. Maximum interval is 600,000 ms (10 minutes).
- `max_backoff` (Number) The maximum backoff interval, in milliseconds, Cribl Stream should apply. Default (and minimum) is 10,000 ms (10 seconds); maximum is 180,000 ms (180 seconds).
- `timeout_retry` (Boolean)


<a id="nestedatt--output_xsiam--urls"></a>
### Nested Schema for `output_xsiam.urls`

Read-Only:

- `url` (String) Parsed as JSON.
- `weight` (Number) Assign a weight (>0) to each endpoint to indicate its traffic-handling capability
