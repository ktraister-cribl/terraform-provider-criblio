// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type InputAzureBlobType string

const (
	InputAzureBlobTypeAzureBlob InputAzureBlobType = "azure_blob"
)

func (e InputAzureBlobType) ToPointer() *InputAzureBlobType {
	return &e
}
func (e *InputAzureBlobType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = InputAzureBlobType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobType: %v", v)
	}
}

type InputAzureBlobConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (i InputAzureBlobConnection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlobConnection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"output"}); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlobConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlobConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputAzureBlobMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputAzureBlobMode string

const (
	InputAzureBlobModeSmart  InputAzureBlobMode = "smart"
	InputAzureBlobModeAlways InputAzureBlobMode = "always"
)

func (e InputAzureBlobMode) ToPointer() *InputAzureBlobMode {
	return &e
}
func (e *InputAzureBlobMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputAzureBlobMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobMode: %v", v)
	}
}

// InputAzureBlobCompression - Codec to use to compress the persisted data
type InputAzureBlobCompression string

const (
	InputAzureBlobCompressionNone InputAzureBlobCompression = "none"
	InputAzureBlobCompressionGzip InputAzureBlobCompression = "gzip"
)

func (e InputAzureBlobCompression) ToPointer() *InputAzureBlobCompression {
	return &e
}
func (e *InputAzureBlobCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputAzureBlobCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobCompression: %v", v)
	}
}

type InputAzureBlobPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputAzureBlobMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputAzureBlobCompression `default:"none" json:"compress"`
}

func (i InputAzureBlobPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlobPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlobPq) GetMode() *InputAzureBlobMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputAzureBlobPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputAzureBlobPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputAzureBlobPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputAzureBlobPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputAzureBlobPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputAzureBlobPq) GetCompress() *InputAzureBlobCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputAzureBlobMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (i InputAzureBlobMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlobMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"name", "value"}); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlobMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputAzureBlobMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputAzureBlobAuthenticationMethod string

const (
	InputAzureBlobAuthenticationMethodManual       InputAzureBlobAuthenticationMethod = "manual"
	InputAzureBlobAuthenticationMethodSecret       InputAzureBlobAuthenticationMethod = "secret"
	InputAzureBlobAuthenticationMethodClientSecret InputAzureBlobAuthenticationMethod = "clientSecret"
	InputAzureBlobAuthenticationMethodClientCert   InputAzureBlobAuthenticationMethod = "clientCert"
)

func (e InputAzureBlobAuthenticationMethod) ToPointer() *InputAzureBlobAuthenticationMethod {
	return &e
}
func (e *InputAzureBlobAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = InputAzureBlobAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobAuthenticationMethod: %v", v)
	}
}

type InputAzureBlobCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (i InputAzureBlobCertificate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlobCertificate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"certificateName"}); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlobCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputAzureBlobType `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputAzureBlobConnection `json:"connections,omitempty"`
	Pq          *InputAzureBlobPq          `json:"pq,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at initialization time. Example referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `default:"5" json:"servicePeriodSecs"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Fields to add to events from this input
	Metadata []InputAzureBlobMetadatum `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                            `default:"600" json:"parquetChunkDownloadTimeout"`
	AuthType                    *InputAzureBlobAuthenticationMethod `default:"manual" json:"authType"`
	Description                 *string                             `json:"description,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitempty"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                    `json:"clientTextSecret,omitempty"`
	Certificate      *InputAzureBlobCertificate `json:"certificate,omitempty"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, []string{"type", "queueName"}); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlob) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputAzureBlob) GetType() InputAzureBlobType {
	if o == nil {
		return InputAzureBlobType("")
	}
	return o.Type
}

func (o *InputAzureBlob) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlob) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAzureBlob) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAzureBlob) GetConnections() []InputAzureBlobConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAzureBlob) GetPq() *InputAzureBlobPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAzureBlob) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputAzureBlob) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputAzureBlob) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputAzureBlob) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.ServicePeriodSecs
}

func (o *InputAzureBlob) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputAzureBlob) GetMetadata() []InputAzureBlobMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAzureBlob) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputAzureBlob) GetAuthType() *InputAzureBlobAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *InputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *InputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputAzureBlob) GetAzureCloud() *string {
	if o == nil {
		return nil
	}
	return o.AzureCloud
}

func (o *InputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *InputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *InputAzureBlob) GetCertificate() *InputAzureBlobCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}
