// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/criblio/terraform-provider-criblio/internal/sdk/internal/utils"
)

type OutputAzureBlobType string

const (
	OutputAzureBlobTypeAzureBlob OutputAzureBlobType = "azure_blob"
)

func (e OutputAzureBlobType) ToPointer() *OutputAzureBlobType {
	return &e
}
func (e *OutputAzureBlobType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = OutputAzureBlobType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobType: %v", v)
	}
}

// OutputAzureBlobDataFormat - Format of the output data
type OutputAzureBlobDataFormat string

const (
	OutputAzureBlobDataFormatJSON    OutputAzureBlobDataFormat = "json"
	OutputAzureBlobDataFormatRaw     OutputAzureBlobDataFormat = "raw"
	OutputAzureBlobDataFormatParquet OutputAzureBlobDataFormat = "parquet"
)

func (e OutputAzureBlobDataFormat) ToPointer() *OutputAzureBlobDataFormat {
	return &e
}
func (e *OutputAzureBlobDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		fallthrough
	case "parquet":
		*e = OutputAzureBlobDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDataFormat: %v", v)
	}
}

// OutputAzureBlobBackpressureBehavior - How to handle events when all receivers are exerting backpressure
type OutputAzureBlobBackpressureBehavior string

const (
	OutputAzureBlobBackpressureBehaviorBlock OutputAzureBlobBackpressureBehavior = "block"
	OutputAzureBlobBackpressureBehaviorDrop  OutputAzureBlobBackpressureBehavior = "drop"
)

func (e OutputAzureBlobBackpressureBehavior) ToPointer() *OutputAzureBlobBackpressureBehavior {
	return &e
}
func (e *OutputAzureBlobBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureBlobBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobBackpressureBehavior: %v", v)
	}
}

// OutputAzureBlobDiskSpaceProtection - How to handle events when disk space is below the global 'Min free disk space' limit
type OutputAzureBlobDiskSpaceProtection string

const (
	OutputAzureBlobDiskSpaceProtectionBlock OutputAzureBlobDiskSpaceProtection = "block"
	OutputAzureBlobDiskSpaceProtectionDrop  OutputAzureBlobDiskSpaceProtection = "drop"
)

func (e OutputAzureBlobDiskSpaceProtection) ToPointer() *OutputAzureBlobDiskSpaceProtection {
	return &e
}
func (e *OutputAzureBlobDiskSpaceProtection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureBlobDiskSpaceProtection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDiskSpaceProtection: %v", v)
	}
}

type OutputAzureBlobAuthenticationMethod string

const (
	OutputAzureBlobAuthenticationMethodManual       OutputAzureBlobAuthenticationMethod = "manual"
	OutputAzureBlobAuthenticationMethodSecret       OutputAzureBlobAuthenticationMethod = "secret"
	OutputAzureBlobAuthenticationMethodClientSecret OutputAzureBlobAuthenticationMethod = "clientSecret"
	OutputAzureBlobAuthenticationMethodClientCert   OutputAzureBlobAuthenticationMethod = "clientCert"
)

func (e OutputAzureBlobAuthenticationMethod) ToPointer() *OutputAzureBlobAuthenticationMethod {
	return &e
}
func (e *OutputAzureBlobAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = OutputAzureBlobAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobAuthenticationMethod: %v", v)
	}
}

type BlobAccessTier string

const (
	BlobAccessTierInferred BlobAccessTier = "Inferred"
	BlobAccessTierHot      BlobAccessTier = "Hot"
	BlobAccessTierCool     BlobAccessTier = "Cool"
	BlobAccessTierCold     BlobAccessTier = "Cold"
	BlobAccessTierArchive  BlobAccessTier = "Archive"
)

func (e BlobAccessTier) ToPointer() *BlobAccessTier {
	return &e
}
func (e *BlobAccessTier) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Inferred":
		fallthrough
	case "Hot":
		fallthrough
	case "Cool":
		fallthrough
	case "Cold":
		fallthrough
	case "Archive":
		*e = BlobAccessTier(v)
		return nil
	default:
		return fmt.Errorf("invalid value for BlobAccessTier: %v", v)
	}
}

// OutputAzureBlobCompression - Data compression format to apply to HTTP content before it is delivered
type OutputAzureBlobCompression string

const (
	OutputAzureBlobCompressionNone OutputAzureBlobCompression = "none"
	OutputAzureBlobCompressionGzip OutputAzureBlobCompression = "gzip"
)

func (e OutputAzureBlobCompression) ToPointer() *OutputAzureBlobCompression {
	return &e
}
func (e *OutputAzureBlobCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureBlobCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobCompression: %v", v)
	}
}

// OutputAzureBlobCompressionLevel - Compression level to apply before moving files to final destination
type OutputAzureBlobCompressionLevel string

const (
	OutputAzureBlobCompressionLevelBestSpeed       OutputAzureBlobCompressionLevel = "best_speed"
	OutputAzureBlobCompressionLevelNormal          OutputAzureBlobCompressionLevel = "normal"
	OutputAzureBlobCompressionLevelBestCompression OutputAzureBlobCompressionLevel = "best_compression"
)

func (e OutputAzureBlobCompressionLevel) ToPointer() *OutputAzureBlobCompressionLevel {
	return &e
}
func (e *OutputAzureBlobCompressionLevel) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "best_speed":
		fallthrough
	case "normal":
		fallthrough
	case "best_compression":
		*e = OutputAzureBlobCompressionLevel(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobCompressionLevel: %v", v)
	}
}

// OutputAzureBlobParquetVersion - Determines which data types are supported and how they are represented
type OutputAzureBlobParquetVersion string

const (
	OutputAzureBlobParquetVersionParquet10 OutputAzureBlobParquetVersion = "PARQUET_1_0"
	OutputAzureBlobParquetVersionParquet24 OutputAzureBlobParquetVersion = "PARQUET_2_4"
	OutputAzureBlobParquetVersionParquet26 OutputAzureBlobParquetVersion = "PARQUET_2_6"
)

func (e OutputAzureBlobParquetVersion) ToPointer() *OutputAzureBlobParquetVersion {
	return &e
}
func (e *OutputAzureBlobParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputAzureBlobParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobParquetVersion: %v", v)
	}
}

// OutputAzureBlobDataPageVersion - Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
type OutputAzureBlobDataPageVersion string

const (
	OutputAzureBlobDataPageVersionDataPageV1 OutputAzureBlobDataPageVersion = "DATA_PAGE_V1"
	OutputAzureBlobDataPageVersionDataPageV2 OutputAzureBlobDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputAzureBlobDataPageVersion) ToPointer() *OutputAzureBlobDataPageVersion {
	return &e
}
func (e *OutputAzureBlobDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputAzureBlobDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureBlobDataPageVersion: %v", v)
	}
}

type OutputAzureBlobKeyValueMetadatum struct {
	Key   *string `default:"" json:"key"`
	Value string  `json:"value"`
}

func (o OutputAzureBlobKeyValueMetadatum) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureBlobKeyValueMetadatum) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"value"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureBlobKeyValueMetadatum) GetKey() *string {
	if o == nil {
		return nil
	}
	return o.Key
}

func (o *OutputAzureBlobKeyValueMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OutputAzureBlobCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (o OutputAzureBlobCertificate) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureBlobCertificate) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"certificateName"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureBlobCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type OutputAzureBlob struct {
	// Unique ID for this output
	ID   *string              `json:"id,omitempty"`
	Type *OutputAzureBlobType `json:"type,omitempty"`
	// Pipeline to process data before sending out to this output
	Pipeline *string `json:"pipeline,omitempty"`
	// Fields to automatically add to events, such as cribl_pipe. Supports wildcards.
	SystemFields []string `json:"systemFields,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// The Azure Blob Storage container name. Name can include only lowercase letters, numbers, and hyphens. For dynamic container names, enter a JavaScript expression within quotes or backtickss, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myContainer-${C.env["CRIBL_WORKER_ID"]}`.
	ContainerName string `json:"containerName"`
	// Create the configured container in Azure Blob Storage if it does not already exist
	CreateContainer *bool `default:"false" json:"createContainer"`
	// Root directory prepended to path before uploading. Value can be a JavaScript expression enclosed in quotes or backticks, to be evaluated at initialization. The expression can evaluate to a constant value and can reference Global Variables, such as `myBlobPrefix-${C.env["CRIBL_WORKER_ID"]}`.
	DestPath *string `json:"destPath,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant and stable storage.
	StagePath *string `default:"$CRIBL_HOME/state/outputs/staging" json:"stagePath"`
	// Add the Output ID value to staging location
	AddIDToStagePath *bool `default:"true" json:"addIdToStagePath"`
	// Maximum number of parts to upload in parallel per file
	MaxConcurrentFileParts *float64 `default:"1" json:"maxConcurrentFileParts"`
	// Remove empty staging directories after moving files
	RemoveEmptyDirs *bool `default:"true" json:"removeEmptyDirs"`
	// JavaScript expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `default:"C.Time.strftime(_time ? _time : Date.now()/1000, '%Y/%m/%d')" json:"partitionExpr"`
	// Format of the output data
	Format *OutputAzureBlobDataFormat `default:"json" json:"format"`
	// JavaScript expression to define the output filename prefix (can be constant)
	BaseFileName *string `default:"CriblOut" json:"baseFileName"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`).
	FileNameSuffix *string `default:".\\${C.env[\"CRIBL_WORKER_ID\"]}.\\${__format}\\${__compression === \"gzip\" ? \".gz\" : \"\"}" json:"fileNameSuffix"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *float64 `default:"32" json:"maxFileSizeMB"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *float64 `default:"300" json:"maxFileOpenTimeSec"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *float64 `default:"30" json:"maxFileIdleTimeSec"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *float64 `default:"100" json:"maxOpenFiles"`
	// If set, this line will be written to the beginning of each output file
	HeaderLine *string `default:"" json:"headerLine"`
	// Buffer size used to write to a file
	WriteHighWaterMark *float64 `default:"64" json:"writeHighWaterMark"`
	// How to handle events when all receivers are exerting backpressure
	OnBackpressure *OutputAzureBlobBackpressureBehavior `default:"block" json:"onBackpressure"`
	// If a file fails to move to its final destination after the maximum number of retries, move it to a designated directory to prevent further errors
	DeadletterEnabled *bool `default:"false" json:"deadletterEnabled"`
	// How to handle events when disk space is below the global 'Min free disk space' limit
	OnDiskFullBackpressure *OutputAzureBlobDiskSpaceProtection  `default:"block" json:"onDiskFullBackpressure"`
	AuthType               *OutputAzureBlobAuthenticationMethod `default:"manual" json:"authType"`
	StorageClass           *BlobAccessTier                      `default:"Inferred" json:"storageClass"`
	Description            *string                              `json:"description,omitempty"`
	// Data compression format to apply to HTTP content before it is delivered
	Compress *OutputAzureBlobCompression `default:"gzip" json:"compress"`
	// Compression level to apply before moving files to final destination
	CompressionLevel *OutputAzureBlobCompressionLevel `default:"best_speed" json:"compressionLevel"`
	// Automatically calculate the schema based on the events of each Parquet file generated
	AutomaticSchema *bool `default:"false" json:"automaticSchema"`
	// Determines which data types are supported and how they are represented
	ParquetVersion *OutputAzureBlobParquetVersion `default:"PARQUET_2_6" json:"parquetVersion"`
	// Serialization format of data pages. Note that some reader implementations use Data page V2's attributes to work more efficiently, while others ignore it.
	ParquetDataPageVersion *OutputAzureBlobDataPageVersion `default:"DATA_PAGE_V2" json:"parquetDataPageVersion"`
	// The number of rows that every group will contain. The final group can contain a smaller number of rows.
	ParquetRowGroupLength *float64 `default:"10000" json:"parquetRowGroupLength"`
	// Target memory size for page segments, such as 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression.
	ParquetPageSize *string `default:"1MB" json:"parquetPageSize"`
	// Log up to 3 rows that @{product} skips due to data mismatch
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// The metadata of files the Destination writes will include the properties you add here as key-value pairs. Useful for tagging. Examples: "key":"OCSF Event Class", "value":"9001"
	KeyValueMetadata []OutputAzureBlobKeyValueMetadatum `json:"keyValueMetadata,omitempty"`
	// Statistics profile an entire file in terms of minimum/maximum values within data, numbers of nulls, etc. You can use Parquet tools to view statistics.
	EnableStatistics *bool `default:"true" json:"enableStatistics"`
	// One page index contains statistics for one data page. Parquet readers use statistics to enable page skipping.
	EnableWritePageIndex *bool `default:"true" json:"enableWritePageIndex"`
	// Parquet tools can use the checksum of a Parquet page to verify data integrity
	EnablePageChecksum *bool `default:"false" json:"enablePageChecksum"`
	// How frequently, in seconds, to clean up empty directories
	EmptyDirCleanupSec *float64 `default:"300" json:"emptyDirCleanupSec"`
	// Storage location for files that fail to reach their final destination after maximum retries are exceeded
	DeadletterPath *string `default:"$CRIBL_HOME/state/outputs/dead-letter" json:"deadletterPath"`
	// The maximum number of times a file will attempt to move to its final destination before being dead-lettered
	MaxRetryNum *float64 `default:"20" json:"maxRetryNum"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// The Azure cloud to use. Defaults to Azure Public Cloud.
	AzureCloud *string `json:"azureCloud,omitempty"`
	// Endpoint suffix for the service URL. Takes precedence over the Azure Cloud setting. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string                     `json:"clientTextSecret,omitempty"`
	Certificate      *OutputAzureBlobCertificate `json:"certificate,omitempty"`
}

func (o OutputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(o, "", false)
}

func (o *OutputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &o, "", false, []string{"containerName"}); err != nil {
		return err
	}
	return nil
}

func (o *OutputAzureBlob) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *OutputAzureBlob) GetType() *OutputAzureBlobType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *OutputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *OutputAzureBlob) GetSystemFields() []string {
	if o == nil {
		return nil
	}
	return o.SystemFields
}

func (o *OutputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *OutputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *OutputAzureBlob) GetContainerName() string {
	if o == nil {
		return ""
	}
	return o.ContainerName
}

func (o *OutputAzureBlob) GetCreateContainer() *bool {
	if o == nil {
		return nil
	}
	return o.CreateContainer
}

func (o *OutputAzureBlob) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

func (o *OutputAzureBlob) GetStagePath() *string {
	if o == nil {
		return nil
	}
	return o.StagePath
}

func (o *OutputAzureBlob) GetAddIDToStagePath() *bool {
	if o == nil {
		return nil
	}
	return o.AddIDToStagePath
}

func (o *OutputAzureBlob) GetMaxConcurrentFileParts() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxConcurrentFileParts
}

func (o *OutputAzureBlob) GetRemoveEmptyDirs() *bool {
	if o == nil {
		return nil
	}
	return o.RemoveEmptyDirs
}

func (o *OutputAzureBlob) GetPartitionExpr() *string {
	if o == nil {
		return nil
	}
	return o.PartitionExpr
}

func (o *OutputAzureBlob) GetFormat() *OutputAzureBlobDataFormat {
	if o == nil {
		return nil
	}
	return o.Format
}

func (o *OutputAzureBlob) GetBaseFileName() *string {
	if o == nil {
		return nil
	}
	return o.BaseFileName
}

func (o *OutputAzureBlob) GetFileNameSuffix() *string {
	if o == nil {
		return nil
	}
	return o.FileNameSuffix
}

func (o *OutputAzureBlob) GetMaxFileSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileSizeMB
}

func (o *OutputAzureBlob) GetMaxFileOpenTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileOpenTimeSec
}

func (o *OutputAzureBlob) GetMaxFileIdleTimeSec() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxFileIdleTimeSec
}

func (o *OutputAzureBlob) GetMaxOpenFiles() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxOpenFiles
}

func (o *OutputAzureBlob) GetHeaderLine() *string {
	if o == nil {
		return nil
	}
	return o.HeaderLine
}

func (o *OutputAzureBlob) GetWriteHighWaterMark() *float64 {
	if o == nil {
		return nil
	}
	return o.WriteHighWaterMark
}

func (o *OutputAzureBlob) GetOnBackpressure() *OutputAzureBlobBackpressureBehavior {
	if o == nil {
		return nil
	}
	return o.OnBackpressure
}

func (o *OutputAzureBlob) GetDeadletterEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.DeadletterEnabled
}

func (o *OutputAzureBlob) GetOnDiskFullBackpressure() *OutputAzureBlobDiskSpaceProtection {
	if o == nil {
		return nil
	}
	return o.OnDiskFullBackpressure
}

func (o *OutputAzureBlob) GetAuthType() *OutputAzureBlobAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *OutputAzureBlob) GetStorageClass() *BlobAccessTier {
	if o == nil {
		return nil
	}
	return o.StorageClass
}

func (o *OutputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *OutputAzureBlob) GetCompress() *OutputAzureBlobCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *OutputAzureBlob) GetCompressionLevel() *OutputAzureBlobCompressionLevel {
	if o == nil {
		return nil
	}
	return o.CompressionLevel
}

func (o *OutputAzureBlob) GetAutomaticSchema() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchema
}

func (o *OutputAzureBlob) GetParquetVersion() *OutputAzureBlobParquetVersion {
	if o == nil {
		return nil
	}
	return o.ParquetVersion
}

func (o *OutputAzureBlob) GetParquetDataPageVersion() *OutputAzureBlobDataPageVersion {
	if o == nil {
		return nil
	}
	return o.ParquetDataPageVersion
}

func (o *OutputAzureBlob) GetParquetRowGroupLength() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetRowGroupLength
}

func (o *OutputAzureBlob) GetParquetPageSize() *string {
	if o == nil {
		return nil
	}
	return o.ParquetPageSize
}

func (o *OutputAzureBlob) GetShouldLogInvalidRows() *bool {
	if o == nil {
		return nil
	}
	return o.ShouldLogInvalidRows
}

func (o *OutputAzureBlob) GetKeyValueMetadata() []OutputAzureBlobKeyValueMetadatum {
	if o == nil {
		return nil
	}
	return o.KeyValueMetadata
}

func (o *OutputAzureBlob) GetEnableStatistics() *bool {
	if o == nil {
		return nil
	}
	return o.EnableStatistics
}

func (o *OutputAzureBlob) GetEnableWritePageIndex() *bool {
	if o == nil {
		return nil
	}
	return o.EnableWritePageIndex
}

func (o *OutputAzureBlob) GetEnablePageChecksum() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePageChecksum
}

func (o *OutputAzureBlob) GetEmptyDirCleanupSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EmptyDirCleanupSec
}

func (o *OutputAzureBlob) GetDeadletterPath() *string {
	if o == nil {
		return nil
	}
	return o.DeadletterPath
}

func (o *OutputAzureBlob) GetMaxRetryNum() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetryNum
}

func (o *OutputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *OutputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *OutputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *OutputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *OutputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *OutputAzureBlob) GetAzureCloud() *string {
	if o == nil {
		return nil
	}
	return o.AzureCloud
}

func (o *OutputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *OutputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *OutputAzureBlob) GetCertificate() *OutputAzureBlobCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}
