// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"errors"
	"fmt"
	"github.com/speakeasy/terraform-provider-criblio/internal/sdk/internal/utils"
)

type TypeZscalerHec string

const (
	TypeZscalerHecZscalerHec TypeZscalerHec = "zscaler_hec"
)

func (e TypeZscalerHec) ToPointer() *TypeZscalerHec {
	return &e
}
func (e *TypeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "zscaler_hec":
		*e = TypeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeZscalerHec: %v", v)
	}
}

type ConnectionZscalerHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionZscalerHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionZscalerHec) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeZscalerHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeZscalerHec string

const (
	ModeZscalerHecSmart  ModeZscalerHec = "smart"
	ModeZscalerHecAlways ModeZscalerHec = "always"
)

func (e ModeZscalerHec) ToPointer() *ModeZscalerHec {
	return &e
}
func (e *ModeZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeZscalerHec: %v", v)
	}
}

// CompressionZscalerHec - Codec to use to compress the persisted data
type CompressionZscalerHec string

const (
	CompressionZscalerHecNone CompressionZscalerHec = "none"
	CompressionZscalerHecGzip CompressionZscalerHec = "gzip"
)

func (e CompressionZscalerHec) ToPointer() *CompressionZscalerHec {
	return &e
}
func (e *CompressionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionZscalerHec: %v", v)
	}
}

type PqZscalerHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeZscalerHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionZscalerHec `default:"none" json:"compress"`
}

func (p PqZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqZscalerHec) GetMode() *ModeZscalerHec {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqZscalerHec) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqZscalerHec) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqZscalerHec) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqZscalerHec) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqZscalerHec) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqZscalerHec) GetCompress() *CompressionZscalerHec {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodZscalerHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodZscalerHec string

const (
	AuthenticationMethodZscalerHecManual AuthenticationMethodZscalerHec = "manual"
	AuthenticationMethodZscalerHecSecret AuthenticationMethodZscalerHec = "secret"
)

func (e AuthenticationMethodZscalerHec) ToPointer() *AuthenticationMethodZscalerHec {
	return &e
}
func (e *AuthenticationMethodZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodZscalerHec: %v", v)
	}
}

type AuthTokenMetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokenMetadatumZscalerHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokenMetadatumZscalerHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenZscalerHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodZscalerHec `default:"manual" json:"authType"`
	TokenSecret any                             `json:"tokenSecret,omitempty"`
	Token       any                             `json:"token"`
	Enabled     *bool                           `default:"true" json:"enabled"`
	Description *string                         `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumZscalerHec `json:"metadata,omitempty"`
}

func (a AuthTokenZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthTokenZscalerHec) GetAuthType() *AuthenticationMethodZscalerHec {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *AuthTokenZscalerHec) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *AuthTokenZscalerHec) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *AuthTokenZscalerHec) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *AuthTokenZscalerHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokenZscalerHec) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *AuthTokenZscalerHec) GetMetadata() []AuthTokenMetadatumZscalerHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

// MinimumTLSVersionZscalerHec - Minimum TLS version to accept from connections
type MinimumTLSVersionZscalerHec string

const (
	MinimumTLSVersionZscalerHecTlSv1  MinimumTLSVersionZscalerHec = "TLSv1"
	MinimumTLSVersionZscalerHecTlSv11 MinimumTLSVersionZscalerHec = "TLSv1.1"
	MinimumTLSVersionZscalerHecTlSv12 MinimumTLSVersionZscalerHec = "TLSv1.2"
	MinimumTLSVersionZscalerHecTlSv13 MinimumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MinimumTLSVersionZscalerHec) ToPointer() *MinimumTLSVersionZscalerHec {
	return &e
}
func (e *MinimumTLSVersionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionZscalerHec: %v", v)
	}
}

// MaximumTLSVersionZscalerHec - Maximum TLS version to accept from connections
type MaximumTLSVersionZscalerHec string

const (
	MaximumTLSVersionZscalerHecTlSv1  MaximumTLSVersionZscalerHec = "TLSv1"
	MaximumTLSVersionZscalerHecTlSv11 MaximumTLSVersionZscalerHec = "TLSv1.1"
	MaximumTLSVersionZscalerHecTlSv12 MaximumTLSVersionZscalerHec = "TLSv1.2"
	MaximumTLSVersionZscalerHecTlSv13 MaximumTLSVersionZscalerHec = "TLSv1.3"
)

func (e MaximumTLSVersionZscalerHec) ToPointer() *MaximumTLSVersionZscalerHec {
	return &e
}
func (e *MaximumTLSVersionZscalerHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionZscalerHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionZscalerHec: %v", v)
	}
}

type TLSSettingsServerSideZscalerHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionZscalerHec `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionZscalerHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideZscalerHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideZscalerHec) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideZscalerHec) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideZscalerHec) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideZscalerHec) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideZscalerHec) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideZscalerHec) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideZscalerHec) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideZscalerHec) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideZscalerHec) GetMinVersion() *MinimumTLSVersionZscalerHec {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideZscalerHec) GetMaxVersion() *MaximumTLSVersionZscalerHec {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumZscalerHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumZscalerHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumZscalerHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputZscalerHec struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     *TypeZscalerHec `json:"type,omitempty"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionZscalerHec `json:"connections,omitempty"`
	Pq          *PqZscalerHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenZscalerHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideZscalerHec `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Zscaler HTTP Event Collector API requests. This input supports the /event endpoint.
	HecAPI *string `default:"/services/collector" json:"hecAPI"`
	// Fields to add to every event. May be overridden by fields added at the token or request level.
	Metadata []MetadatumZscalerHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Whether to enable zscaler HEC acknowledgements
	HecAcks *bool `default:"false" json:"hecAcks"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Enable to emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool     `default:"false" json:"emitTokenMetrics"`
	Description      *string   `json:"description,omitempty"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputZscalerHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputZscalerHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputZscalerHec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputZscalerHec) GetType() *TypeZscalerHec {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputZscalerHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputZscalerHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputZscalerHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputZscalerHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputZscalerHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputZscalerHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputZscalerHec) GetConnections() []ConnectionZscalerHec {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputZscalerHec) GetPq() *PqZscalerHec {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputZscalerHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputZscalerHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputZscalerHec) GetAuthTokens() []AuthTokenZscalerHec {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputZscalerHec) GetTLS() *TLSSettingsServerSideZscalerHec {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputZscalerHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputZscalerHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputZscalerHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputZscalerHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputZscalerHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputZscalerHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputZscalerHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputZscalerHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputZscalerHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputZscalerHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputZscalerHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputZscalerHec) GetHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.HecAPI
}

func (o *InputZscalerHec) GetMetadata() []MetadatumZscalerHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputZscalerHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputZscalerHec) GetHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.HecAcks
}

func (o *InputZscalerHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputZscalerHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputZscalerHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputZscalerHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputZscalerHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeSecurityLake string

const (
	InputTypeSecurityLakeSecurityLake InputTypeSecurityLake = "security_lake"
)

func (e InputTypeSecurityLake) ToPointer() *InputTypeSecurityLake {
	return &e
}
func (e *InputTypeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = InputTypeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSecurityLake: %v", v)
	}
}

type ConnectionSecurityLake struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSecurityLake) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSecurityLake - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSecurityLake string

const (
	ModeSecurityLakeSmart  ModeSecurityLake = "smart"
	ModeSecurityLakeAlways ModeSecurityLake = "always"
)

func (e ModeSecurityLake) ToPointer() *ModeSecurityLake {
	return &e
}
func (e *ModeSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSecurityLake: %v", v)
	}
}

// CompressionSecurityLake - Codec to use to compress the persisted data
type CompressionSecurityLake string

const (
	CompressionSecurityLakeNone CompressionSecurityLake = "none"
	CompressionSecurityLakeGzip CompressionSecurityLake = "gzip"
)

func (e CompressionSecurityLake) ToPointer() *CompressionSecurityLake {
	return &e
}
func (e *CompressionSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSecurityLake: %v", v)
	}
}

type PqSecurityLake struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSecurityLake `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSecurityLake `default:"none" json:"compress"`
}

func (p PqSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSecurityLake) GetMode() *ModeSecurityLake {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSecurityLake) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSecurityLake) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSecurityLake) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSecurityLake) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSecurityLake) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSecurityLake) GetCompress() *CompressionSecurityLake {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputAuthenticationMethodSecurityLake - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodSecurityLake string

const (
	InputAuthenticationMethodSecurityLakeAuto   InputAuthenticationMethodSecurityLake = "auto"
	InputAuthenticationMethodSecurityLakeManual InputAuthenticationMethodSecurityLake = "manual"
	InputAuthenticationMethodSecurityLakeSecret InputAuthenticationMethodSecurityLake = "secret"
)

func (e InputAuthenticationMethodSecurityLake) ToPointer() *InputAuthenticationMethodSecurityLake {
	return &e
}
func (e *InputAuthenticationMethodSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodSecurityLake: %v", v)
	}
}

// InputSignatureVersionSecurityLake - Signature version to use for signing S3 requests
type InputSignatureVersionSecurityLake string

const (
	InputSignatureVersionSecurityLakeV2 InputSignatureVersionSecurityLake = "v2"
	InputSignatureVersionSecurityLakeV4 InputSignatureVersionSecurityLake = "v4"
)

func (e InputSignatureVersionSecurityLake) ToPointer() *InputSignatureVersionSecurityLake {
	return &e
}
func (e *InputSignatureVersionSecurityLake) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSignatureVersionSecurityLake(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSignatureVersionSecurityLake: %v", v)
	}
}

type PreprocessSecurityLake struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessSecurityLake) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessSecurityLake) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessSecurityLake) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumSecurityLake struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSecurityLake) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSecurityLake) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingSecurityLake struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingSecurityLake) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingSecurityLake) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputSecurityLake struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     InputTypeSecurityLake `json:"type"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSecurityLake `json:"connections,omitempty"`
	Pq          *PqSecurityLake          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodSecurityLake `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputSignatureVersionSecurityLake `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                   `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessSecurityLake `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumSecurityLake `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                   `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingSecurityLake `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputSecurityLake) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSecurityLake) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSecurityLake) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSecurityLake) GetType() InputTypeSecurityLake {
	if o == nil {
		return InputTypeSecurityLake("")
	}
	return o.Type
}

func (o *InputSecurityLake) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSecurityLake) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSecurityLake) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSecurityLake) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSecurityLake) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSecurityLake) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSecurityLake) GetConnections() []ConnectionSecurityLake {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSecurityLake) GetPq() *PqSecurityLake {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSecurityLake) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSecurityLake) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputSecurityLake) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSecurityLake) GetAwsAuthenticationMethod() *InputAuthenticationMethodSecurityLake {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSecurityLake) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSecurityLake) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSecurityLake) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSecurityLake) GetSignatureVersion() *InputSignatureVersionSecurityLake {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSecurityLake) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSecurityLake) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSecurityLake) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSecurityLake) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSecurityLake) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSecurityLake) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSecurityLake) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputSecurityLake) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSecurityLake) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputSecurityLake) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSecurityLake) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSecurityLake) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSecurityLake) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSecurityLake) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputSecurityLake) GetPreprocess() *PreprocessSecurityLake {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputSecurityLake) GetMetadata() []MetadatumSecurityLake {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSecurityLake) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputSecurityLake) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputSecurityLake) GetCheckpointing() *CheckpointingSecurityLake {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputSecurityLake) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSecurityLake) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSecurityLake) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSecurityLake) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSecurityLake) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSecurityLake) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeNetflow string

const (
	InputTypeNetflowNetflow InputTypeNetflow = "netflow"
)

func (e InputTypeNetflow) ToPointer() *InputTypeNetflow {
	return &e
}
func (e *InputTypeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "netflow":
		*e = InputTypeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeNetflow: %v", v)
	}
}

type ConnectionNetflow struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionNetflow) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeNetflow - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeNetflow string

const (
	ModeNetflowSmart  ModeNetflow = "smart"
	ModeNetflowAlways ModeNetflow = "always"
)

func (e ModeNetflow) ToPointer() *ModeNetflow {
	return &e
}
func (e *ModeNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeNetflow: %v", v)
	}
}

// CompressionNetflow - Codec to use to compress the persisted data
type CompressionNetflow string

const (
	CompressionNetflowNone CompressionNetflow = "none"
	CompressionNetflowGzip CompressionNetflow = "gzip"
)

func (e CompressionNetflow) ToPointer() *CompressionNetflow {
	return &e
}
func (e *CompressionNetflow) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionNetflow(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionNetflow: %v", v)
	}
}

type PqNetflow struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeNetflow `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionNetflow `default:"none" json:"compress"`
}

func (p PqNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqNetflow) GetMode() *ModeNetflow {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqNetflow) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqNetflow) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqNetflow) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqNetflow) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqNetflow) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqNetflow) GetCompress() *CompressionNetflow {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumNetflow struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumNetflow) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumNetflow) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputNetflow struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputTypeNetflow `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionNetflow `json:"connections,omitempty"`
	Pq          *PqNetflow          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"2055" json:"port"`
	// Allow forwarding of events to a NetFlow destination. Enabling this feature will generate an extra event containing __netflowRaw which can be routed to a NetFlow destination. Note that these events will not count against ingest quota.
	EnablePassThrough *bool `default:"false" json:"enablePassThrough"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Specifies how many minutes NetFlow v9 templates are cached before being discarded if not refreshed. Adjust based on your network's template update frequency to optimize performance and memory usage.
	TemplateCacheMinutes *float64 `default:"30" json:"templateCacheMinutes"`
	// Accept messages in Netflow V5 format.
	V5Enabled *bool `default:"true" json:"v5Enabled"`
	// Accept messages in Netflow V9 format.
	V9Enabled *bool `default:"true" json:"v9Enabled"`
	// Accept messages in IPFIX format.
	IpfixEnabled *bool `default:"false" json:"ipfixEnabled"`
	// Fields to add to events from this input
	Metadata    []MetadatumNetflow `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	Status      *TFStatus          `json:"status,omitempty"`
}

func (i InputNetflow) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputNetflow) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputNetflow) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputNetflow) GetType() *InputTypeNetflow {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputNetflow) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputNetflow) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputNetflow) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputNetflow) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputNetflow) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputNetflow) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputNetflow) GetConnections() []ConnectionNetflow {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputNetflow) GetPq() *PqNetflow {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputNetflow) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputNetflow) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputNetflow) GetEnablePassThrough() *bool {
	if o == nil {
		return nil
	}
	return o.EnablePassThrough
}

func (o *InputNetflow) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputNetflow) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputNetflow) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputNetflow) GetTemplateCacheMinutes() *float64 {
	if o == nil {
		return nil
	}
	return o.TemplateCacheMinutes
}

func (o *InputNetflow) GetV5Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V5Enabled
}

func (o *InputNetflow) GetV9Enabled() *bool {
	if o == nil {
		return nil
	}
	return o.V9Enabled
}

func (o *InputNetflow) GetIpfixEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.IpfixEnabled
}

func (o *InputNetflow) GetMetadata() []MetadatumNetflow {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputNetflow) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputNetflow) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeWiz string

const (
	TypeWizWiz TypeWiz = "wiz"
)

func (e TypeWiz) ToPointer() *TypeWiz {
	return &e
}
func (e *TypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wiz":
		*e = TypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWiz: %v", v)
	}
}

type ConnectionWiz struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWiz) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWiz) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWiz - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWiz string

const (
	ModeWizSmart  ModeWiz = "smart"
	ModeWizAlways ModeWiz = "always"
)

func (e ModeWiz) ToPointer() *ModeWiz {
	return &e
}
func (e *ModeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWiz: %v", v)
	}
}

// CompressionWiz - Codec to use to compress the persisted data
type CompressionWiz string

const (
	CompressionWizNone CompressionWiz = "none"
	CompressionWizGzip CompressionWiz = "gzip"
)

func (e CompressionWiz) ToPointer() *CompressionWiz {
	return &e
}
func (e *CompressionWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWiz: %v", v)
	}
}

type PqWiz struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWiz `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWiz `default:"none" json:"compress"`
}

func (p PqWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWiz) GetMode() *ModeWiz {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWiz) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWiz) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWiz) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWiz) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWiz) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWiz) GetCompress() *CompressionWiz {
	if o == nil {
		return nil
	}
	return o.Compress
}

type ContentConfigWiz struct {
	// The name of the Wiz query
	ContentType        string  `json:"contentType"`
	ContentDescription *string `json:"contentDescription,omitempty"`
	Enabled            *bool   `default:"false" json:"enabled"`
}

func (c ContentConfigWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *ContentConfigWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ContentConfigWiz) GetContentType() string {
	if o == nil {
		return ""
	}
	return o.ContentType
}

func (o *ContentConfigWiz) GetContentDescription() *string {
	if o == nil {
		return nil
	}
	return o.ContentDescription
}

func (o *ContentConfigWiz) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

type MetadatumWiz struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWiz) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWiz) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeWiz - The algorithm to use when performing HTTP retries
type RetryTypeWiz string

const (
	RetryTypeWizNone    RetryTypeWiz = "none"
	RetryTypeWizBackoff RetryTypeWiz = "backoff"
	RetryTypeWizStatic  RetryTypeWiz = "static"
)

func (e RetryTypeWiz) ToPointer() *RetryTypeWiz {
	return &e
}
func (e *RetryTypeWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeWiz: %v", v)
	}
}

type RetryRulesWiz struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeWiz `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesWiz) GetType() *RetryTypeWiz {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesWiz) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesWiz) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesWiz) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesWiz) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesWiz) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesWiz) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesWiz) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodWiz - Enter client secret directly, or select a stored secret
type AuthenticationMethodWiz string

const (
	AuthenticationMethodWizManual AuthenticationMethodWiz = "manual"
	AuthenticationMethodWizSecret AuthenticationMethodWiz = "secret"
)

func (e AuthenticationMethodWiz) ToPointer() *AuthenticationMethodWiz {
	return &e
}
func (e *AuthenticationMethodWiz) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodWiz(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodWiz: %v", v)
	}
}

type InputWiz struct {
	// Unique ID for this input
	ID       *string  `json:"id,omitempty"`
	Type     *TypeWiz `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWiz `json:"connections,omitempty"`
	Pq          *PqWiz          `json:"pq,omitempty"`
	// The Wiz GraphQL API endpoint. Example: https://api.us1.app.wiz.io/graphql
	Endpoint *string `default:"https://api.<region>.app.wiz.io/graphql" json:"endpoint"`
	// The authentication URL to generate an OAuth token
	AuthURL string `json:"authUrl"`
	// The audience to use when requesting an OAuth token for a custom auth URL. When not specified, `wiz-api` will be used.
	AuthAudienceOverride *string `json:"authAudienceOverride,omitempty"`
	// The client ID of the Wiz application
	ClientID      string             `json:"clientId"`
	ContentConfig []ContentConfigWiz `json:"contentConfig,omitempty"`
	// HTTP request inactivity timeout. Use 0 to disable.
	RequestTimeout *float64 `default:"300" json:"requestTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata   []MetadatumWiz `json:"metadata,omitempty"`
	RetryRules *RetryRulesWiz `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodWiz `default:"manual" json:"authType"`
	Description *string                  `json:"description,omitempty"`
	// The client secret of the Wiz application
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputWiz) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWiz) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWiz) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWiz) GetType() *TypeWiz {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWiz) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWiz) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWiz) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWiz) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWiz) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWiz) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWiz) GetConnections() []ConnectionWiz {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWiz) GetPq() *PqWiz {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWiz) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputWiz) GetAuthURL() string {
	if o == nil {
		return ""
	}
	return o.AuthURL
}

func (o *InputWiz) GetAuthAudienceOverride() *string {
	if o == nil {
		return nil
	}
	return o.AuthAudienceOverride
}

func (o *InputWiz) GetClientID() string {
	if o == nil {
		return ""
	}
	return o.ClientID
}

func (o *InputWiz) GetContentConfig() []ContentConfigWiz {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputWiz) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputWiz) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputWiz) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputWiz) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputWiz) GetMetadata() []MetadatumWiz {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWiz) GetRetryRules() *RetryRulesWiz {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputWiz) GetAuthType() *AuthenticationMethodWiz {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputWiz) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWiz) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputWiz) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputWiz) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputJournalFilesType string

const (
	InputJournalFilesTypeJournalFiles InputJournalFilesType = "journal_files"
)

func (e InputJournalFilesType) ToPointer() *InputJournalFilesType {
	return &e
}
func (e *InputJournalFilesType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "journal_files":
		*e = InputJournalFilesType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesType: %v", v)
	}
}

type InputJournalFilesConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputJournalFilesConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFilesConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputJournalFilesMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputJournalFilesMode string

const (
	InputJournalFilesModeSmart  InputJournalFilesMode = "smart"
	InputJournalFilesModeAlways InputJournalFilesMode = "always"
)

func (e InputJournalFilesMode) ToPointer() *InputJournalFilesMode {
	return &e
}
func (e *InputJournalFilesMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputJournalFilesMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesMode: %v", v)
	}
}

// InputJournalFilesCompression - Codec to use to compress the persisted data
type InputJournalFilesCompression string

const (
	InputJournalFilesCompressionNone InputJournalFilesCompression = "none"
	InputJournalFilesCompressionGzip InputJournalFilesCompression = "gzip"
)

func (e InputJournalFilesCompression) ToPointer() *InputJournalFilesCompression {
	return &e
}
func (e *InputJournalFilesCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputJournalFilesCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesCompression: %v", v)
	}
}

type InputJournalFilesPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputJournalFilesMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputJournalFilesCompression `default:"none" json:"compress"`
}

func (i InputJournalFilesPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFilesPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFilesPq) GetMode() *InputJournalFilesMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputJournalFilesPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputJournalFilesPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputJournalFilesPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputJournalFilesPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputJournalFilesPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputJournalFilesPq) GetCompress() *InputJournalFilesCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputJournalFilesRule struct {
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *InputJournalFilesRule) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *InputJournalFilesRule) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputJournalFilesMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputJournalFilesMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputJournalFilesMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputJournalFiles struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputJournalFilesType `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputJournalFilesConnection `json:"connections,omitempty"`
	Pq          *InputJournalFilesPq          `json:"pq,omitempty"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Time, in seconds, between scanning for journals.
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals,omitempty"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputJournalFilesRule `json:"rules,omitempty"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `default:"false" json:"currentBoot"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputJournalFilesMetadatum `json:"metadata,omitempty"`
	Description *string                      `json:"description,omitempty"`
	Status      *TFStatus                    `json:"status,omitempty"`
}

func (i InputJournalFiles) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputJournalFiles) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputJournalFiles) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputJournalFiles) GetType() *InputJournalFilesType {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputJournalFiles) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputJournalFiles) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputJournalFiles) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputJournalFiles) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputJournalFiles) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputJournalFiles) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputJournalFiles) GetConnections() []InputJournalFilesConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputJournalFiles) GetPq() *InputJournalFilesPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputJournalFiles) GetPath() string {
	if o == nil {
		return ""
	}
	return o.Path
}

func (o *InputJournalFiles) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputJournalFiles) GetJournals() []string {
	if o == nil {
		return nil
	}
	return o.Journals
}

func (o *InputJournalFiles) GetRules() []InputJournalFilesRule {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputJournalFiles) GetCurrentBoot() *bool {
	if o == nil {
		return nil
	}
	return o.CurrentBoot
}

func (o *InputJournalFiles) GetMaxAgeDur() *string {
	if o == nil {
		return nil
	}
	return o.MaxAgeDur
}

func (o *InputJournalFiles) GetMetadata() []InputJournalFilesMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputJournalFiles) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputJournalFiles) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeRawUDP string

const (
	TypeRawUDPRawUDP TypeRawUDP = "raw_udp"
)

func (e TypeRawUDP) ToPointer() *TypeRawUDP {
	return &e
}
func (e *TypeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "raw_udp":
		*e = TypeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeRawUDP: %v", v)
	}
}

type ConnectionRawUDP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionRawUDP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionRawUDP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeRawUDP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeRawUDP string

const (
	ModeRawUDPSmart  ModeRawUDP = "smart"
	ModeRawUDPAlways ModeRawUDP = "always"
)

func (e ModeRawUDP) ToPointer() *ModeRawUDP {
	return &e
}
func (e *ModeRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeRawUDP: %v", v)
	}
}

// CompressionRawUDP - Codec to use to compress the persisted data
type CompressionRawUDP string

const (
	CompressionRawUDPNone CompressionRawUDP = "none"
	CompressionRawUDPGzip CompressionRawUDP = "gzip"
)

func (e CompressionRawUDP) ToPointer() *CompressionRawUDP {
	return &e
}
func (e *CompressionRawUDP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionRawUDP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionRawUDP: %v", v)
	}
}

type PqRawUDP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeRawUDP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionRawUDP `default:"none" json:"compress"`
}

func (p PqRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqRawUDP) GetMode() *ModeRawUDP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqRawUDP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqRawUDP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqRawUDP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqRawUDP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqRawUDP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqRawUDP) GetCompress() *CompressionRawUDP {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumRawUDP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumRawUDP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumRawUDP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputRawUDP struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     *TypeRawUDP `json:"type,omitempty"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionRawUDP `json:"connections,omitempty"`
	Pq          *PqRawUDP          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// If true, each UDP packet is assumed to contain a single message. If false, each UDP packet is assumed to contain multiple messages, separated by newlines.
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// If true, a __rawBytes field will be added to each event containing the raw bytes of the datagram.
	IngestRawBytes *bool `default:"false" json:"ingestRawBytes"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumRawUDP `json:"metadata,omitempty"`
	Description *string           `json:"description,omitempty"`
	Status      *TFStatus         `json:"status,omitempty"`
}

func (i InputRawUDP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRawUDP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputRawUDP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputRawUDP) GetType() *TypeRawUDP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputRawUDP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputRawUDP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputRawUDP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputRawUDP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputRawUDP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputRawUDP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputRawUDP) GetConnections() []ConnectionRawUDP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputRawUDP) GetPq() *PqRawUDP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputRawUDP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputRawUDP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputRawUDP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputRawUDP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputRawUDP) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputRawUDP) GetIngestRawBytes() *bool {
	if o == nil {
		return nil
	}
	return o.IngestRawBytes
}

func (o *InputRawUDP) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputRawUDP) GetMetadata() []MetadatumRawUDP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputRawUDP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputRawUDP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeWinEventLogs string

const (
	TypeWinEventLogsWinEventLogs TypeWinEventLogs = "win_event_logs"
)

func (e TypeWinEventLogs) ToPointer() *TypeWinEventLogs {
	return &e
}
func (e *TypeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "win_event_logs":
		*e = TypeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWinEventLogs: %v", v)
	}
}

type ConnectionWinEventLogs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWinEventLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWinEventLogs) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWinEventLogs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWinEventLogs string

const (
	ModeWinEventLogsSmart  ModeWinEventLogs = "smart"
	ModeWinEventLogsAlways ModeWinEventLogs = "always"
)

func (e ModeWinEventLogs) ToPointer() *ModeWinEventLogs {
	return &e
}
func (e *ModeWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWinEventLogs: %v", v)
	}
}

// CompressionWinEventLogs - Codec to use to compress the persisted data
type CompressionWinEventLogs string

const (
	CompressionWinEventLogsNone CompressionWinEventLogs = "none"
	CompressionWinEventLogsGzip CompressionWinEventLogs = "gzip"
)

func (e CompressionWinEventLogs) ToPointer() *CompressionWinEventLogs {
	return &e
}
func (e *CompressionWinEventLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWinEventLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWinEventLogs: %v", v)
	}
}

type PqWinEventLogs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWinEventLogs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWinEventLogs `default:"none" json:"compress"`
}

func (p PqWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWinEventLogs) GetMode() *ModeWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWinEventLogs) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWinEventLogs) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWinEventLogs) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWinEventLogs) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWinEventLogs) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWinEventLogs) GetCompress() *CompressionWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ReadMode - Read all stored and future event logs, or only future events
type ReadMode string

const (
	ReadModeOldest ReadMode = "oldest"
	ReadModeNewest ReadMode = "newest"
)

func (e ReadMode) ToPointer() *ReadMode {
	return &e
}
func (e *ReadMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "oldest":
		fallthrough
	case "newest":
		*e = ReadMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ReadMode: %v", v)
	}
}

// EventFormat - Format of individual events
type EventFormat string

const (
	EventFormatJSON EventFormat = "json"
	EventFormatXML  EventFormat = "xml"
)

func (e EventFormat) ToPointer() *EventFormat {
	return &e
}
func (e *EventFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "xml":
		*e = EventFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for EventFormat: %v", v)
	}
}

type MetadatumWinEventLogs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWinEventLogs) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWinEventLogs) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWinEventLogs struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     TypeWinEventLogs `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWinEventLogs `json:"connections,omitempty"`
	Pq          *PqWinEventLogs          `json:"pq,omitempty"`
	// Enter the event logs to collect. Run "Get-WinEvent -ListLog *" in PowerShell to see the available logs.
	LogNames []string `json:"logNames,omitempty"`
	// Read all stored and future event logs, or only future events
	ReadMode *ReadMode `default:"oldest" json:"readMode"`
	// Format of individual events
	EventFormat *EventFormat `default:"json" json:"eventFormat"`
	// Enable to use built-in tools (PowerShell for JSON, wevtutil for XML) to collect event logs instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-event-logs/#advanced-settings)
	DisableNativeModule *bool `default:"false" json:"disableNativeModule"`
	// Time, in seconds, between checking for new entries (Applicable for pre-4.8.0 nodes that use Windows Tools)
	Interval *float64 `default:"10" json:"interval"`
	// The maximum number of events to read in one polling interval. A batch size higher than 500 can cause delays when pulling from multiple event logs. (Applicable for pre-4.8.0 nodes that use Windows Tools)
	BatchSize *float64 `default:"500" json:"batchSize"`
	// Fields to add to events from this input
	Metadata []MetadatumWinEventLogs `json:"metadata,omitempty"`
	// The maximum number of bytes in an event before it is flushed to the pipelines
	MaxEventBytes *float64  `default:"51200" json:"maxEventBytes"`
	Description   *string   `json:"description,omitempty"`
	Status        *TFStatus `json:"status,omitempty"`
}

func (i InputWinEventLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWinEventLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWinEventLogs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWinEventLogs) GetType() TypeWinEventLogs {
	if o == nil {
		return TypeWinEventLogs("")
	}
	return o.Type
}

func (o *InputWinEventLogs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWinEventLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWinEventLogs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWinEventLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWinEventLogs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWinEventLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWinEventLogs) GetConnections() []ConnectionWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWinEventLogs) GetPq() *PqWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWinEventLogs) GetLogNames() []string {
	if o == nil {
		return nil
	}
	return o.LogNames
}

func (o *InputWinEventLogs) GetReadMode() *ReadMode {
	if o == nil {
		return nil
	}
	return o.ReadMode
}

func (o *InputWinEventLogs) GetEventFormat() *EventFormat {
	if o == nil {
		return nil
	}
	return o.EventFormat
}

func (o *InputWinEventLogs) GetDisableNativeModule() *bool {
	if o == nil {
		return nil
	}
	return o.DisableNativeModule
}

func (o *InputWinEventLogs) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWinEventLogs) GetBatchSize() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchSize
}

func (o *InputWinEventLogs) GetMetadata() []MetadatumWinEventLogs {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWinEventLogs) GetMaxEventBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxEventBytes
}

func (o *InputWinEventLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWinEventLogs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeWef string

const (
	TypeWefWef TypeWef = "wef"
)

func (e TypeWef) ToPointer() *TypeWef {
	return &e
}
func (e *TypeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "wef":
		*e = TypeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWef: %v", v)
	}
}

type ConnectionWef struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWef) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWef) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeWef - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeWef string

const (
	ModeWefSmart  ModeWef = "smart"
	ModeWefAlways ModeWef = "always"
)

func (e ModeWef) ToPointer() *ModeWef {
	return &e
}
func (e *ModeWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeWef: %v", v)
	}
}

// CompressionWef - Codec to use to compress the persisted data
type CompressionWef string

const (
	CompressionWefNone CompressionWef = "none"
	CompressionWefGzip CompressionWef = "gzip"
)

func (e CompressionWef) ToPointer() *CompressionWef {
	return &e
}
func (e *CompressionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWef: %v", v)
	}
}

type PqWef struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeWef `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWef `default:"none" json:"compress"`
}

func (p PqWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWef) GetMode() *ModeWef {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWef) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWef) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWef) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWef) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWef) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWef) GetCompress() *CompressionWef {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthMethodAuthenticationMethod - Method by which to authenticate incoming client connections.
type AuthMethodAuthenticationMethod string

const (
	AuthMethodAuthenticationMethodClientCert AuthMethodAuthenticationMethod = "clientCert"
	AuthMethodAuthenticationMethodKerberos   AuthMethodAuthenticationMethod = "kerberos"
)

func (e AuthMethodAuthenticationMethod) ToPointer() *AuthMethodAuthenticationMethod {
	return &e
}
func (e *AuthMethodAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "clientCert":
		fallthrough
	case "kerberos":
		*e = AuthMethodAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthMethodAuthenticationMethod: %v", v)
	}
}

// MinimumTLSVersionWef - Minimum TLS version to accept from connections.
type MinimumTLSVersionWef string

const (
	MinimumTLSVersionWefTlSv1  MinimumTLSVersionWef = "TLSv1"
	MinimumTLSVersionWefTlSv11 MinimumTLSVersionWef = "TLSv1.1"
	MinimumTLSVersionWefTlSv12 MinimumTLSVersionWef = "TLSv1.2"
	MinimumTLSVersionWefTlSv13 MinimumTLSVersionWef = "TLSv1.3"
)

func (e MinimumTLSVersionWef) ToPointer() *MinimumTLSVersionWef {
	return &e
}
func (e *MinimumTLSVersionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionWef: %v", v)
	}
}

// MaximumTLSVersionWef - Maximum TLS version to accept from connections
type MaximumTLSVersionWef string

const (
	MaximumTLSVersionWefTlSv1  MaximumTLSVersionWef = "TLSv1"
	MaximumTLSVersionWefTlSv11 MaximumTLSVersionWef = "TLSv1.1"
	MaximumTLSVersionWefTlSv12 MaximumTLSVersionWef = "TLSv1.2"
	MaximumTLSVersionWefTlSv13 MaximumTLSVersionWef = "TLSv1.3"
)

func (e MaximumTLSVersionWef) ToPointer() *MaximumTLSVersionWef {
	return &e
}
func (e *MaximumTLSVersionWef) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionWef(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionWef: %v", v)
	}
}

type MTLSSettings struct {
	// Enable TLS
	Disabled *bool `default:"false" json:"disabled"`
	// Required for WEF certificate authentication.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Required for WEF certificate authentication.
	RequestCert *bool `default:"true" json:"requestCert"`
	// Name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
	// Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it.
	CaPath string `json:"caPath"`
	// Regex matching allowable common names in peer certificates' subject attribute.
	CommonNameRegex *string `default:"/.*/" json:"commonNameRegex"`
	// Minimum TLS version to accept from connections.
	MinVersion *MinimumTLSVersionWef `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionWef `json:"maxVersion,omitempty"`
	// Enable OCSP check of certificate
	OcspCheck *bool `default:"false" json:"ocspCheck"`
	Keytab    any   `json:"keytab,omitempty"`
	Principal any   `json:"principal,omitempty"`
	// If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors.
	OcspCheckFailClose *bool `default:"false" json:"ocspCheckFailClose"`
}

func (m MTLSSettings) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MTLSSettings) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *MTLSSettings) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *MTLSSettings) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *MTLSSettings) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *MTLSSettings) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *MTLSSettings) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *MTLSSettings) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *MTLSSettings) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

func (o *MTLSSettings) GetCaPath() string {
	if o == nil {
		return ""
	}
	return o.CaPath
}

func (o *MTLSSettings) GetCommonNameRegex() *string {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *MTLSSettings) GetMinVersion() *MinimumTLSVersionWef {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *MTLSSettings) GetMaxVersion() *MaximumTLSVersionWef {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

func (o *MTLSSettings) GetOcspCheck() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheck
}

func (o *MTLSSettings) GetKeytab() any {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *MTLSSettings) GetPrincipal() any {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *MTLSSettings) GetOcspCheckFailClose() *bool {
	if o == nil {
		return nil
	}
	return o.OcspCheckFailClose
}

// InputFormat - Content format in which the endpoint should deliver events.
type InputFormat string

const (
	InputFormatRaw          InputFormat = "Raw"
	InputFormatRenderedText InputFormat = "RenderedText"
)

func (e InputFormat) ToPointer() *InputFormat {
	return &e
}
func (e *InputFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Raw":
		fallthrough
	case "RenderedText":
		*e = InputFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFormat: %v", v)
	}
}

// QueryBuilderMode - Select the query builder mode.
type QueryBuilderMode string

const (
	QueryBuilderModeSimple QueryBuilderMode = "simple"
	QueryBuilderModeXML    QueryBuilderMode = "xml"
)

func (e QueryBuilderMode) ToPointer() *QueryBuilderMode {
	return &e
}
func (e *QueryBuilderMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "simple":
		fallthrough
	case "xml":
		*e = QueryBuilderMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for QueryBuilderMode: %v", v)
	}
}

type SubscriptionMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *SubscriptionMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SubscriptionMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSubscription struct {
	// Friendly name for this subscription.
	SubscriptionName string `json:"subscriptionName"`
	// Version UUID for this subscription. If any subscription parameters are modified, this value will change.
	Version *string `json:"version,omitempty"`
	// Content format in which the endpoint should deliver events.
	ContentFormat *InputFormat `default:"Raw" json:"contentFormat"`
	// Maximum time (in seconds) between endpoint checkins before considering it unavailable.
	HeartbeatInterval *float64 `default:"60" json:"heartbeatInterval"`
	// Interval (in seconds) over which the endpoint should collect events before sending them to Stream.
	BatchTimeout *float64 `default:"60" json:"batchTimeout"`
	// Set to Yes if a newly-subscribed endpoint should send previously existing events. Set to No to only receive new events
	ReadExistingEvents *bool `default:"false" json:"readExistingEvents"`
	// If toggled to Yes, @{product} will keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events' -- see the documentation for details.
	SendBookmarks *bool `default:"true" json:"sendBookmarks"`
	// If toggled to Yes, Stream will receive compressed events from the source.
	Compress *bool `default:"true" json:"compress"`
	// Enter the DNS names of the endpoints that should forward these events. You may use wildcards, for example: *.mydomain.com
	Targets []string `json:"targets,omitempty"`
	// The RFC-3066 locale the Windows clients should use when sending events. Defaults to "en-US".
	Locale *string `default:"en-US" json:"locale"`
	// Select the query builder mode.
	QuerySelector *QueryBuilderMode `default:"simple" json:"querySelector"`
	// Fields to add to events ingested under this subscription
	Metadata []SubscriptionMetadatum `json:"metadata,omitempty"`
}

func (i InputSubscription) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSubscription) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSubscription) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *InputSubscription) GetVersion() *string {
	if o == nil {
		return nil
	}
	return o.Version
}

func (o *InputSubscription) GetContentFormat() *InputFormat {
	if o == nil {
		return nil
	}
	return o.ContentFormat
}

func (o *InputSubscription) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputSubscription) GetBatchTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.BatchTimeout
}

func (o *InputSubscription) GetReadExistingEvents() *bool {
	if o == nil {
		return nil
	}
	return o.ReadExistingEvents
}

func (o *InputSubscription) GetSendBookmarks() *bool {
	if o == nil {
		return nil
	}
	return o.SendBookmarks
}

func (o *InputSubscription) GetCompress() *bool {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputSubscription) GetTargets() []string {
	if o == nil {
		return nil
	}
	return o.Targets
}

func (o *InputSubscription) GetLocale() *string {
	if o == nil {
		return nil
	}
	return o.Locale
}

func (o *InputSubscription) GetQuerySelector() *QueryBuilderMode {
	if o == nil {
		return nil
	}
	return o.QuerySelector
}

func (o *InputSubscription) GetMetadata() []SubscriptionMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type MetadatumWef struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWef) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWef) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputWef struct {
	// Unique ID for this input
	ID       *string  `json:"id,omitempty"`
	Type     *TypeWef `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWef `json:"connections,omitempty"`
	Pq          *PqWef          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64 `default:"5986" json:"port"`
	// Method by which to authenticate incoming client connections.
	AuthMethod *AuthMethodAuthenticationMethod `default:"clientCert" json:"authMethod"`
	TLS        *MTLSSettings                   `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"90" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain
	CaFingerprint *string `json:"caFingerprint,omitempty"`
	// Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided.
	Keytab *string `json:"keytab,omitempty"`
	// Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>.
	Principal *string `json:"principal,omitempty"`
	// Allow events to be ingested even if their MachineID does not match the client certificate CN.
	AllowMachineIDMismatch *bool `default:"false" json:"allowMachineIdMismatch"`
	// Subscriptions to events on forwarding endpoints.
	Subscriptions []InputSubscription `json:"subscriptions"`
	// Fields to add to events from this input
	Metadata    []MetadatumWef `json:"metadata,omitempty"`
	Description *string        `json:"description,omitempty"`
	Status      *TFStatus      `json:"status,omitempty"`
}

func (i InputWef) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWef) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWef) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputWef) GetType() *TypeWef {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputWef) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWef) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWef) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWef) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWef) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWef) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWef) GetConnections() []ConnectionWef {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWef) GetPq() *PqWef {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWef) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputWef) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputWef) GetAuthMethod() *AuthMethodAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthMethod
}

func (o *InputWef) GetTLS() *MTLSSettings {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputWef) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputWef) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputWef) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputWef) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputWef) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputWef) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputWef) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputWef) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputWef) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputWef) GetCaFingerprint() *string {
	if o == nil {
		return nil
	}
	return o.CaFingerprint
}

func (o *InputWef) GetKeytab() *string {
	if o == nil {
		return nil
	}
	return o.Keytab
}

func (o *InputWef) GetPrincipal() *string {
	if o == nil {
		return nil
	}
	return o.Principal
}

func (o *InputWef) GetAllowMachineIDMismatch() *bool {
	if o == nil {
		return nil
	}
	return o.AllowMachineIDMismatch
}

func (o *InputWef) GetSubscriptions() []InputSubscription {
	if o == nil {
		return []InputSubscription{}
	}
	return o.Subscriptions
}

func (o *InputWef) GetMetadata() []MetadatumWef {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWef) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWef) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeAppscope string

const (
	TypeAppscopeAppscope TypeAppscope = "appscope"
)

func (e TypeAppscope) ToPointer() *TypeAppscope {
	return &e
}
func (e *TypeAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "appscope":
		*e = TypeAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeAppscope: %v", v)
	}
}

type ConnectionAppscope struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionAppscope) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionAppscope) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeAppscope - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeAppscope string

const (
	ModeAppscopeSmart  ModeAppscope = "smart"
	ModeAppscopeAlways ModeAppscope = "always"
)

func (e ModeAppscope) ToPointer() *ModeAppscope {
	return &e
}
func (e *ModeAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeAppscope: %v", v)
	}
}

// CompressionAppscope - Codec to use to compress the persisted data
type CompressionAppscope string

const (
	CompressionAppscopeNone CompressionAppscope = "none"
	CompressionAppscopeGzip CompressionAppscope = "gzip"
)

func (e CompressionAppscope) ToPointer() *CompressionAppscope {
	return &e
}
func (e *CompressionAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionAppscope: %v", v)
	}
}

type PqAppscope struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeAppscope `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionAppscope `default:"none" json:"compress"`
}

func (p PqAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqAppscope) GetMode() *ModeAppscope {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqAppscope) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqAppscope) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqAppscope) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqAppscope) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqAppscope) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqAppscope) GetCompress() *CompressionAppscope {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumAppscope struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumAppscope) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumAppscope) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type Allow struct {
	// Specify the name of a process or family of processes.
	Procname string `json:"procname"`
	// Specify a string to substring-match against process command-line.
	Arg *string `json:"arg,omitempty"`
	// Choose a config to apply to processes that match the process name and/or argument.
	Config string `json:"config"`
}

func (o *Allow) GetProcname() string {
	if o == nil {
		return ""
	}
	return o.Procname
}

func (o *Allow) GetArg() *string {
	if o == nil {
		return nil
	}
	return o.Arg
}

func (o *Allow) GetConfig() string {
	if o == nil {
		return ""
	}
	return o.Config
}

type FilterAppscope struct {
	// Specify processes that AppScope should be loaded into, and the config to use.
	Allow []Allow `json:"allow,omitempty"`
	// To override the UNIX domain socket or address/port specified in General Settings (while leaving Authentication settings as is), enter a URL.
	TransportURL *string `json:"transportURL,omitempty"`
}

func (o *FilterAppscope) GetAllow() []Allow {
	if o == nil {
		return nil
	}
	return o.Allow
}

func (o *FilterAppscope) GetTransportURL() *string {
	if o == nil {
		return nil
	}
	return o.TransportURL
}

type DataCompressionFormatAppscope string

const (
	DataCompressionFormatAppscopeNone DataCompressionFormatAppscope = "none"
	DataCompressionFormatAppscopeGzip DataCompressionFormatAppscope = "gzip"
)

func (e DataCompressionFormatAppscope) ToPointer() *DataCompressionFormatAppscope {
	return &e
}
func (e *DataCompressionFormatAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormatAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormatAppscope: %v", v)
	}
}

type PersistenceAppscope struct {
	// Spool events and metrics on disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                        `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatAppscope `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/appscope
	DestPath *string `default:"\\$CRIBL_HOME/state/appscope" json:"destPath"`
}

func (p PersistenceAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PersistenceAppscope) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *PersistenceAppscope) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *PersistenceAppscope) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *PersistenceAppscope) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *PersistenceAppscope) GetCompress() *DataCompressionFormatAppscope {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *PersistenceAppscope) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

// AuthenticationMethodAppscope - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodAppscope string

const (
	AuthenticationMethodAppscopeManual AuthenticationMethodAppscope = "manual"
	AuthenticationMethodAppscopeSecret AuthenticationMethodAppscope = "secret"
)

func (e AuthenticationMethodAppscope) ToPointer() *AuthenticationMethodAppscope {
	return &e
}
func (e *AuthenticationMethodAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodAppscope: %v", v)
	}
}

// MinimumTLSVersionAppscope - Minimum TLS version to accept from connections
type MinimumTLSVersionAppscope string

const (
	MinimumTLSVersionAppscopeTlSv1  MinimumTLSVersionAppscope = "TLSv1"
	MinimumTLSVersionAppscopeTlSv11 MinimumTLSVersionAppscope = "TLSv1.1"
	MinimumTLSVersionAppscopeTlSv12 MinimumTLSVersionAppscope = "TLSv1.2"
	MinimumTLSVersionAppscopeTlSv13 MinimumTLSVersionAppscope = "TLSv1.3"
)

func (e MinimumTLSVersionAppscope) ToPointer() *MinimumTLSVersionAppscope {
	return &e
}
func (e *MinimumTLSVersionAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionAppscope: %v", v)
	}
}

// MaximumTLSVersionAppscope - Maximum TLS version to accept from connections
type MaximumTLSVersionAppscope string

const (
	MaximumTLSVersionAppscopeTlSv1  MaximumTLSVersionAppscope = "TLSv1"
	MaximumTLSVersionAppscopeTlSv11 MaximumTLSVersionAppscope = "TLSv1.1"
	MaximumTLSVersionAppscopeTlSv12 MaximumTLSVersionAppscope = "TLSv1.2"
	MaximumTLSVersionAppscopeTlSv13 MaximumTLSVersionAppscope = "TLSv1.3"
)

func (e MaximumTLSVersionAppscope) ToPointer() *MaximumTLSVersionAppscope {
	return &e
}
func (e *MaximumTLSVersionAppscope) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionAppscope(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionAppscope: %v", v)
	}
}

type TLSSettingsServerSideAppscope struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionAppscope `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionAppscope `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideAppscope) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideAppscope) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideAppscope) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideAppscope) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideAppscope) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideAppscope) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideAppscope) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideAppscope) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideAppscope) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideAppscope) GetMinVersion() *MinimumTLSVersionAppscope {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideAppscope) GetMaxVersion() *MaximumTLSVersionAppscope {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputAppscope struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeAppscope `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionAppscope `json:"connections,omitempty"`
	Pq          *PqAppscope          `json:"pq,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumAppscope `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Toggle to Yes to specify a file-backed UNIX domain socket connection, instead of a network host and port.
	EnableUnixPath *bool                `default:"false" json:"enableUnixPath"`
	Filter         *FilterAppscope      `json:"filter,omitempty"`
	Persistence    *PersistenceAppscope `json:"persistence,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthenticationMethodAppscope `default:"manual" json:"authType"`
	Description *string                       `json:"description,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `json:"host,omitempty"`
	// Port to listen on
	Port *float64                       `json:"port,omitempty"`
	TLS  *TLSSettingsServerSideAppscope `json:"tls,omitempty"`
	// Path to the UNIX domain socket to listen on.
	UnixSocketPath *string `default:"\\$CRIBL_HOME/state/appscope.sock" json:"unixSocketPath"`
	// Permissions to set for socket e.g., 777. If empty, falls back to the runtime user's default permissions.
	UnixSocketPerms *string `json:"unixSocketPerms,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputAppscope) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAppscope) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputAppscope) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputAppscope) GetType() TypeAppscope {
	if o == nil {
		return TypeAppscope("")
	}
	return o.Type
}

func (o *InputAppscope) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAppscope) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAppscope) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAppscope) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAppscope) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAppscope) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAppscope) GetConnections() []ConnectionAppscope {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAppscope) GetPq() *PqAppscope {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAppscope) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputAppscope) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputAppscope) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputAppscope) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputAppscope) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputAppscope) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputAppscope) GetMetadata() []MetadatumAppscope {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAppscope) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAppscope) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAppscope) GetEnableUnixPath() *bool {
	if o == nil {
		return nil
	}
	return o.EnableUnixPath
}

func (o *InputAppscope) GetFilter() *FilterAppscope {
	if o == nil {
		return nil
	}
	return o.Filter
}

func (o *InputAppscope) GetPersistence() *PersistenceAppscope {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputAppscope) GetAuthType() *AuthenticationMethodAppscope {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAppscope) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAppscope) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputAppscope) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputAppscope) GetTLS() *TLSSettingsServerSideAppscope {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputAppscope) GetUnixSocketPath() *string {
	if o == nil {
		return nil
	}
	return o.UnixSocketPath
}

func (o *InputAppscope) GetUnixSocketPerms() *string {
	if o == nil {
		return nil
	}
	return o.UnixSocketPerms
}

func (o *InputAppscope) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *InputAppscope) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAppscope) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeTCP string

const (
	TypeTCPTCP TypeTCP = "tcp"
)

func (e TypeTCP) ToPointer() *TypeTCP {
	return &e
}
func (e *TypeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcp":
		*e = TypeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeTCP: %v", v)
	}
}

type ConnectionTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionTCP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeTCP string

const (
	ModeTCPSmart  ModeTCP = "smart"
	ModeTCPAlways ModeTCP = "always"
)

func (e ModeTCP) ToPointer() *ModeTCP {
	return &e
}
func (e *ModeTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeTCP: %v", v)
	}
}

// CompressionTCP - Codec to use to compress the persisted data
type CompressionTCP string

const (
	CompressionTCPNone CompressionTCP = "none"
	CompressionTCPGzip CompressionTCP = "gzip"
)

func (e CompressionTCP) ToPointer() *CompressionTCP {
	return &e
}
func (e *CompressionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionTCP: %v", v)
	}
}

type PqTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionTCP `default:"none" json:"compress"`
}

func (p PqTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqTCP) GetMode() *ModeTCP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqTCP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqTCP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqTCP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqTCP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqTCP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqTCP) GetCompress() *CompressionTCP {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionTCP - Minimum TLS version to accept from connections
type MinimumTLSVersionTCP string

const (
	MinimumTLSVersionTCPTlSv1  MinimumTLSVersionTCP = "TLSv1"
	MinimumTLSVersionTCPTlSv11 MinimumTLSVersionTCP = "TLSv1.1"
	MinimumTLSVersionTCPTlSv12 MinimumTLSVersionTCP = "TLSv1.2"
	MinimumTLSVersionTCPTlSv13 MinimumTLSVersionTCP = "TLSv1.3"
)

func (e MinimumTLSVersionTCP) ToPointer() *MinimumTLSVersionTCP {
	return &e
}
func (e *MinimumTLSVersionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionTCP: %v", v)
	}
}

// MaximumTLSVersionTCP - Maximum TLS version to accept from connections
type MaximumTLSVersionTCP string

const (
	MaximumTLSVersionTCPTlSv1  MaximumTLSVersionTCP = "TLSv1"
	MaximumTLSVersionTCPTlSv11 MaximumTLSVersionTCP = "TLSv1.1"
	MaximumTLSVersionTCPTlSv12 MaximumTLSVersionTCP = "TLSv1.2"
	MaximumTLSVersionTCPTlSv13 MaximumTLSVersionTCP = "TLSv1.3"
)

func (e MaximumTLSVersionTCP) ToPointer() *MaximumTLSVersionTCP {
	return &e
}
func (e *MaximumTLSVersionTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionTCP: %v", v)
	}
}

type TLSSettingsServerSideTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionTCP `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideTCP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideTCP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideTCP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideTCP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideTCP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideTCP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideTCP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideTCP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideTCP) GetMinVersion() *MinimumTLSVersionTCP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideTCP) GetMaxVersion() *MaximumTLSVersionTCP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumTCP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumTCP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PreprocessTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessTCP) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessTCP) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

// AuthenticationMethodTCP - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthenticationMethodTCP string

const (
	AuthenticationMethodTCPManual AuthenticationMethodTCP = "manual"
	AuthenticationMethodTCPSecret AuthenticationMethodTCP = "secret"
)

func (e AuthenticationMethodTCP) ToPointer() *AuthenticationMethodTCP {
	return &e
}
func (e *AuthenticationMethodTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodTCP: %v", v)
	}
}

type InputTCP struct {
	Status *TFStatus `json:"status,omitempty"`
	// Unique ID for this input
	ID       *string  `json:"id,omitempty"`
	Type     *TypeTCP `json:"type,omitempty"`
	Disabled *bool    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTCP `json:"connections,omitempty"`
	Pq          *PqTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                   `json:"port"`
	TLS  *TLSSettingsServerSideTCP `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTCP `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Client will pass the header record with every new connection. The header can contain an authToken, and an object with a list of fields and values to add to every event. These fields can be used to simplify Event Breaker selection, routing, etc. Header has this format, and must be followed by a newline: { "authToken" : "myToken", "fields": { "field1": "value1", "field2": "value2" } }
	EnableHeader *bool          `default:"false" json:"enableHeader"`
	Preprocess   *PreprocessTCP `json:"preprocess,omitempty"`
	Description  *string        `json:"description,omitempty"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType *AuthenticationMethodTCP `default:"manual" json:"authType"`
}

func (i InputTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTCP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

func (o *InputTCP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputTCP) GetType() *TypeTCP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTCP) GetConnections() []ConnectionTCP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTCP) GetPq() *PqTCP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTCP) GetTLS() *TLSSettingsServerSideTCP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTCP) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTCP) GetMetadata() []MetadatumTCP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTCP) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputTCP) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputTCP) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *InputTCP) GetPreprocess() *PreprocessTCP {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTCP) GetAuthType() *AuthenticationMethodTCP {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputFileType string

const (
	InputFileTypeFile InputFileType = "file"
)

func (e InputFileType) ToPointer() *InputFileType {
	return &e
}
func (e *InputFileType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "file":
		*e = InputFileType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileType: %v", v)
	}
}

type InputFileConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputFileConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFileConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputFilePqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputFilePqMode string

const (
	InputFilePqModeSmart  InputFilePqMode = "smart"
	InputFilePqModeAlways InputFilePqMode = "always"
)

func (e InputFilePqMode) ToPointer() *InputFilePqMode {
	return &e
}
func (e *InputFilePqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputFilePqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFilePqMode: %v", v)
	}
}

// InputFileCompression - Codec to use to compress the persisted data
type InputFileCompression string

const (
	InputFileCompressionNone InputFileCompression = "none"
	InputFileCompressionGzip InputFileCompression = "gzip"
)

func (e InputFileCompression) ToPointer() *InputFileCompression {
	return &e
}
func (e *InputFileCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputFileCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileCompression: %v", v)
	}
}

type InputFilePq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputFilePqMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputFileCompression `default:"none" json:"compress"`
}

func (i InputFilePq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFilePq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputFilePq) GetMode() *InputFilePqMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputFilePq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputFilePq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputFilePq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputFilePq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputFilePq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputFilePq) GetCompress() *InputFileCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputFileMode - Choose how to discover files to monitor
type InputFileMode string

const (
	InputFileModeAuto   InputFileMode = "auto"
	InputFileModeManual InputFileMode = "manual"
)

func (e InputFileMode) ToPointer() *InputFileMode {
	return &e
}
func (e *InputFileMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		*e = InputFileMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputFileMode: %v", v)
	}
}

type InputFileMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputFileMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputFileMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputFile struct {
	// Unique ID for this input
	ID       string        `json:"id"`
	Type     InputFileType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputFileConnection `json:"connections,omitempty"`
	Pq          *InputFilePq          `json:"pq,omitempty"`
	// Choose how to discover files to monitor
	Mode *InputFileMode `default:"auto" json:"mode"`
	// Time, in seconds, between scanning for files
	Interval *float64 `default:"10" json:"interval"`
	// The full path of discovered files are matched against this wildcard list
	Filenames []string `json:"filenames,omitempty"`
	// Read only new entries at the end of all files discovered at next startup. @{product} will then read newly discovered files from the head. Disable this to resume reading all files from head.
	TailOnly *bool `default:"false" json:"tailOnly"`
	// Time, in seconds, before an idle file is closed
	IdleTimeout *float64 `default:"300" json:"idleTimeout"`
	// The maximum age of files to monitor. Format examples: 60s, 4h, 3d, 1w. Age is relative to file modification time. Leave empty to apply no age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Skip files with modification times earlier than the maximum age duration
	CheckFileModTime *bool `default:"false" json:"checkFileModTime"`
	// Forces files containing binary data to be streamed as text
	ForceText *bool `default:"false" json:"forceText"`
	// Length of file header bytes to use in hash for unique file identification
	HashLen *float64 `default:"256" json:"hashLen"`
	// Fields to add to events from this input
	Metadata []InputFileMetadatum `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	Description         *string  `json:"description,omitempty"`
	// Directory path to search for files. Environment variables will be resolved, e.g. $CRIBL_HOME/log/.
	Path *string `json:"path,omitempty"`
	// Set how many subdirectories deep to search. Use 0 to search only files in the given path, 1 to also look in its immediate subdirectories, etc. Leave it empty for unlimited depth.
	Depth                     *float64 `json:"depth,omitempty"`
	SuppressMissingPathErrors *bool    `default:"false" json:"suppressMissingPathErrors"`
	// Delete files after they have been collected
	DeleteFiles *bool `default:"false" json:"deleteFiles"`
	// Stream binary files as Base64-encoded chunks.
	IncludeUnidentifiableBinary *bool     `default:"false" json:"includeUnidentifiableBinary"`
	Status                      *TFStatus `json:"status,omitempty"`
}

func (i InputFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputFile) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputFile) GetType() InputFileType {
	if o == nil {
		return InputFileType("")
	}
	return o.Type
}

func (o *InputFile) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFile) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFile) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputFile) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputFile) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputFile) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputFile) GetConnections() []InputFileConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputFile) GetPq() *InputFilePq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputFile) GetMode() *InputFileMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputFile) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputFile) GetFilenames() []string {
	if o == nil {
		return nil
	}
	return o.Filenames
}

func (o *InputFile) GetTailOnly() *bool {
	if o == nil {
		return nil
	}
	return o.TailOnly
}

func (o *InputFile) GetIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.IdleTimeout
}

func (o *InputFile) GetMaxAgeDur() *string {
	if o == nil {
		return nil
	}
	return o.MaxAgeDur
}

func (o *InputFile) GetCheckFileModTime() *bool {
	if o == nil {
		return nil
	}
	return o.CheckFileModTime
}

func (o *InputFile) GetForceText() *bool {
	if o == nil {
		return nil
	}
	return o.ForceText
}

func (o *InputFile) GetHashLen() *float64 {
	if o == nil {
		return nil
	}
	return o.HashLen
}

func (o *InputFile) GetMetadata() []InputFileMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputFile) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputFile) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputFile) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputFile) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputFile) GetDepth() *float64 {
	if o == nil {
		return nil
	}
	return o.Depth
}

func (o *InputFile) GetSuppressMissingPathErrors() *bool {
	if o == nil {
		return nil
	}
	return o.SuppressMissingPathErrors
}

func (o *InputFile) GetDeleteFiles() *bool {
	if o == nil {
		return nil
	}
	return o.DeleteFiles
}

func (o *InputFile) GetIncludeUnidentifiableBinary() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeUnidentifiableBinary
}

func (o *InputFile) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSyslogType2 string

const (
	InputSyslogType2Syslog InputSyslogType2 = "syslog"
)

func (e InputSyslogType2) ToPointer() *InputSyslogType2 {
	return &e
}
func (e *InputSyslogType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType2: %v", v)
	}
}

type InputSyslogConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSyslogConnection2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogConnection2) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSyslogMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode2 string

const (
	InputSyslogMode2Smart  InputSyslogMode2 = "smart"
	InputSyslogMode2Always InputSyslogMode2 = "always"
)

func (e InputSyslogMode2) ToPointer() *InputSyslogMode2 {
	return &e
}
func (e *InputSyslogMode2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSyslogMode2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMode2: %v", v)
	}
}

// InputSyslogCompression2 - Codec to use to compress the persisted data
type InputSyslogCompression2 string

const (
	InputSyslogCompression2None InputSyslogCompression2 = "none"
	InputSyslogCompression2Gzip InputSyslogCompression2 = "gzip"
)

func (e InputSyslogCompression2) ToPointer() *InputSyslogCompression2 {
	return &e
}
func (e *InputSyslogCompression2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSyslogCompression2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogCompression2: %v", v)
	}
}

type InputSyslogPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSyslogCompression2 `default:"none" json:"compress"`
}

func (i InputSyslogPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogPq2) GetMode() *InputSyslogMode2 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSyslogPq2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogPq2) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSyslogPq2) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSyslogPq2) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSyslogPq2) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSyslogPq2) GetCompress() *InputSyslogCompression2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSyslogMinimumTLSVersion2 - Minimum TLS version to accept from connections
type InputSyslogMinimumTLSVersion2 string

const (
	InputSyslogMinimumTLSVersion2TlSv1  InputSyslogMinimumTLSVersion2 = "TLSv1"
	InputSyslogMinimumTLSVersion2TlSv11 InputSyslogMinimumTLSVersion2 = "TLSv1.1"
	InputSyslogMinimumTLSVersion2TlSv12 InputSyslogMinimumTLSVersion2 = "TLSv1.2"
	InputSyslogMinimumTLSVersion2TlSv13 InputSyslogMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion2) ToPointer() *InputSyslogMinimumTLSVersion2 {
	return &e
}
func (e *InputSyslogMinimumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMinimumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMinimumTLSVersion2: %v", v)
	}
}

// InputSyslogMaximumTLSVersion2 - Maximum TLS version to accept from connections
type InputSyslogMaximumTLSVersion2 string

const (
	InputSyslogMaximumTLSVersion2TlSv1  InputSyslogMaximumTLSVersion2 = "TLSv1"
	InputSyslogMaximumTLSVersion2TlSv11 InputSyslogMaximumTLSVersion2 = "TLSv1.1"
	InputSyslogMaximumTLSVersion2TlSv12 InputSyslogMaximumTLSVersion2 = "TLSv1.2"
	InputSyslogMaximumTLSVersion2TlSv13 InputSyslogMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion2) ToPointer() *InputSyslogMaximumTLSVersion2 {
	return &e
}
func (e *InputSyslogMaximumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMaximumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMaximumTLSVersion2: %v", v)
	}
}

type InputSyslogTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputSyslogMinimumTLSVersion2 `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputSyslogMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogTLSSettingsServerSide2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogTLSSettingsServerSide2) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSyslogTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSyslogTLSSettingsServerSide2) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSyslogTLSSettingsServerSide2) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSyslogTLSSettingsServerSide2) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSyslogTLSSettingsServerSide2) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSyslogTLSSettingsServerSide2) GetMinVersion() *InputSyslogMinimumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSyslogTLSSettingsServerSide2) GetMaxVersion() *InputSyslogMaximumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSyslogMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSyslogMetadatum2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSyslogMetadatum2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslogSyslog2 struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputSyslogType2 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection2 `json:"connections,omitempty"`
	Pq          *InputSyslogPq2          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort float64 `json:"tcpPort"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum2 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputSyslogSyslog2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogSyslog2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSyslogSyslog2) GetType() InputSyslogType2 {
	if o == nil {
		return InputSyslogType2("")
	}
	return o.Type
}

func (o *InputSyslogSyslog2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogSyslog2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogSyslog2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslogSyslog2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslogSyslog2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslogSyslog2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslogSyslog2) GetConnections() []InputSyslogConnection2 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslogSyslog2) GetPq() *InputSyslogPq2 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslogSyslog2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslogSyslog2) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputSyslogSyslog2) GetTCPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.TCPPort
}

func (o *InputSyslogSyslog2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogSyslog2) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslogSyslog2) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslogSyslog2) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslogSyslog2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslogSyslog2) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslogSyslog2) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslogSyslog2) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslogSyslog2) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslogSyslog2) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslogSyslog2) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslogSyslog2) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslogSyslog2) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslogSyslog2) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslogSyslog2) GetTLS() *InputSyslogTLSSettingsServerSide2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslogSyslog2) GetMetadata() []InputSyslogMetadatum2 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslogSyslog2) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslogSyslog2) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslogSyslog2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslogSyslog2) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSyslogType1 string

const (
	InputSyslogType1Syslog InputSyslogType1 = "syslog"
)

func (e InputSyslogType1) ToPointer() *InputSyslogType1 {
	return &e
}
func (e *InputSyslogType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "syslog":
		*e = InputSyslogType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogType1: %v", v)
	}
}

type InputSyslogConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputSyslogConnection1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogConnection1) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputSyslogMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputSyslogMode1 string

const (
	InputSyslogMode1Smart  InputSyslogMode1 = "smart"
	InputSyslogMode1Always InputSyslogMode1 = "always"
)

func (e InputSyslogMode1) ToPointer() *InputSyslogMode1 {
	return &e
}
func (e *InputSyslogMode1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputSyslogMode1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMode1: %v", v)
	}
}

// InputSyslogCompression1 - Codec to use to compress the persisted data
type InputSyslogCompression1 string

const (
	InputSyslogCompression1None InputSyslogCompression1 = "none"
	InputSyslogCompression1Gzip InputSyslogCompression1 = "gzip"
)

func (e InputSyslogCompression1) ToPointer() *InputSyslogCompression1 {
	return &e
}
func (e *InputSyslogCompression1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputSyslogCompression1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogCompression1: %v", v)
	}
}

type InputSyslogPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputSyslogMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputSyslogCompression1 `default:"none" json:"compress"`
}

func (i InputSyslogPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogPq1) GetMode() *InputSyslogMode1 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputSyslogPq1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogPq1) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputSyslogPq1) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputSyslogPq1) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputSyslogPq1) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputSyslogPq1) GetCompress() *InputSyslogCompression1 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputSyslogMinimumTLSVersion1 - Minimum TLS version to accept from connections
type InputSyslogMinimumTLSVersion1 string

const (
	InputSyslogMinimumTLSVersion1TlSv1  InputSyslogMinimumTLSVersion1 = "TLSv1"
	InputSyslogMinimumTLSVersion1TlSv11 InputSyslogMinimumTLSVersion1 = "TLSv1.1"
	InputSyslogMinimumTLSVersion1TlSv12 InputSyslogMinimumTLSVersion1 = "TLSv1.2"
	InputSyslogMinimumTLSVersion1TlSv13 InputSyslogMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMinimumTLSVersion1) ToPointer() *InputSyslogMinimumTLSVersion1 {
	return &e
}
func (e *InputSyslogMinimumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMinimumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMinimumTLSVersion1: %v", v)
	}
}

// InputSyslogMaximumTLSVersion1 - Maximum TLS version to accept from connections
type InputSyslogMaximumTLSVersion1 string

const (
	InputSyslogMaximumTLSVersion1TlSv1  InputSyslogMaximumTLSVersion1 = "TLSv1"
	InputSyslogMaximumTLSVersion1TlSv11 InputSyslogMaximumTLSVersion1 = "TLSv1.1"
	InputSyslogMaximumTLSVersion1TlSv12 InputSyslogMaximumTLSVersion1 = "TLSv1.2"
	InputSyslogMaximumTLSVersion1TlSv13 InputSyslogMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputSyslogMaximumTLSVersion1) ToPointer() *InputSyslogMaximumTLSVersion1 {
	return &e
}
func (e *InputSyslogMaximumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputSyslogMaximumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSyslogMaximumTLSVersion1: %v", v)
	}
}

type InputSyslogTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputSyslogMinimumTLSVersion1 `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputSyslogMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputSyslogTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogTLSSettingsServerSide1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogTLSSettingsServerSide1) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputSyslogTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputSyslogTLSSettingsServerSide1) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputSyslogTLSSettingsServerSide1) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputSyslogTLSSettingsServerSide1) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSyslogTLSSettingsServerSide1) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputSyslogTLSSettingsServerSide1) GetMinVersion() *InputSyslogMinimumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputSyslogTLSSettingsServerSide1) GetMaxVersion() *InputSyslogMaximumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputSyslogMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputSyslogMetadatum1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputSyslogMetadatum1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSyslogSyslog1 struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     InputSyslogType1 `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputSyslogConnection1 `json:"connections,omitempty"`
	Pq          *InputSyslogPq1          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort float64 `json:"udpPort"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Timezone to assign to timestamps without timezone info
	TimestampTimezone *string `default:"local" json:"timestampTimezone"`
	// Treat UDP packet data received as full syslog message
	SingleMsgUDPPackets *bool `default:"false" json:"singleMsgUdpPackets"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Wildcard list of fields to keep from source data; * = ALL (default)
	KeepFieldsList []string `json:"keepFieldsList,omitempty"`
	// Enable if incoming messages use octet counting per RFC 6587.
	OctetCounting *bool `default:"false" json:"octetCounting"`
	// Enable if we should infer the syslog framing of the incoming messages.
	InferFraming *bool `default:"true" json:"inferFraming"`
	// Enable if we should infer octet counting only if the messages comply with RFC 5424.
	StrictlyInferOctetCounting *bool `default:"true" json:"strictlyInferOctetCounting"`
	// Enable if RFC 3164-formatted messages have hyphens in the app name portion of the TAG section. If disabled, only alphanumeric characters and underscores are allowed. Ignored for RFC 5424-formatted messages.
	AllowNonStandardAppName *bool `default:"false" json:"allowNonStandardAppName"`
	// Maximum number of active connections allowed per Worker Process for TCP connections. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64                           `default:"0" json:"socketMaxLifespan"`
	TLS               *InputSyslogTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []InputSyslogMetadatum1 `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputSyslogSyslog1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSyslogSyslog1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSyslogSyslog1) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSyslogSyslog1) GetType() InputSyslogType1 {
	if o == nil {
		return InputSyslogType1("")
	}
	return o.Type
}

func (o *InputSyslogSyslog1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSyslogSyslog1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSyslogSyslog1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSyslogSyslog1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSyslogSyslog1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSyslogSyslog1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSyslogSyslog1) GetConnections() []InputSyslogConnection1 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSyslogSyslog1) GetPq() *InputSyslogPq1 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSyslogSyslog1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSyslogSyslog1) GetUDPPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.UDPPort
}

func (o *InputSyslogSyslog1) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputSyslogSyslog1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSyslogSyslog1) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSyslogSyslog1) GetTimestampTimezone() *string {
	if o == nil {
		return nil
	}
	return o.TimestampTimezone
}

func (o *InputSyslogSyslog1) GetSingleMsgUDPPackets() *bool {
	if o == nil {
		return nil
	}
	return o.SingleMsgUDPPackets
}

func (o *InputSyslogSyslog1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSyslogSyslog1) GetKeepFieldsList() []string {
	if o == nil {
		return nil
	}
	return o.KeepFieldsList
}

func (o *InputSyslogSyslog1) GetOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.OctetCounting
}

func (o *InputSyslogSyslog1) GetInferFraming() *bool {
	if o == nil {
		return nil
	}
	return o.InferFraming
}

func (o *InputSyslogSyslog1) GetStrictlyInferOctetCounting() *bool {
	if o == nil {
		return nil
	}
	return o.StrictlyInferOctetCounting
}

func (o *InputSyslogSyslog1) GetAllowNonStandardAppName() *bool {
	if o == nil {
		return nil
	}
	return o.AllowNonStandardAppName
}

func (o *InputSyslogSyslog1) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSyslogSyslog1) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSyslogSyslog1) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSyslogSyslog1) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSyslogSyslog1) GetTLS() *InputSyslogTLSSettingsServerSide1 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSyslogSyslog1) GetMetadata() []InputSyslogMetadatum1 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSyslogSyslog1) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSyslogSyslog1) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputSyslogSyslog1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSyslogSyslog1) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputSyslogType string

const (
	InputSyslogTypeInputSyslogSyslog1 InputSyslogType = "InputSyslog_Syslog_1"
	InputSyslogTypeInputSyslogSyslog2 InputSyslogType = "InputSyslog_Syslog_2"
)

type InputSyslog struct {
	InputSyslogSyslog1 *InputSyslogSyslog1 `queryParam:"inline"`
	InputSyslogSyslog2 *InputSyslogSyslog2 `queryParam:"inline"`

	Type InputSyslogType
}

func CreateInputSyslogInputSyslogSyslog1(inputSyslogSyslog1 InputSyslogSyslog1) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog1

	return InputSyslog{
		InputSyslogSyslog1: &inputSyslogSyslog1,
		Type:               typ,
	}
}

func CreateInputSyslogInputSyslogSyslog2(inputSyslogSyslog2 InputSyslogSyslog2) InputSyslog {
	typ := InputSyslogTypeInputSyslogSyslog2

	return InputSyslog{
		InputSyslogSyslog2: &inputSyslogSyslog2,
		Type:               typ,
	}
}

func (u *InputSyslog) UnmarshalJSON(data []byte) error {

	var inputSyslogSyslog1 InputSyslogSyslog1 = InputSyslogSyslog1{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog1, "", true, true); err == nil {
		u.InputSyslogSyslog1 = &inputSyslogSyslog1
		u.Type = InputSyslogTypeInputSyslogSyslog1
		return nil
	}

	var inputSyslogSyslog2 InputSyslogSyslog2 = InputSyslogSyslog2{}
	if err := utils.UnmarshalJSON(data, &inputSyslogSyslog2, "", true, true); err == nil {
		u.InputSyslogSyslog2 = &inputSyslogSyslog2
		u.Type = InputSyslogTypeInputSyslogSyslog2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputSyslog", string(data))
}

func (u InputSyslog) MarshalJSON() ([]byte, error) {
	if u.InputSyslogSyslog1 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog1, "", true)
	}

	if u.InputSyslogSyslog2 != nil {
		return utils.MarshalJSON(u.InputSyslogSyslog2, "", true)
	}

	return nil, errors.New("could not marshal union type InputSyslog: all fields are null")
}

type InputTypeSqs string

const (
	InputTypeSqsSqs InputTypeSqs = "sqs"
)

func (e InputTypeSqs) ToPointer() *InputTypeSqs {
	return &e
}
func (e *InputTypeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sqs":
		*e = InputTypeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSqs: %v", v)
	}
}

type ConnectionSqs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSqs) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeSqs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSqs string

const (
	PqModeSqsSmart  PqModeSqs = "smart"
	PqModeSqsAlways PqModeSqs = "always"
)

func (e PqModeSqs) ToPointer() *PqModeSqs {
	return &e
}
func (e *PqModeSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeSqs: %v", v)
	}
}

// PqCompressionSqs - Codec to use to compress the persisted data
type PqCompressionSqs string

const (
	PqCompressionSqsNone PqCompressionSqs = "none"
	PqCompressionSqsGzip PqCompressionSqs = "gzip"
)

func (e PqCompressionSqs) ToPointer() *PqCompressionSqs {
	return &e
}
func (e *PqCompressionSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionSqs: %v", v)
	}
}

type PqSqs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSqs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionSqs `default:"none" json:"compress"`
}

func (p PqSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSqs) GetMode() *PqModeSqs {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSqs) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSqs) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSqs) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSqs) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSqs) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSqs) GetCompress() *PqCompressionSqs {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputQueueType - The queue type used (or created). Defaults to Standard
type InputQueueType string

const (
	InputQueueTypeStandard InputQueueType = "standard"
	InputQueueTypeFifo     InputQueueType = "fifo"
)

func (e InputQueueType) ToPointer() *InputQueueType {
	return &e
}
func (e *InputQueueType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "standard":
		fallthrough
	case "fifo":
		*e = InputQueueType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputQueueType: %v", v)
	}
}

// InputAuthenticationMethodSqs - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodSqs string

const (
	InputAuthenticationMethodSqsAuto   InputAuthenticationMethodSqs = "auto"
	InputAuthenticationMethodSqsManual InputAuthenticationMethodSqs = "manual"
	InputAuthenticationMethodSqsSecret InputAuthenticationMethodSqs = "secret"
)

func (e InputAuthenticationMethodSqs) ToPointer() *InputAuthenticationMethodSqs {
	return &e
}
func (e *InputAuthenticationMethodSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodSqs: %v", v)
	}
}

// InputSignatureVersionSqs - Signature version to use for signing SQS requests
type InputSignatureVersionSqs string

const (
	InputSignatureVersionSqsV2 InputSignatureVersionSqs = "v2"
	InputSignatureVersionSqsV4 InputSignatureVersionSqs = "v4"
)

func (e InputSignatureVersionSqs) ToPointer() *InputSignatureVersionSqs {
	return &e
}
func (e *InputSignatureVersionSqs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSignatureVersionSqs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSignatureVersionSqs: %v", v)
	}
}

type MetadatumSqs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSqs) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSqs) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSqs struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputTypeSqs `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSqs `json:"connections,omitempty"`
	Pq          *PqSqs          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read events from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can only be evaluated at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// The queue type used (or created). Defaults to Standard
	QueueType *InputQueueType `default:"standard" json:"queueType"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// Create queue if it does not exist.
	CreateQueue *bool `default:"false" json:"createQueue"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodSqs `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                       `json:"awsSecretKey,omitempty"`
	// AWS Region where the SQS queue is located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// SQS service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to SQS-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing SQS requests
	SignatureVersion *InputSignatureVersionSqs `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access SQS
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"10" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// Fields to add to events from this input
	Metadata []MetadatumSqs `json:"metadata,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	Description *string  `json:"description,omitempty"`
	AwsAPIKey   *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string `json:"awsSecret,omitempty"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64  `default:"3" json:"numReceivers"`
	Status       *TFStatus `json:"status,omitempty"`
}

func (i InputSqs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSqs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSqs) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSqs) GetType() *InputTypeSqs {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSqs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSqs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSqs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSqs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSqs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSqs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSqs) GetConnections() []ConnectionSqs {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSqs) GetPq() *PqSqs {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSqs) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputSqs) GetQueueType() *InputQueueType {
	if o == nil {
		return nil
	}
	return o.QueueType
}

func (o *InputSqs) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputSqs) GetCreateQueue() *bool {
	if o == nil {
		return nil
	}
	return o.CreateQueue
}

func (o *InputSqs) GetAwsAuthenticationMethod() *InputAuthenticationMethodSqs {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputSqs) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputSqs) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputSqs) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSqs) GetSignatureVersion() *InputSignatureVersionSqs {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputSqs) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputSqs) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSqs) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputSqs) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputSqs) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputSqs) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputSqs) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputSqs) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputSqs) GetMetadata() []MetadatumSqs {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSqs) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputSqs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSqs) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputSqs) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputSqs) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputSqs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeModelDrivenTelemetry string

const (
	TypeModelDrivenTelemetryModelDrivenTelemetry TypeModelDrivenTelemetry = "model_driven_telemetry"
)

func (e TypeModelDrivenTelemetry) ToPointer() *TypeModelDrivenTelemetry {
	return &e
}
func (e *TypeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "model_driven_telemetry":
		*e = TypeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeModelDrivenTelemetry: %v", v)
	}
}

type ConnectionModelDrivenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionModelDrivenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionModelDrivenTelemetry) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeModelDrivenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeModelDrivenTelemetry string

const (
	ModeModelDrivenTelemetrySmart  ModeModelDrivenTelemetry = "smart"
	ModeModelDrivenTelemetryAlways ModeModelDrivenTelemetry = "always"
)

func (e ModeModelDrivenTelemetry) ToPointer() *ModeModelDrivenTelemetry {
	return &e
}
func (e *ModeModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeModelDrivenTelemetry: %v", v)
	}
}

// CompressionModelDrivenTelemetry - Codec to use to compress the persisted data
type CompressionModelDrivenTelemetry string

const (
	CompressionModelDrivenTelemetryNone CompressionModelDrivenTelemetry = "none"
	CompressionModelDrivenTelemetryGzip CompressionModelDrivenTelemetry = "gzip"
)

func (e CompressionModelDrivenTelemetry) ToPointer() *CompressionModelDrivenTelemetry {
	return &e
}
func (e *CompressionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionModelDrivenTelemetry: %v", v)
	}
}

type PqModelDrivenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeModelDrivenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionModelDrivenTelemetry `default:"none" json:"compress"`
}

func (p PqModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqModelDrivenTelemetry) GetMode() *ModeModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqModelDrivenTelemetry) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqModelDrivenTelemetry) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqModelDrivenTelemetry) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqModelDrivenTelemetry) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqModelDrivenTelemetry) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqModelDrivenTelemetry) GetCompress() *CompressionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionModelDrivenTelemetry - Minimum TLS version to accept from connections
type MinimumTLSVersionModelDrivenTelemetry string

const (
	MinimumTLSVersionModelDrivenTelemetryTlSv1  MinimumTLSVersionModelDrivenTelemetry = "TLSv1"
	MinimumTLSVersionModelDrivenTelemetryTlSv11 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MinimumTLSVersionModelDrivenTelemetryTlSv12 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MinimumTLSVersionModelDrivenTelemetryTlSv13 MinimumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MinimumTLSVersionModelDrivenTelemetry) ToPointer() *MinimumTLSVersionModelDrivenTelemetry {
	return &e
}
func (e *MinimumTLSVersionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionModelDrivenTelemetry: %v", v)
	}
}

// MaximumTLSVersionModelDrivenTelemetry - Maximum TLS version to accept from connections
type MaximumTLSVersionModelDrivenTelemetry string

const (
	MaximumTLSVersionModelDrivenTelemetryTlSv1  MaximumTLSVersionModelDrivenTelemetry = "TLSv1"
	MaximumTLSVersionModelDrivenTelemetryTlSv11 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.1"
	MaximumTLSVersionModelDrivenTelemetryTlSv12 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.2"
	MaximumTLSVersionModelDrivenTelemetryTlSv13 MaximumTLSVersionModelDrivenTelemetry = "TLSv1.3"
)

func (e MaximumTLSVersionModelDrivenTelemetry) ToPointer() *MaximumTLSVersionModelDrivenTelemetry {
	return &e
}
func (e *MaximumTLSVersionModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionModelDrivenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionModelDrivenTelemetry: %v", v)
	}
}

type TLSSettingsServerSideModelDrivenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionModelDrivenTelemetry `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionModelDrivenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetMinVersion() *MinimumTLSVersionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideModelDrivenTelemetry) GetMaxVersion() *MaximumTLSVersionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumModelDrivenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumModelDrivenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumModelDrivenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputModelDrivenTelemetry struct {
	// Unique ID for this input
	ID       *string                   `json:"id,omitempty"`
	Type     *TypeModelDrivenTelemetry `json:"type,omitempty"`
	Disabled *bool                     `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionModelDrivenTelemetry `json:"connections,omitempty"`
	Pq          *PqModelDrivenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                                   `default:"57000" json:"port"`
	TLS  *TLSSettingsServerSideModelDrivenTelemetry `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumModelDrivenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// Time in milliseconds to allow the server to shutdown gracefully before forcing shutdown. Defaults to 5000.
	ShutdownTimeoutMs *float64  `default:"5000" json:"shutdownTimeoutMs"`
	Description       *string   `json:"description,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputModelDrivenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputModelDrivenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputModelDrivenTelemetry) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputModelDrivenTelemetry) GetType() *TypeModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputModelDrivenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputModelDrivenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputModelDrivenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputModelDrivenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputModelDrivenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputModelDrivenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputModelDrivenTelemetry) GetConnections() []ConnectionModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputModelDrivenTelemetry) GetPq() *PqModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputModelDrivenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputModelDrivenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputModelDrivenTelemetry) GetTLS() *TLSSettingsServerSideModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputModelDrivenTelemetry) GetMetadata() []MetadatumModelDrivenTelemetry {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputModelDrivenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputModelDrivenTelemetry) GetShutdownTimeoutMs() *float64 {
	if o == nil {
		return nil
	}
	return o.ShutdownTimeoutMs
}

func (o *InputModelDrivenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputModelDrivenTelemetry) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeOpenTelemetry string

const (
	InputTypeOpenTelemetryOpenTelemetry InputTypeOpenTelemetry = "open_telemetry"
)

func (e InputTypeOpenTelemetry) ToPointer() *InputTypeOpenTelemetry {
	return &e
}
func (e *InputTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "open_telemetry":
		*e = InputTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeOpenTelemetry: %v", v)
	}
}

type ConnectionOpenTelemetry struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOpenTelemetry) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeOpenTelemetry - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeOpenTelemetry string

const (
	PqModeOpenTelemetrySmart  PqModeOpenTelemetry = "smart"
	PqModeOpenTelemetryAlways PqModeOpenTelemetry = "always"
)

func (e PqModeOpenTelemetry) ToPointer() *PqModeOpenTelemetry {
	return &e
}
func (e *PqModeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeOpenTelemetry: %v", v)
	}
}

// PqCompressionOpenTelemetry - Codec to use to compress the persisted data
type PqCompressionOpenTelemetry string

const (
	PqCompressionOpenTelemetryNone PqCompressionOpenTelemetry = "none"
	PqCompressionOpenTelemetryGzip PqCompressionOpenTelemetry = "gzip"
)

func (e PqCompressionOpenTelemetry) ToPointer() *PqCompressionOpenTelemetry {
	return &e
}
func (e *PqCompressionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionOpenTelemetry: %v", v)
	}
}

type PqOpenTelemetry struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeOpenTelemetry `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionOpenTelemetry `default:"none" json:"compress"`
}

func (p PqOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOpenTelemetry) GetMode() *PqModeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOpenTelemetry) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOpenTelemetry) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOpenTelemetry) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOpenTelemetry) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOpenTelemetry) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOpenTelemetry) GetCompress() *PqCompressionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionOpenTelemetry - Minimum TLS version to accept from connections
type InputMinimumTLSVersionOpenTelemetry string

const (
	InputMinimumTLSVersionOpenTelemetryTlSv1  InputMinimumTLSVersionOpenTelemetry = "TLSv1"
	InputMinimumTLSVersionOpenTelemetryTlSv11 InputMinimumTLSVersionOpenTelemetry = "TLSv1.1"
	InputMinimumTLSVersionOpenTelemetryTlSv12 InputMinimumTLSVersionOpenTelemetry = "TLSv1.2"
	InputMinimumTLSVersionOpenTelemetryTlSv13 InputMinimumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e InputMinimumTLSVersionOpenTelemetry) ToPointer() *InputMinimumTLSVersionOpenTelemetry {
	return &e
}
func (e *InputMinimumTLSVersionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionOpenTelemetry: %v", v)
	}
}

// InputMaximumTLSVersionOpenTelemetry - Maximum TLS version to accept from connections
type InputMaximumTLSVersionOpenTelemetry string

const (
	InputMaximumTLSVersionOpenTelemetryTlSv1  InputMaximumTLSVersionOpenTelemetry = "TLSv1"
	InputMaximumTLSVersionOpenTelemetryTlSv11 InputMaximumTLSVersionOpenTelemetry = "TLSv1.1"
	InputMaximumTLSVersionOpenTelemetryTlSv12 InputMaximumTLSVersionOpenTelemetry = "TLSv1.2"
	InputMaximumTLSVersionOpenTelemetryTlSv13 InputMaximumTLSVersionOpenTelemetry = "TLSv1.3"
)

func (e InputMaximumTLSVersionOpenTelemetry) ToPointer() *InputMaximumTLSVersionOpenTelemetry {
	return &e
}
func (e *InputMaximumTLSVersionOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionOpenTelemetry: %v", v)
	}
}

type TLSSettingsServerSideOpenTelemetry struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMinimumTLSVersionOpenTelemetry `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMaximumTLSVersionOpenTelemetry `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideOpenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideOpenTelemetry) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideOpenTelemetry) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideOpenTelemetry) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideOpenTelemetry) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideOpenTelemetry) GetMinVersion() *InputMinimumTLSVersionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideOpenTelemetry) GetMaxVersion() *InputMaximumTLSVersionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputProtocolOpenTelemetry - Select whether to leverage gRPC or HTTP for OpenTelemetry
type InputProtocolOpenTelemetry string

const (
	InputProtocolOpenTelemetryGrpc InputProtocolOpenTelemetry = "grpc"
	InputProtocolOpenTelemetryHTTP InputProtocolOpenTelemetry = "http"
)

func (e InputProtocolOpenTelemetry) ToPointer() *InputProtocolOpenTelemetry {
	return &e
}
func (e *InputProtocolOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "http":
		*e = InputProtocolOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputProtocolOpenTelemetry: %v", v)
	}
}

// InputOTLPVersion - The version of OTLP Protobuf definitions to use when interpreting received data
type InputOTLPVersion string

const (
	InputOTLPVersionZeroDot10Dot0 InputOTLPVersion = "0.10.0"
	InputOTLPVersionOneDot3Dot1   InputOTLPVersion = "1.3.1"
)

func (e InputOTLPVersion) ToPointer() *InputOTLPVersion {
	return &e
}
func (e *InputOTLPVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "0.10.0":
		fallthrough
	case "1.3.1":
		*e = InputOTLPVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputOTLPVersion: %v", v)
	}
}

// InputAuthenticationTypeOpenTelemetry - OpenTelemetry authentication type
type InputAuthenticationTypeOpenTelemetry string

const (
	InputAuthenticationTypeOpenTelemetryNone              InputAuthenticationTypeOpenTelemetry = "none"
	InputAuthenticationTypeOpenTelemetryBasic             InputAuthenticationTypeOpenTelemetry = "basic"
	InputAuthenticationTypeOpenTelemetryCredentialsSecret InputAuthenticationTypeOpenTelemetry = "credentialsSecret"
	InputAuthenticationTypeOpenTelemetryToken             InputAuthenticationTypeOpenTelemetry = "token"
	InputAuthenticationTypeOpenTelemetryTextSecret        InputAuthenticationTypeOpenTelemetry = "textSecret"
	InputAuthenticationTypeOpenTelemetryOauth             InputAuthenticationTypeOpenTelemetry = "oauth"
)

func (e InputAuthenticationTypeOpenTelemetry) ToPointer() *InputAuthenticationTypeOpenTelemetry {
	return &e
}
func (e *InputAuthenticationTypeOpenTelemetry) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputAuthenticationTypeOpenTelemetry(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationTypeOpenTelemetry: %v", v)
	}
}

type InputMetadatumOpenTelemetry struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputMetadatumOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputMetadatumOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOauthParamOpenTelemetry struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *InputOauthParamOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOauthParamOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOauthHeaderOpenTelemetry struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *InputOauthHeaderOpenTelemetry) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputOauthHeaderOpenTelemetry) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputOpenTelemetry struct {
	// Unique ID for this input
	ID       *string                 `json:"id,omitempty"`
	Type     *InputTypeOpenTelemetry `json:"type,omitempty"`
	Disabled *bool                   `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOpenTelemetry `json:"connections,omitempty"`
	Pq          *PqOpenTelemetry          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port *float64                            `default:"4317" json:"port"`
	TLS  *TLSSettingsServerSideOpenTelemetry `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket  *int64 `default:"0" json:"maxRequestsPerSocket"`
	EnableProxyHeader     any    `json:"enableProxyHeader,omitempty"`
	CaptureHeaders        any    `json:"captureHeaders,omitempty"`
	ActivityLogSampleRate any    `json:"activityLogSampleRate,omitempty"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"15" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist.
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Select whether to leverage gRPC or HTTP for OpenTelemetry
	Protocol *InputProtocolOpenTelemetry `default:"grpc" json:"protocol"`
	// Enable to extract each incoming span to a separate event
	ExtractSpans *bool `default:"false" json:"extractSpans"`
	// Enable to extract each incoming Gauge or IntGauge metric to multiple events, one per data point
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// The version of OTLP Protobuf definitions to use when interpreting received data
	OtlpVersion *InputOTLPVersion `default:"0.10.0" json:"otlpVersion"`
	// OpenTelemetry authentication type
	AuthType *InputAuthenticationTypeOpenTelemetry `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata []InputMetadatumOpenTelemetry `json:"metadata,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	Description  *string  `json:"description,omitempty"`
	Username     *string  `json:"username,omitempty"`
	Password     *string  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []InputOauthParamOpenTelemetry `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []InputOauthHeaderOpenTelemetry `json:"oauthHeaders,omitempty"`
	// Enable to extract each incoming log record to a separate event
	ExtractLogs *bool     `default:"false" json:"extractLogs"`
	Status      *TFStatus `json:"status,omitempty"`
}

func (i InputOpenTelemetry) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOpenTelemetry) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOpenTelemetry) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOpenTelemetry) GetType() *InputTypeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOpenTelemetry) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOpenTelemetry) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOpenTelemetry) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOpenTelemetry) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOpenTelemetry) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOpenTelemetry) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOpenTelemetry) GetConnections() []ConnectionOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOpenTelemetry) GetPq() *PqOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOpenTelemetry) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputOpenTelemetry) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputOpenTelemetry) GetTLS() *TLSSettingsServerSideOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputOpenTelemetry) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputOpenTelemetry) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputOpenTelemetry) GetEnableProxyHeader() any {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputOpenTelemetry) GetCaptureHeaders() any {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputOpenTelemetry) GetActivityLogSampleRate() any {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputOpenTelemetry) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputOpenTelemetry) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputOpenTelemetry) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputOpenTelemetry) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputOpenTelemetry) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputOpenTelemetry) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputOpenTelemetry) GetProtocol() *InputProtocolOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *InputOpenTelemetry) GetExtractSpans() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractSpans
}

func (o *InputOpenTelemetry) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputOpenTelemetry) GetOtlpVersion() *InputOTLPVersion {
	if o == nil {
		return nil
	}
	return o.OtlpVersion
}

func (o *InputOpenTelemetry) GetAuthType() *InputAuthenticationTypeOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOpenTelemetry) GetMetadata() []InputMetadatumOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOpenTelemetry) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputOpenTelemetry) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOpenTelemetry) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOpenTelemetry) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOpenTelemetry) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputOpenTelemetry) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOpenTelemetry) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOpenTelemetry) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputOpenTelemetry) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputOpenTelemetry) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputOpenTelemetry) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputOpenTelemetry) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputOpenTelemetry) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputOpenTelemetry) GetOauthParams() []InputOauthParamOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputOpenTelemetry) GetOauthHeaders() []InputOauthHeaderOpenTelemetry {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputOpenTelemetry) GetExtractLogs() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractLogs
}

func (o *InputOpenTelemetry) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeSnmp string

const (
	InputTypeSnmpSnmp InputTypeSnmp = "snmp"
)

func (e InputTypeSnmp) ToPointer() *InputTypeSnmp {
	return &e
}
func (e *InputTypeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "snmp":
		*e = InputTypeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSnmp: %v", v)
	}
}

type ConnectionSnmp struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSnmp) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSnmp - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSnmp string

const (
	ModeSnmpSmart  ModeSnmp = "smart"
	ModeSnmpAlways ModeSnmp = "always"
)

func (e ModeSnmp) ToPointer() *ModeSnmp {
	return &e
}
func (e *ModeSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSnmp: %v", v)
	}
}

// CompressionSnmp - Codec to use to compress the persisted data
type CompressionSnmp string

const (
	CompressionSnmpNone CompressionSnmp = "none"
	CompressionSnmpGzip CompressionSnmp = "gzip"
)

func (e CompressionSnmp) ToPointer() *CompressionSnmp {
	return &e
}
func (e *CompressionSnmp) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSnmp(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSnmp: %v", v)
	}
}

type PqSnmp struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSnmp `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSnmp `default:"none" json:"compress"`
}

func (p PqSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSnmp) GetMode() *ModeSnmp {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSnmp) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSnmp) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSnmp) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSnmp) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSnmp) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSnmp) GetCompress() *CompressionSnmp {
	if o == nil {
		return nil
	}
	return o.Compress
}

type AuthenticationProtocol string

const (
	AuthenticationProtocolNone   AuthenticationProtocol = "none"
	AuthenticationProtocolMd5    AuthenticationProtocol = "md5"
	AuthenticationProtocolSha    AuthenticationProtocol = "sha"
	AuthenticationProtocolSha224 AuthenticationProtocol = "sha224"
	AuthenticationProtocolSha256 AuthenticationProtocol = "sha256"
	AuthenticationProtocolSha384 AuthenticationProtocol = "sha384"
	AuthenticationProtocolSha512 AuthenticationProtocol = "sha512"
)

func (e AuthenticationProtocol) ToPointer() *AuthenticationProtocol {
	return &e
}
func (e *AuthenticationProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "md5":
		fallthrough
	case "sha":
		fallthrough
	case "sha224":
		fallthrough
	case "sha256":
		fallthrough
	case "sha384":
		fallthrough
	case "sha512":
		*e = AuthenticationProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationProtocol: %v", v)
	}
}

type V3User struct {
	Name         string                  `json:"name"`
	AuthProtocol *AuthenticationProtocol `default:"none" json:"authProtocol"`
	AuthKey      any                     `json:"authKey,omitempty"`
	PrivProtocol *string                 `default:"none" json:"privProtocol"`
}

func (v V3User) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(v, "", false)
}

func (v *V3User) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &v, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *V3User) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *V3User) GetAuthProtocol() *AuthenticationProtocol {
	if o == nil {
		return nil
	}
	return o.AuthProtocol
}

func (o *V3User) GetAuthKey() any {
	if o == nil {
		return nil
	}
	return o.AuthKey
}

func (o *V3User) GetPrivProtocol() *string {
	if o == nil {
		return nil
	}
	return o.PrivProtocol
}

// SNMPv3Authentication - Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
type SNMPv3Authentication struct {
	V3AuthEnabled *bool `default:"false" json:"v3AuthEnabled"`
	// Pass through traps that don't match any of the configured users. @{product} will not attempt to decrypt these traps.
	AllowUnmatchedTrap *bool `default:"false" json:"allowUnmatchedTrap"`
	// User credentials for receiving v3 traps
	V3Users []V3User `json:"v3Users,omitempty"`
}

func (s SNMPv3Authentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SNMPv3Authentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SNMPv3Authentication) GetV3AuthEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.V3AuthEnabled
}

func (o *SNMPv3Authentication) GetAllowUnmatchedTrap() *bool {
	if o == nil {
		return nil
	}
	return o.AllowUnmatchedTrap
}

func (o *SNMPv3Authentication) GetV3Users() []V3User {
	if o == nil {
		return nil
	}
	return o.V3Users
}

type MetadatumSnmp struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSnmp) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSnmp) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSnmp struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputTypeSnmp `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSnmp `json:"connections,omitempty"`
	Pq          *PqSnmp          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// UDP port to receive SNMP traps on. Defaults to 162.
	Port *float64 `default:"162" json:"port"`
	// Authentication parameters for SNMPv3 trap. Set the log level to debug if you are experiencing authentication or decryption issues.
	SnmpV3Auth *SNMPv3Authentication `json:"snmpV3Auth,omitempty"`
	// Maximum number of events to buffer when downstream is blocking.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Fields to add to events from this input
	Metadata []MetadatumSnmp `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64 `json:"udpSocketRxBufSize,omitempty"`
	// If enabled, parses varbinds as an array of objects that include OID, value, and type
	VarbindsWithTypes *bool     `default:"false" json:"varbindsWithTypes"`
	Description       *string   `json:"description,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputSnmp) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSnmp) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSnmp) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSnmp) GetType() *InputTypeSnmp {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSnmp) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSnmp) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSnmp) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSnmp) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSnmp) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSnmp) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSnmp) GetConnections() []ConnectionSnmp {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSnmp) GetPq() *PqSnmp {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSnmp) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSnmp) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *InputSnmp) GetSnmpV3Auth() *SNMPv3Authentication {
	if o == nil {
		return nil
	}
	return o.SnmpV3Auth
}

func (o *InputSnmp) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputSnmp) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSnmp) GetMetadata() []MetadatumSnmp {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSnmp) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputSnmp) GetVarbindsWithTypes() *bool {
	if o == nil {
		return nil
	}
	return o.VarbindsWithTypes
}

func (o *InputSnmp) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSnmp) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeS3Inventory string

const (
	TypeS3InventoryS3Inventory TypeS3Inventory = "s3_inventory"
)

func (e TypeS3Inventory) ToPointer() *TypeS3Inventory {
	return &e
}
func (e *TypeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3_inventory":
		*e = TypeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeS3Inventory: %v", v)
	}
}

type ConnectionS3Inventory struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionS3Inventory) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionS3Inventory) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeS3Inventory - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3Inventory string

const (
	ModeS3InventorySmart  ModeS3Inventory = "smart"
	ModeS3InventoryAlways ModeS3Inventory = "always"
)

func (e ModeS3Inventory) ToPointer() *ModeS3Inventory {
	return &e
}
func (e *ModeS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeS3Inventory: %v", v)
	}
}

// CompressionS3Inventory - Codec to use to compress the persisted data
type CompressionS3Inventory string

const (
	CompressionS3InventoryNone CompressionS3Inventory = "none"
	CompressionS3InventoryGzip CompressionS3Inventory = "gzip"
)

func (e CompressionS3Inventory) ToPointer() *CompressionS3Inventory {
	return &e
}
func (e *CompressionS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionS3Inventory: %v", v)
	}
}

type PqS3Inventory struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3Inventory `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionS3Inventory `default:"none" json:"compress"`
}

func (p PqS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqS3Inventory) GetMode() *ModeS3Inventory {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqS3Inventory) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqS3Inventory) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqS3Inventory) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqS3Inventory) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqS3Inventory) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqS3Inventory) GetCompress() *CompressionS3Inventory {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodS3Inventory - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodS3Inventory string

const (
	AuthenticationMethodS3InventoryAuto   AuthenticationMethodS3Inventory = "auto"
	AuthenticationMethodS3InventoryManual AuthenticationMethodS3Inventory = "manual"
	AuthenticationMethodS3InventorySecret AuthenticationMethodS3Inventory = "secret"
)

func (e AuthenticationMethodS3Inventory) ToPointer() *AuthenticationMethodS3Inventory {
	return &e
}
func (e *AuthenticationMethodS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodS3Inventory: %v", v)
	}
}

// SignatureVersionS3Inventory - Signature version to use for signing S3 requests
type SignatureVersionS3Inventory string

const (
	SignatureVersionS3InventoryV2 SignatureVersionS3Inventory = "v2"
	SignatureVersionS3InventoryV4 SignatureVersionS3Inventory = "v4"
)

func (e SignatureVersionS3Inventory) ToPointer() *SignatureVersionS3Inventory {
	return &e
}
func (e *SignatureVersionS3Inventory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionS3Inventory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionS3Inventory: %v", v)
	}
}

type PreprocessS3Inventory struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessS3Inventory) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessS3Inventory) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessS3Inventory) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumS3Inventory struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumS3Inventory) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumS3Inventory) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingS3Inventory struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingS3Inventory) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingS3Inventory) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputS3Inventory struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeS3Inventory `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3Inventory `json:"connections,omitempty"`
	Pq          *PqS3Inventory          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodS3Inventory `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionS3Inventory `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3Inventory `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3Inventory `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64                  `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3Inventory `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Filename suffix of the manifest checksum file. If a filename matching this suffix is received        in the queue, the matching manifest file will be downloaded and validated against its value. Defaults to "checksum"
	ChecksumSuffix *string `default:"checksum" json:"checksumSuffix"`
	// Maximum download size (KB) of each manifest or checksum file. Manifest files larger than this size will not be read.        Defaults to 4096.
	MaxManifestSizeKB *int64 `default:"4096" json:"maxManifestSizeKB"`
	// If set to Yes, each inventory file in the manifest will be validated against its checksum. Defaults to false
	ValidateInventoryFiles *bool   `default:"false" json:"validateInventoryFiles"`
	Description            *string `json:"description,omitempty"`
	AwsAPIKey              *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputS3Inventory) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3Inventory) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3Inventory) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputS3Inventory) GetType() TypeS3Inventory {
	if o == nil {
		return TypeS3Inventory("")
	}
	return o.Type
}

func (o *InputS3Inventory) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3Inventory) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3Inventory) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3Inventory) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3Inventory) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3Inventory) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3Inventory) GetConnections() []ConnectionS3Inventory {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3Inventory) GetPq() *PqS3Inventory {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3Inventory) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3Inventory) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3Inventory) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3Inventory) GetAwsAuthenticationMethod() *AuthenticationMethodS3Inventory {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3Inventory) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3Inventory) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3Inventory) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3Inventory) GetSignatureVersion() *SignatureVersionS3Inventory {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3Inventory) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3Inventory) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3Inventory) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3Inventory) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3Inventory) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3Inventory) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3Inventory) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3Inventory) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3Inventory) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3Inventory) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3Inventory) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3Inventory) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3Inventory) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3Inventory) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3Inventory) GetPreprocess() *PreprocessS3Inventory {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3Inventory) GetMetadata() []MetadatumS3Inventory {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3Inventory) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3Inventory) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3Inventory) GetCheckpointing() *CheckpointingS3Inventory {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3Inventory) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3Inventory) GetChecksumSuffix() *string {
	if o == nil {
		return nil
	}
	return o.ChecksumSuffix
}

func (o *InputS3Inventory) GetMaxManifestSizeKB() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxManifestSizeKB
}

func (o *InputS3Inventory) GetValidateInventoryFiles() *bool {
	if o == nil {
		return nil
	}
	return o.ValidateInventoryFiles
}

func (o *InputS3Inventory) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3Inventory) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3Inventory) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3Inventory) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeS3 string

const (
	InputTypeS3S3 InputTypeS3 = "s3"
)

func (e InputTypeS3) ToPointer() *InputTypeS3 {
	return &e
}
func (e *InputTypeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = InputTypeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeS3: %v", v)
	}
}

type ConnectionS3 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionS3) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeS3 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeS3 string

const (
	ModeS3Smart  ModeS3 = "smart"
	ModeS3Always ModeS3 = "always"
)

func (e ModeS3) ToPointer() *ModeS3 {
	return &e
}
func (e *ModeS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeS3: %v", v)
	}
}

// CompressionS3 - Codec to use to compress the persisted data
type CompressionS3 string

const (
	CompressionS3None CompressionS3 = "none"
	CompressionS3Gzip CompressionS3 = "gzip"
)

func (e CompressionS3) ToPointer() *CompressionS3 {
	return &e
}
func (e *CompressionS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionS3: %v", v)
	}
}

type PqS3 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeS3 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionS3 `default:"none" json:"compress"`
}

func (p PqS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqS3) GetMode() *ModeS3 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqS3) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqS3) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqS3) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqS3) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqS3) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqS3) GetCompress() *CompressionS3 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputAuthenticationMethodS3 - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodS3 string

const (
	InputAuthenticationMethodS3Auto   InputAuthenticationMethodS3 = "auto"
	InputAuthenticationMethodS3Manual InputAuthenticationMethodS3 = "manual"
	InputAuthenticationMethodS3Secret InputAuthenticationMethodS3 = "secret"
)

func (e InputAuthenticationMethodS3) ToPointer() *InputAuthenticationMethodS3 {
	return &e
}
func (e *InputAuthenticationMethodS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodS3: %v", v)
	}
}

// InputSignatureVersionS3 - Signature version to use for signing S3 requests
type InputSignatureVersionS3 string

const (
	InputSignatureVersionS3V2 InputSignatureVersionS3 = "v2"
	InputSignatureVersionS3V4 InputSignatureVersionS3 = "v4"
)

func (e InputSignatureVersionS3) ToPointer() *InputSignatureVersionS3 {
	return &e
}
func (e *InputSignatureVersionS3) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSignatureVersionS3(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSignatureVersionS3: %v", v)
	}
}

type PreprocessS3 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessS3) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessS3) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessS3) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumS3 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumS3) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumS3) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingS3 struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingS3) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingS3) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputS3 struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     InputTypeS3 `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionS3 `json:"connections,omitempty"`
	Pq          *PqS3          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodS3 `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                      `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *InputSignatureVersionS3 `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool         `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessS3 `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumS3 `json:"metadata,omitempty"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64         `default:"600" json:"parquetChunkDownloadTimeout"`
	Checkpointing               *CheckpointingS3 `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputS3) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputS3) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputS3) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputS3) GetType() InputTypeS3 {
	if o == nil {
		return InputTypeS3("")
	}
	return o.Type
}

func (o *InputS3) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputS3) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputS3) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputS3) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputS3) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputS3) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputS3) GetConnections() []ConnectionS3 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputS3) GetPq() *PqS3 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputS3) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputS3) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputS3) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputS3) GetAwsAuthenticationMethod() *InputAuthenticationMethodS3 {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputS3) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputS3) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputS3) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputS3) GetSignatureVersion() *InputSignatureVersionS3 {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputS3) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputS3) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputS3) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputS3) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputS3) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputS3) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputS3) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputS3) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputS3) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputS3) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputS3) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputS3) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputS3) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputS3) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputS3) GetPreprocess() *PreprocessS3 {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputS3) GetMetadata() []MetadatumS3 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputS3) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputS3) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputS3) GetCheckpointing() *CheckpointingS3 {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputS3) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputS3) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputS3) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputS3) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputS3) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputS3) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeMetrics string

const (
	TypeMetricsMetrics TypeMetrics = "metrics"
)

func (e TypeMetrics) ToPointer() *TypeMetrics {
	return &e
}
func (e *TypeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "metrics":
		*e = TypeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeMetrics: %v", v)
	}
}

type ConnectionMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionMetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeMetrics string

const (
	ModeMetricsSmart  ModeMetrics = "smart"
	ModeMetricsAlways ModeMetrics = "always"
)

func (e ModeMetrics) ToPointer() *ModeMetrics {
	return &e
}
func (e *ModeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeMetrics: %v", v)
	}
}

// CompressionMetrics - Codec to use to compress the persisted data
type CompressionMetrics string

const (
	CompressionMetricsNone CompressionMetrics = "none"
	CompressionMetricsGzip CompressionMetrics = "gzip"
)

func (e CompressionMetrics) ToPointer() *CompressionMetrics {
	return &e
}
func (e *CompressionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionMetrics: %v", v)
	}
}

type PqMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionMetrics `default:"none" json:"compress"`
}

func (p PqMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqMetrics) GetMode() *ModeMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqMetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqMetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqMetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqMetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqMetrics) GetCompress() *CompressionMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionMetrics - Minimum TLS version to accept from connections
type MinimumTLSVersionMetrics string

const (
	MinimumTLSVersionMetricsTlSv1  MinimumTLSVersionMetrics = "TLSv1"
	MinimumTLSVersionMetricsTlSv11 MinimumTLSVersionMetrics = "TLSv1.1"
	MinimumTLSVersionMetricsTlSv12 MinimumTLSVersionMetrics = "TLSv1.2"
	MinimumTLSVersionMetricsTlSv13 MinimumTLSVersionMetrics = "TLSv1.3"
)

func (e MinimumTLSVersionMetrics) ToPointer() *MinimumTLSVersionMetrics {
	return &e
}
func (e *MinimumTLSVersionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionMetrics: %v", v)
	}
}

// MaximumTLSVersionMetrics - Maximum TLS version to accept from connections
type MaximumTLSVersionMetrics string

const (
	MaximumTLSVersionMetricsTlSv1  MaximumTLSVersionMetrics = "TLSv1"
	MaximumTLSVersionMetricsTlSv11 MaximumTLSVersionMetrics = "TLSv1.1"
	MaximumTLSVersionMetricsTlSv12 MaximumTLSVersionMetrics = "TLSv1.2"
	MaximumTLSVersionMetricsTlSv13 MaximumTLSVersionMetrics = "TLSv1.3"
)

func (e MaximumTLSVersionMetrics) ToPointer() *MaximumTLSVersionMetrics {
	return &e
}
func (e *MaximumTLSVersionMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionMetrics: %v", v)
	}
}

type TLSSettingsServerSideMetrics struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionMetrics `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionMetrics `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideMetrics) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideMetrics) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideMetrics) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideMetrics) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideMetrics) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideMetrics) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideMetrics) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideMetrics) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideMetrics) GetMinVersion() *MinimumTLSVersionMetrics {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideMetrics) GetMaxVersion() *MaximumTLSVersionMetrics {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumMetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputMetrics struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     TypeMetrics `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMetrics `json:"connections,omitempty"`
	Pq          *PqMetrics          `json:"pq,omitempty"`
	// Address to bind on. For IPv4 (all addresses), use the default '0.0.0.0'. For IPv6, enter '::' (all addresses) or specify an IP address.
	Host *string `default:"0.0.0.0" json:"host"`
	// Enter UDP port number to listen on. Not required if listening on TCP.
	UDPPort *float64 `json:"udpPort,omitempty"`
	// Enter TCP port number to listen on. Not required if listening on UDP.
	TCPPort *float64 `json:"tcpPort,omitempty"`
	// Maximum number of events to buffer when downstream is blocking. Only applies to UDP.
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// Regex matching IP addresses that are allowed to send data
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Enable if the connection is proxied by a device that supports Proxy Protocol V1 or V2
	EnableProxyHeader *bool                         `default:"false" json:"enableProxyHeader"`
	TLS               *TLSSettingsServerSideMetrics `json:"tls,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumMetrics `json:"metadata,omitempty"`
	// Optionally, set the SO_RCVBUF socket option for the UDP socket. This value tells the operating system how many bytes can be buffered in the kernel before events are dropped. Leave blank to use the OS default. Caution: Increasing this value will affect OS memory utilization.
	UDPSocketRxBufSize *float64  `json:"udpSocketRxBufSize,omitempty"`
	Description        *string   `json:"description,omitempty"`
	Status             *TFStatus `json:"status,omitempty"`
}

func (i InputMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMetrics) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputMetrics) GetType() TypeMetrics {
	if o == nil {
		return TypeMetrics("")
	}
	return o.Type
}

func (o *InputMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMetrics) GetConnections() []ConnectionMetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMetrics) GetPq() *PqMetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMetrics) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputMetrics) GetUDPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPPort
}

func (o *InputMetrics) GetTCPPort() *float64 {
	if o == nil {
		return nil
	}
	return o.TCPPort
}

func (o *InputMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputMetrics) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputMetrics) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputMetrics) GetTLS() *TLSSettingsServerSideMetrics {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMetrics) GetMetadata() []MetadatumMetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMetrics) GetUDPSocketRxBufSize() *float64 {
	if o == nil {
		return nil
	}
	return o.UDPSocketRxBufSize
}

func (o *InputMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeCriblmetrics string

const (
	TypeCriblmetricsCriblmetrics TypeCriblmetrics = "criblmetrics"
)

func (e TypeCriblmetrics) ToPointer() *TypeCriblmetrics {
	return &e
}
func (e *TypeCriblmetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "criblmetrics":
		*e = TypeCriblmetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCriblmetrics: %v", v)
	}
}

type ConnectionCriblmetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblmetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblmetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCriblmetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCriblmetrics string

const (
	ModeCriblmetricsSmart  ModeCriblmetrics = "smart"
	ModeCriblmetricsAlways ModeCriblmetrics = "always"
)

func (e ModeCriblmetrics) ToPointer() *ModeCriblmetrics {
	return &e
}
func (e *ModeCriblmetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCriblmetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCriblmetrics: %v", v)
	}
}

// CompressionCriblmetrics - Codec to use to compress the persisted data
type CompressionCriblmetrics string

const (
	CompressionCriblmetricsNone CompressionCriblmetrics = "none"
	CompressionCriblmetricsGzip CompressionCriblmetrics = "gzip"
)

func (e CompressionCriblmetrics) ToPointer() *CompressionCriblmetrics {
	return &e
}
func (e *CompressionCriblmetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCriblmetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCriblmetrics: %v", v)
	}
}

type PqCriblmetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCriblmetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCriblmetrics `default:"none" json:"compress"`
}

func (p PqCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblmetrics) GetMode() *ModeCriblmetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblmetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblmetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblmetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblmetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblmetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblmetrics) GetCompress() *CompressionCriblmetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumCriblmetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblmetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblmetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblmetrics struct {
	// Unique ID for this input
	ID       string           `json:"id"`
	Type     TypeCriblmetrics `json:"type"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblmetrics `json:"connections,omitempty"`
	Pq          *PqCriblmetrics          `json:"pq,omitempty"`
	// A prefix that is applied to the metrics provided by Cribl Stream
	Prefix *string `default:"cribl.logstream." json:"prefix"`
	// Include granular metrics.  Disabling this will drop the following metrics events: `cribl.logstream.host.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.index.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.source.(in_bytes,in_events,out_bytes,out_events)`, `cribl.logstream.sourcetype.(in_bytes,in_events,out_bytes,out_events)`.
	FullFidelity *bool `default:"true" json:"fullFidelity"`
	// Fields to add to events from this input
	Metadata    []MetadatumCriblmetrics `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputCriblmetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblmetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblmetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCriblmetrics) GetType() TypeCriblmetrics {
	if o == nil {
		return TypeCriblmetrics("")
	}
	return o.Type
}

func (o *InputCriblmetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblmetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblmetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblmetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblmetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblmetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblmetrics) GetConnections() []ConnectionCriblmetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblmetrics) GetPq() *PqCriblmetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblmetrics) GetPrefix() *string {
	if o == nil {
		return nil
	}
	return o.Prefix
}

func (o *InputCriblmetrics) GetFullFidelity() *bool {
	if o == nil {
		return nil
	}
	return o.FullFidelity
}

func (o *InputCriblmetrics) GetMetadata() []MetadatumCriblmetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblmetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblmetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeKinesis string

const (
	InputTypeKinesisKinesis InputTypeKinesis = "kinesis"
)

func (e InputTypeKinesis) ToPointer() *InputTypeKinesis {
	return &e
}
func (e *InputTypeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kinesis":
		*e = InputTypeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeKinesis: %v", v)
	}
}

type ConnectionKinesis struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKinesis) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeKinesis - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeKinesis string

const (
	PqModeKinesisSmart  PqModeKinesis = "smart"
	PqModeKinesisAlways PqModeKinesis = "always"
)

func (e PqModeKinesis) ToPointer() *PqModeKinesis {
	return &e
}
func (e *PqModeKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeKinesis: %v", v)
	}
}

// PqCompressionKinesis - Codec to use to compress the persisted data
type PqCompressionKinesis string

const (
	PqCompressionKinesisNone PqCompressionKinesis = "none"
	PqCompressionKinesisGzip PqCompressionKinesis = "gzip"
)

func (e PqCompressionKinesis) ToPointer() *PqCompressionKinesis {
	return &e
}
func (e *PqCompressionKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionKinesis: %v", v)
	}
}

type PqKinesis struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeKinesis `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionKinesis `default:"none" json:"compress"`
}

func (p PqKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKinesis) GetMode() *PqModeKinesis {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKinesis) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKinesis) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKinesis) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKinesis) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKinesis) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKinesis) GetCompress() *PqCompressionKinesis {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ShardIteratorStart - Location at which to start reading a shard for the first time.
type ShardIteratorStart string

const (
	ShardIteratorStartTrimHorizon ShardIteratorStart = "TRIM_HORIZON"
	ShardIteratorStartLatest      ShardIteratorStart = "LATEST"
)

func (e ShardIteratorStart) ToPointer() *ShardIteratorStart {
	return &e
}
func (e *ShardIteratorStart) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TRIM_HORIZON":
		fallthrough
	case "LATEST":
		*e = ShardIteratorStart(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardIteratorStart: %v", v)
	}
}

// InputRecordDataFormat - Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
type InputRecordDataFormat string

const (
	InputRecordDataFormatCribl      InputRecordDataFormat = "cribl"
	InputRecordDataFormatNdjson     InputRecordDataFormat = "ndjson"
	InputRecordDataFormatCloudwatch InputRecordDataFormat = "cloudwatch"
	InputRecordDataFormatLine       InputRecordDataFormat = "line"
)

func (e InputRecordDataFormat) ToPointer() *InputRecordDataFormat {
	return &e
}
func (e *InputRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		fallthrough
	case "ndjson":
		fallthrough
	case "cloudwatch":
		fallthrough
	case "line":
		*e = InputRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputRecordDataFormat: %v", v)
	}
}

// ShardLoadBalancing - The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
type ShardLoadBalancing string

const (
	ShardLoadBalancingConsistentHashing ShardLoadBalancing = "ConsistentHashing"
	ShardLoadBalancingRoundRobin        ShardLoadBalancing = "RoundRobin"
)

func (e ShardLoadBalancing) ToPointer() *ShardLoadBalancing {
	return &e
}
func (e *ShardLoadBalancing) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ConsistentHashing":
		fallthrough
	case "RoundRobin":
		*e = ShardLoadBalancing(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ShardLoadBalancing: %v", v)
	}
}

// InputAuthenticationMethodKinesis - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodKinesis string

const (
	InputAuthenticationMethodKinesisAuto   InputAuthenticationMethodKinesis = "auto"
	InputAuthenticationMethodKinesisManual InputAuthenticationMethodKinesis = "manual"
	InputAuthenticationMethodKinesisSecret InputAuthenticationMethodKinesis = "secret"
)

func (e InputAuthenticationMethodKinesis) ToPointer() *InputAuthenticationMethodKinesis {
	return &e
}
func (e *InputAuthenticationMethodKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodKinesis: %v", v)
	}
}

// InputSignatureVersionKinesis - Signature version to use for signing Kinesis stream requests
type InputSignatureVersionKinesis string

const (
	InputSignatureVersionKinesisV2 InputSignatureVersionKinesis = "v2"
	InputSignatureVersionKinesisV4 InputSignatureVersionKinesis = "v4"
)

func (e InputSignatureVersionKinesis) ToPointer() *InputSignatureVersionKinesis {
	return &e
}
func (e *InputSignatureVersionKinesis) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSignatureVersionKinesis(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSignatureVersionKinesis: %v", v)
	}
}

type MetadatumKinesis struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKinesis) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKinesis) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKinesis struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputTypeKinesis `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKinesis `json:"connections,omitempty"`
	Pq          *PqKinesis          `json:"pq,omitempty"`
	// Kinesis stream name to read data from.
	StreamName string `json:"streamName"`
	// Time interval in minutes between consecutive service calls
	ServiceInterval *float64 `default:"1" json:"serviceInterval"`
	// A JS expression to be called with each shardId for the stream, if the expression evalutates to a truthy value the shard will be processed.
	ShardExpr *string `default:"true" json:"shardExpr"`
	// Location at which to start reading a shard for the first time.
	ShardIteratorType *ShardIteratorStart `default:"TRIM_HORIZON" json:"shardIteratorType"`
	// Format of data inside the Kinesis Stream records. Gzip compression is automatically detected.
	PayloadFormat *InputRecordDataFormat `default:"cribl" json:"payloadFormat"`
	// Maximum number of records per getRecords call
	GetRecordsLimit *float64 `default:"5000" json:"getRecordsLimit"`
	// Maximum number of records, across all shards, to pull down at once per Worker Process
	GetRecordsLimitTotal *float64 `default:"20000" json:"getRecordsLimitTotal"`
	// The load-balancing algorithm to use for spreading out shards across Workers and Worker Processes
	LoadBalancingAlgorithm *ShardLoadBalancing `default:"ConsistentHashing" json:"loadBalancingAlgorithm"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodKinesis `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                           `json:"awsSecretKey,omitempty"`
	// Region where the Kinesis stream is located
	Region string `json:"region"`
	// Kinesis stream service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to Kinesis stream-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing Kinesis stream requests
	SignatureVersion *InputSignatureVersionKinesis `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access Kinesis stream
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Verify Kinesis Producer Library (KPL) event checksums
	VerifyKPLCheckSums *bool `default:"false" json:"verifyKPLCheckSums"`
	// Yes means: when resuming streaming from a stored state, Stream will read the next available record, rather than rereading the last-read record. Enabling this can cause data loss after a Worker Node's unexpected shutdown or restart.
	AvoidDuplicates *bool `default:"false" json:"avoidDuplicates"`
	// Fields to add to events from this input
	Metadata    []MetadatumKinesis `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	AwsAPIKey   *string            `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputKinesis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKinesis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKinesis) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputKinesis) GetType() *InputTypeKinesis {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKinesis) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKinesis) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKinesis) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKinesis) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKinesis) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKinesis) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKinesis) GetConnections() []ConnectionKinesis {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKinesis) GetPq() *PqKinesis {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKinesis) GetStreamName() string {
	if o == nil {
		return ""
	}
	return o.StreamName
}

func (o *InputKinesis) GetServiceInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.ServiceInterval
}

func (o *InputKinesis) GetShardExpr() *string {
	if o == nil {
		return nil
	}
	return o.ShardExpr
}

func (o *InputKinesis) GetShardIteratorType() *ShardIteratorStart {
	if o == nil {
		return nil
	}
	return o.ShardIteratorType
}

func (o *InputKinesis) GetPayloadFormat() *InputRecordDataFormat {
	if o == nil {
		return nil
	}
	return o.PayloadFormat
}

func (o *InputKinesis) GetGetRecordsLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimit
}

func (o *InputKinesis) GetGetRecordsLimitTotal() *float64 {
	if o == nil {
		return nil
	}
	return o.GetRecordsLimitTotal
}

func (o *InputKinesis) GetLoadBalancingAlgorithm() *ShardLoadBalancing {
	if o == nil {
		return nil
	}
	return o.LoadBalancingAlgorithm
}

func (o *InputKinesis) GetAwsAuthenticationMethod() *InputAuthenticationMethodKinesis {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputKinesis) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputKinesis) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputKinesis) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputKinesis) GetSignatureVersion() *InputSignatureVersionKinesis {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputKinesis) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputKinesis) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKinesis) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputKinesis) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputKinesis) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputKinesis) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputKinesis) GetVerifyKPLCheckSums() *bool {
	if o == nil {
		return nil
	}
	return o.VerifyKPLCheckSums
}

func (o *InputKinesis) GetAvoidDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.AvoidDuplicates
}

func (o *InputKinesis) GetMetadata() []MetadatumKinesis {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKinesis) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKinesis) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputKinesis) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputKinesis) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeHTTPRaw string

const (
	TypeHTTPRawHTTPRaw TypeHTTPRaw = "http_raw"
)

func (e TypeHTTPRaw) ToPointer() *TypeHTTPRaw {
	return &e
}
func (e *TypeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http_raw":
		*e = TypeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeHTTPRaw: %v", v)
	}
}

type ConnectionHTTPRaw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionHTTPRaw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionHTTPRaw) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeHTTPRaw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeHTTPRaw string

const (
	ModeHTTPRawSmart  ModeHTTPRaw = "smart"
	ModeHTTPRawAlways ModeHTTPRaw = "always"
)

func (e ModeHTTPRaw) ToPointer() *ModeHTTPRaw {
	return &e
}
func (e *ModeHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeHTTPRaw: %v", v)
	}
}

// CompressionHTTPRaw - Codec to use to compress the persisted data
type CompressionHTTPRaw string

const (
	CompressionHTTPRawNone CompressionHTTPRaw = "none"
	CompressionHTTPRawGzip CompressionHTTPRaw = "gzip"
)

func (e CompressionHTTPRaw) ToPointer() *CompressionHTTPRaw {
	return &e
}
func (e *CompressionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionHTTPRaw: %v", v)
	}
}

type PqHTTPRaw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeHTTPRaw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionHTTPRaw `default:"none" json:"compress"`
}

func (p PqHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqHTTPRaw) GetMode() *ModeHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqHTTPRaw) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqHTTPRaw) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqHTTPRaw) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqHTTPRaw) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqHTTPRaw) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqHTTPRaw) GetCompress() *CompressionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionHTTPRaw - Minimum TLS version to accept from connections
type MinimumTLSVersionHTTPRaw string

const (
	MinimumTLSVersionHTTPRawTlSv1  MinimumTLSVersionHTTPRaw = "TLSv1"
	MinimumTLSVersionHTTPRawTlSv11 MinimumTLSVersionHTTPRaw = "TLSv1.1"
	MinimumTLSVersionHTTPRawTlSv12 MinimumTLSVersionHTTPRaw = "TLSv1.2"
	MinimumTLSVersionHTTPRawTlSv13 MinimumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MinimumTLSVersionHTTPRaw) ToPointer() *MinimumTLSVersionHTTPRaw {
	return &e
}
func (e *MinimumTLSVersionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionHTTPRaw: %v", v)
	}
}

// MaximumTLSVersionHTTPRaw - Maximum TLS version to accept from connections
type MaximumTLSVersionHTTPRaw string

const (
	MaximumTLSVersionHTTPRawTlSv1  MaximumTLSVersionHTTPRaw = "TLSv1"
	MaximumTLSVersionHTTPRawTlSv11 MaximumTLSVersionHTTPRaw = "TLSv1.1"
	MaximumTLSVersionHTTPRawTlSv12 MaximumTLSVersionHTTPRaw = "TLSv1.2"
	MaximumTLSVersionHTTPRawTlSv13 MaximumTLSVersionHTTPRaw = "TLSv1.3"
)

func (e MaximumTLSVersionHTTPRaw) ToPointer() *MaximumTLSVersionHTTPRaw {
	return &e
}
func (e *MaximumTLSVersionHTTPRaw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionHTTPRaw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionHTTPRaw: %v", v)
	}
}

type TLSSettingsServerSideHTTPRaw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionHTTPRaw `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionHTTPRaw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideHTTPRaw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideHTTPRaw) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideHTTPRaw) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideHTTPRaw) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideHTTPRaw) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideHTTPRaw) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideHTTPRaw) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideHTTPRaw) GetMinVersion() *MinimumTLSVersionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideHTTPRaw) GetMaxVersion() *MaximumTLSVersionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumHTTPRaw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumHTTPRaw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtMetadatumHTTPRaw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokensExtMetadatumHTTPRaw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokensExtMetadatumHTTPRaw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtHTTPRaw struct {
	// Shared secret to be provided by any client (Authorization: <token>)
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTPRaw `json:"metadata,omitempty"`
}

func (o *AuthTokensExtHTTPRaw) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokensExtHTTPRaw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokensExtHTTPRaw) GetMetadata() []AuthTokensExtMetadatumHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTPRaw struct {
	// Unique ID for this input
	ID       *string      `json:"id,omitempty"`
	Type     *TypeHTTPRaw `json:"type,omitempty"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTPRaw `json:"connections,omitempty"`
	Pq          *PqHTTPRaw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                      `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTPRaw `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata []MetadatumHTTPRaw `json:"metadata,omitempty"`
	// List of URI paths accepted by this input, wildcards are supported, e.g /api/v*/hook. Defaults to allow all.
	AllowedPaths []string `json:"allowedPaths,omitempty"`
	// List of HTTP methods accepted by this input, wildcards are supported, e.g. P*, GET. Defaults to allow all.
	AllowedMethods []string `json:"allowedMethods,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []AuthTokensExtHTTPRaw `json:"authTokensExt,omitempty"`
	Description   *string                `json:"description,omitempty"`
	Status        *TFStatus              `json:"status,omitempty"`
}

func (i InputHTTPRaw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTPRaw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTPRaw) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputHTTPRaw) GetType() *TypeHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTPRaw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTPRaw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTPRaw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTPRaw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTPRaw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTPRaw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTPRaw) GetConnections() []ConnectionHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTPRaw) GetPq() *PqHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTPRaw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTPRaw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTPRaw) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTPRaw) GetTLS() *TLSSettingsServerSideHTTPRaw {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTPRaw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTPRaw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTPRaw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTPRaw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTPRaw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTPRaw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTPRaw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTPRaw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTPRaw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTPRaw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTPRaw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTPRaw) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputHTTPRaw) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputHTTPRaw) GetMetadata() []MetadatumHTTPRaw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTPRaw) GetAllowedPaths() []string {
	if o == nil {
		return nil
	}
	return o.AllowedPaths
}

func (o *InputHTTPRaw) GetAllowedMethods() []string {
	if o == nil {
		return nil
	}
	return o.AllowedMethods
}

func (o *InputHTTPRaw) GetAuthTokensExt() []AuthTokensExtHTTPRaw {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTPRaw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputHTTPRaw) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeDatagen string

const (
	TypeDatagenDatagen TypeDatagen = "datagen"
)

func (e TypeDatagen) ToPointer() *TypeDatagen {
	return &e
}
func (e *TypeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datagen":
		*e = TypeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatagen: %v", v)
	}
}

type ConnectionDatagen struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionDatagen) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionDatagen) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeDatagen - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatagen string

const (
	ModeDatagenSmart  ModeDatagen = "smart"
	ModeDatagenAlways ModeDatagen = "always"
)

func (e ModeDatagen) ToPointer() *ModeDatagen {
	return &e
}
func (e *ModeDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeDatagen: %v", v)
	}
}

// CompressionDatagen - Codec to use to compress the persisted data
type CompressionDatagen string

const (
	CompressionDatagenNone CompressionDatagen = "none"
	CompressionDatagenGzip CompressionDatagen = "gzip"
)

func (e CompressionDatagen) ToPointer() *CompressionDatagen {
	return &e
}
func (e *CompressionDatagen) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionDatagen(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionDatagen: %v", v)
	}
}

type PqDatagen struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatagen `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionDatagen `default:"none" json:"compress"`
}

func (p PqDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqDatagen) GetMode() *ModeDatagen {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqDatagen) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqDatagen) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqDatagen) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqDatagen) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqDatagen) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqDatagen) GetCompress() *CompressionDatagen {
	if o == nil {
		return nil
	}
	return o.Compress
}

type Sample struct {
	// Name of the datagen file
	Sample string `json:"sample"`
	// Maximum no. of events to generate per second per worker node. Defaults to 10.
	EventsPerSec *float64 `default:"10" json:"eventsPerSec"`
}

func (s Sample) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Sample) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Sample) GetSample() string {
	if o == nil {
		return ""
	}
	return o.Sample
}

func (o *Sample) GetEventsPerSec() *float64 {
	if o == nil {
		return nil
	}
	return o.EventsPerSec
}

type MetadatumDatagen struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumDatagen) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumDatagen) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputDatagen struct {
	// Unique ID for this input
	ID       *string     `json:"id,omitempty"`
	Type     TypeDatagen `json:"type"`
	Disabled *bool       `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatagen `json:"connections,omitempty"`
	Pq          *PqDatagen          `json:"pq,omitempty"`
	// List of datagens
	Samples []Sample `json:"samples"`
	// Fields to add to events from this input
	Metadata    []MetadatumDatagen `json:"metadata,omitempty"`
	Description *string            `json:"description,omitempty"`
	Status      *TFStatus          `json:"status,omitempty"`
}

func (i InputDatagen) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatagen) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatagen) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputDatagen) GetType() TypeDatagen {
	if o == nil {
		return TypeDatagen("")
	}
	return o.Type
}

func (o *InputDatagen) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatagen) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatagen) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatagen) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatagen) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatagen) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatagen) GetConnections() []ConnectionDatagen {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatagen) GetPq() *PqDatagen {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatagen) GetSamples() []Sample {
	if o == nil {
		return []Sample{}
	}
	return o.Samples
}

func (o *InputDatagen) GetMetadata() []MetadatumDatagen {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatagen) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputDatagen) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeDatadogAgent string

const (
	TypeDatadogAgentDatadogAgent TypeDatadogAgent = "datadog_agent"
)

func (e TypeDatadogAgent) ToPointer() *TypeDatadogAgent {
	return &e
}
func (e *TypeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "datadog_agent":
		*e = TypeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeDatadogAgent: %v", v)
	}
}

type ConnectionDatadogAgent struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionDatadogAgent) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionDatadogAgent) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeDatadogAgent - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeDatadogAgent string

const (
	ModeDatadogAgentSmart  ModeDatadogAgent = "smart"
	ModeDatadogAgentAlways ModeDatadogAgent = "always"
)

func (e ModeDatadogAgent) ToPointer() *ModeDatadogAgent {
	return &e
}
func (e *ModeDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeDatadogAgent: %v", v)
	}
}

// CompressionDatadogAgent - Codec to use to compress the persisted data
type CompressionDatadogAgent string

const (
	CompressionDatadogAgentNone CompressionDatadogAgent = "none"
	CompressionDatadogAgentGzip CompressionDatadogAgent = "gzip"
)

func (e CompressionDatadogAgent) ToPointer() *CompressionDatadogAgent {
	return &e
}
func (e *CompressionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionDatadogAgent: %v", v)
	}
}

type PqDatadogAgent struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeDatadogAgent `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionDatadogAgent `default:"none" json:"compress"`
}

func (p PqDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqDatadogAgent) GetMode() *ModeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqDatadogAgent) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqDatadogAgent) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqDatadogAgent) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqDatadogAgent) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqDatadogAgent) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqDatadogAgent) GetCompress() *CompressionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionDatadogAgent - Minimum TLS version to accept from connections
type MinimumTLSVersionDatadogAgent string

const (
	MinimumTLSVersionDatadogAgentTlSv1  MinimumTLSVersionDatadogAgent = "TLSv1"
	MinimumTLSVersionDatadogAgentTlSv11 MinimumTLSVersionDatadogAgent = "TLSv1.1"
	MinimumTLSVersionDatadogAgentTlSv12 MinimumTLSVersionDatadogAgent = "TLSv1.2"
	MinimumTLSVersionDatadogAgentTlSv13 MinimumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MinimumTLSVersionDatadogAgent) ToPointer() *MinimumTLSVersionDatadogAgent {
	return &e
}
func (e *MinimumTLSVersionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionDatadogAgent: %v", v)
	}
}

// MaximumTLSVersionDatadogAgent - Maximum TLS version to accept from connections
type MaximumTLSVersionDatadogAgent string

const (
	MaximumTLSVersionDatadogAgentTlSv1  MaximumTLSVersionDatadogAgent = "TLSv1"
	MaximumTLSVersionDatadogAgentTlSv11 MaximumTLSVersionDatadogAgent = "TLSv1.1"
	MaximumTLSVersionDatadogAgentTlSv12 MaximumTLSVersionDatadogAgent = "TLSv1.2"
	MaximumTLSVersionDatadogAgentTlSv13 MaximumTLSVersionDatadogAgent = "TLSv1.3"
)

func (e MaximumTLSVersionDatadogAgent) ToPointer() *MaximumTLSVersionDatadogAgent {
	return &e
}
func (e *MaximumTLSVersionDatadogAgent) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionDatadogAgent(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionDatadogAgent: %v", v)
	}
}

type TLSSettingsServerSideDatadogAgent struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionDatadogAgent `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionDatadogAgent `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideDatadogAgent) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideDatadogAgent) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideDatadogAgent) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideDatadogAgent) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideDatadogAgent) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideDatadogAgent) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideDatadogAgent) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideDatadogAgent) GetMinVersion() *MinimumTLSVersionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideDatadogAgent) GetMaxVersion() *MaximumTLSVersionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumDatadogAgent struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumDatadogAgent) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumDatadogAgent) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type ProxyModeDatadogAgent struct {
	// Toggle to Yes to send key validation requests from Datadog Agent to the Datadog API. If toggled to No (the default), Stream handles key validation requests by always responding that the key is valid.
	Enabled *bool `default:"false" json:"enabled"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (p ProxyModeDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ProxyModeDatadogAgent) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *ProxyModeDatadogAgent) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type InputDatadogAgent struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *TypeDatadogAgent `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionDatadogAgent `json:"connections,omitempty"`
	Pq          *PqDatadogAgent          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSideDatadogAgent `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Toggle to Yes to extract each incoming metric to multiple events, one per data point. This works well when sending metrics to a statsd-type output. If sending metrics to DatadogHQ or any destination that accepts arbitrary JSON, leave toggled to No (the default).
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Fields to add to events from this input
	Metadata    []MetadatumDatadogAgent `json:"metadata,omitempty"`
	ProxyMode   *ProxyModeDatadogAgent  `json:"proxyMode,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputDatadogAgent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputDatadogAgent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputDatadogAgent) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputDatadogAgent) GetType() *TypeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputDatadogAgent) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputDatadogAgent) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputDatadogAgent) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputDatadogAgent) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputDatadogAgent) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputDatadogAgent) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputDatadogAgent) GetConnections() []ConnectionDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputDatadogAgent) GetPq() *PqDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputDatadogAgent) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputDatadogAgent) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputDatadogAgent) GetTLS() *TLSSettingsServerSideDatadogAgent {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputDatadogAgent) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputDatadogAgent) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputDatadogAgent) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputDatadogAgent) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputDatadogAgent) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputDatadogAgent) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputDatadogAgent) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputDatadogAgent) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputDatadogAgent) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputDatadogAgent) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputDatadogAgent) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputDatadogAgent) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputDatadogAgent) GetMetadata() []MetadatumDatadogAgent {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputDatadogAgent) GetProxyMode() *ProxyModeDatadogAgent {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputDatadogAgent) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputDatadogAgent) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeCrowdstrike string

const (
	TypeCrowdstrikeCrowdstrike TypeCrowdstrike = "crowdstrike"
)

func (e TypeCrowdstrike) ToPointer() *TypeCrowdstrike {
	return &e
}
func (e *TypeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "crowdstrike":
		*e = TypeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCrowdstrike: %v", v)
	}
}

type ConnectionCrowdstrike struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCrowdstrike) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCrowdstrike) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCrowdstrike - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCrowdstrike string

const (
	ModeCrowdstrikeSmart  ModeCrowdstrike = "smart"
	ModeCrowdstrikeAlways ModeCrowdstrike = "always"
)

func (e ModeCrowdstrike) ToPointer() *ModeCrowdstrike {
	return &e
}
func (e *ModeCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCrowdstrike: %v", v)
	}
}

// CompressionCrowdstrike - Codec to use to compress the persisted data
type CompressionCrowdstrike string

const (
	CompressionCrowdstrikeNone CompressionCrowdstrike = "none"
	CompressionCrowdstrikeGzip CompressionCrowdstrike = "gzip"
)

func (e CompressionCrowdstrike) ToPointer() *CompressionCrowdstrike {
	return &e
}
func (e *CompressionCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCrowdstrike: %v", v)
	}
}

type PqCrowdstrike struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCrowdstrike `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCrowdstrike `default:"none" json:"compress"`
}

func (p PqCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCrowdstrike) GetMode() *ModeCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCrowdstrike) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCrowdstrike) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCrowdstrike) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCrowdstrike) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCrowdstrike) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCrowdstrike) GetCompress() *CompressionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodCrowdstrike - AWS authentication method. Choose Auto to use IAM roles.
type AuthenticationMethodCrowdstrike string

const (
	AuthenticationMethodCrowdstrikeAuto   AuthenticationMethodCrowdstrike = "auto"
	AuthenticationMethodCrowdstrikeManual AuthenticationMethodCrowdstrike = "manual"
	AuthenticationMethodCrowdstrikeSecret AuthenticationMethodCrowdstrike = "secret"
)

func (e AuthenticationMethodCrowdstrike) ToPointer() *AuthenticationMethodCrowdstrike {
	return &e
}
func (e *AuthenticationMethodCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodCrowdstrike: %v", v)
	}
}

// SignatureVersionCrowdstrike - Signature version to use for signing S3 requests
type SignatureVersionCrowdstrike string

const (
	SignatureVersionCrowdstrikeV2 SignatureVersionCrowdstrike = "v2"
	SignatureVersionCrowdstrikeV4 SignatureVersionCrowdstrike = "v4"
)

func (e SignatureVersionCrowdstrike) ToPointer() *SignatureVersionCrowdstrike {
	return &e
}
func (e *SignatureVersionCrowdstrike) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionCrowdstrike(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionCrowdstrike: %v", v)
	}
}

type PreprocessCrowdstrike struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (p PreprocessCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PreprocessCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PreprocessCrowdstrike) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *PreprocessCrowdstrike) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *PreprocessCrowdstrike) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type MetadatumCrowdstrike struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCrowdstrike) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCrowdstrike) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type CheckpointingCrowdstrike struct {
	// Resume processing files after an interruption
	Enabled *bool `default:"false" json:"enabled"`
	// If checkpointing is enabled, the number of times to retry processing when a processing error occurs. If skip file on error is enabled, this setting is ignored.
	Retries *float64 `default:"5" json:"retries"`
}

func (c CheckpointingCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CheckpointingCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CheckpointingCrowdstrike) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CheckpointingCrowdstrike) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

type InputCrowdstrike struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     TypeCrowdstrike `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCrowdstrike `json:"connections,omitempty"`
	Pq          *PqCrowdstrike          `json:"pq,omitempty"`
	// The name, URL, or ARN of the SQS queue to read notifications from. When a non-AWS URL is specified, format must be: '{url}/myQueueName'. Example: 'https://host:port/myQueueName'. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. Example referencing a Global Variable: `https://host:port/myQueue-${C.vars.myVar}`.
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// SQS queue owner's AWS account ID. Leave empty if SQS queue is in same AWS account.
	AwsAccountID *string `json:"awsAccountId,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AuthenticationMethodCrowdstrike `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                          `json:"awsSecretKey,omitempty"`
	// AWS Region where the S3 bucket and SQS queue are located. Required, unless the Queue entry is a URL or ARN that includes a Region.
	Region *string `json:"region,omitempty"`
	// S3 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing S3 requests
	SignatureVersion *SignatureVersionCrowdstrike `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// The maximum number of messages SQS should return in a poll request. Amazon SQS never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 10.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// After messages are retrieved by a ReceiveMessage request, @{product} will hide them from subsequent retrieve requests for at least this duration. You can set this as high as 43200 sec. (12 hours).
	VisibilityTimeout *float64 `default:"21600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// Socket inactivity timeout (in seconds). Increase this value if timeouts occur due to backpressure.
	SocketTimeout *float64 `default:"300" json:"socketTimeout"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `default:"true" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Use Assume Role credentials when accessing SQS
	EnableSQSAssumeRole *bool                  `default:"false" json:"enableSQSAssumeRole"`
	Preprocess          *PreprocessCrowdstrike `json:"preprocess,omitempty"`
	// Fields to add to events from this input
	Metadata      []MetadatumCrowdstrike    `json:"metadata,omitempty"`
	Checkpointing *CheckpointingCrowdstrike `json:"checkpointing,omitempty"`
	// How long to wait for events before trying polling again. The lower the number the higher the AWS bill. The higher the number the longer it will take for the source to react to configuration changes and system restarts.
	PollTimeout *float64 `default:"10" json:"pollTimeout"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding    *string `json:"encoding,omitempty"`
	Description *string `json:"description,omitempty"`
	AwsAPIKey   *string `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputCrowdstrike) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCrowdstrike) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCrowdstrike) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCrowdstrike) GetType() TypeCrowdstrike {
	if o == nil {
		return TypeCrowdstrike("")
	}
	return o.Type
}

func (o *InputCrowdstrike) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCrowdstrike) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCrowdstrike) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCrowdstrike) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCrowdstrike) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCrowdstrike) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCrowdstrike) GetConnections() []ConnectionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCrowdstrike) GetPq() *PqCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCrowdstrike) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputCrowdstrike) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputCrowdstrike) GetAwsAccountID() *string {
	if o == nil {
		return nil
	}
	return o.AwsAccountID
}

func (o *InputCrowdstrike) GetAwsAuthenticationMethod() *AuthenticationMethodCrowdstrike {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputCrowdstrike) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputCrowdstrike) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputCrowdstrike) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputCrowdstrike) GetSignatureVersion() *SignatureVersionCrowdstrike {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputCrowdstrike) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputCrowdstrike) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputCrowdstrike) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCrowdstrike) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCrowdstrike) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputCrowdstrike) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputCrowdstrike) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputCrowdstrike) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCrowdstrike) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputCrowdstrike) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputCrowdstrike) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputCrowdstrike) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputCrowdstrike) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputCrowdstrike) GetEnableSQSAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableSQSAssumeRole
}

func (o *InputCrowdstrike) GetPreprocess() *PreprocessCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCrowdstrike) GetMetadata() []MetadatumCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCrowdstrike) GetCheckpointing() *CheckpointingCrowdstrike {
	if o == nil {
		return nil
	}
	return o.Checkpointing
}

func (o *InputCrowdstrike) GetPollTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.PollTimeout
}

func (o *InputCrowdstrike) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputCrowdstrike) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCrowdstrike) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputCrowdstrike) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputCrowdstrike) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeWindowsMetrics string

const (
	TypeWindowsMetricsWindowsMetrics TypeWindowsMetrics = "windows_metrics"
)

func (e TypeWindowsMetrics) ToPointer() *TypeWindowsMetrics {
	return &e
}
func (e *TypeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "windows_metrics":
		*e = TypeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeWindowsMetrics: %v", v)
	}
}

type ConnectionWindowsMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionWindowsMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionWindowsMetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeWindowsMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeWindowsMetrics string

const (
	PqModeWindowsMetricsSmart  PqModeWindowsMetrics = "smart"
	PqModeWindowsMetricsAlways PqModeWindowsMetrics = "always"
)

func (e PqModeWindowsMetrics) ToPointer() *PqModeWindowsMetrics {
	return &e
}
func (e *PqModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeWindowsMetrics: %v", v)
	}
}

// CompressionWindowsMetrics - Codec to use to compress the persisted data
type CompressionWindowsMetrics string

const (
	CompressionWindowsMetricsNone CompressionWindowsMetrics = "none"
	CompressionWindowsMetricsGzip CompressionWindowsMetrics = "gzip"
)

func (e CompressionWindowsMetrics) ToPointer() *CompressionWindowsMetrics {
	return &e
}
func (e *CompressionWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionWindowsMetrics: %v", v)
	}
}

type PqWindowsMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeWindowsMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionWindowsMetrics `default:"none" json:"compress"`
}

func (p PqWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqWindowsMetrics) GetMode() *PqModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqWindowsMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqWindowsMetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqWindowsMetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqWindowsMetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqWindowsMetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqWindowsMetrics) GetCompress() *CompressionWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

// HostModeWindowsMetrics - Select level of detail for host metrics
type HostModeWindowsMetrics string

const (
	HostModeWindowsMetricsBasic    HostModeWindowsMetrics = "basic"
	HostModeWindowsMetricsAll      HostModeWindowsMetrics = "all"
	HostModeWindowsMetricsCustom   HostModeWindowsMetrics = "custom"
	HostModeWindowsMetricsDisabled HostModeWindowsMetrics = "disabled"
)

func (e HostModeWindowsMetrics) ToPointer() *HostModeWindowsMetrics {
	return &e
}
func (e *HostModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = HostModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for HostModeWindowsMetrics: %v", v)
	}
}

// SystemModeWindowsMetrics - Select the level of details for system metrics
type SystemModeWindowsMetrics string

const (
	SystemModeWindowsMetricsBasic    SystemModeWindowsMetrics = "basic"
	SystemModeWindowsMetricsAll      SystemModeWindowsMetrics = "all"
	SystemModeWindowsMetricsCustom   SystemModeWindowsMetrics = "custom"
	SystemModeWindowsMetricsDisabled SystemModeWindowsMetrics = "disabled"
)

func (e SystemModeWindowsMetrics) ToPointer() *SystemModeWindowsMetrics {
	return &e
}
func (e *SystemModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = SystemModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SystemModeWindowsMetrics: %v", v)
	}
}

type SystemWindowsMetrics struct {
	// Select the level of details for system metrics
	Mode *SystemModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for all system information
	Detail *bool `default:"false" json:"detail"`
}

func (s SystemWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SystemWindowsMetrics) GetMode() *SystemModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *SystemWindowsMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// CPUModeWindowsMetrics - Select the level of details for CPU metrics
type CPUModeWindowsMetrics string

const (
	CPUModeWindowsMetricsBasic    CPUModeWindowsMetrics = "basic"
	CPUModeWindowsMetricsAll      CPUModeWindowsMetrics = "all"
	CPUModeWindowsMetricsCustom   CPUModeWindowsMetrics = "custom"
	CPUModeWindowsMetricsDisabled CPUModeWindowsMetrics = "disabled"
)

func (e CPUModeWindowsMetrics) ToPointer() *CPUModeWindowsMetrics {
	return &e
}
func (e *CPUModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = CPUModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CPUModeWindowsMetrics: %v", v)
	}
}

type CPUWindowsMetrics struct {
	// Select the level of details for CPU metrics
	Mode *CPUModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (c CPUWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CPUWindowsMetrics) GetMode() *CPUModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *CPUWindowsMetrics) GetPerCPU() *bool {
	if o == nil {
		return nil
	}
	return o.PerCPU
}

func (o *CPUWindowsMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

func (o *CPUWindowsMetrics) GetTime() *bool {
	if o == nil {
		return nil
	}
	return o.Time
}

// MemoryModeWindowsMetrics - Select the level of details for memory metrics
type MemoryModeWindowsMetrics string

const (
	MemoryModeWindowsMetricsBasic    MemoryModeWindowsMetrics = "basic"
	MemoryModeWindowsMetricsAll      MemoryModeWindowsMetrics = "all"
	MemoryModeWindowsMetricsCustom   MemoryModeWindowsMetrics = "custom"
	MemoryModeWindowsMetricsDisabled MemoryModeWindowsMetrics = "disabled"
)

func (e MemoryModeWindowsMetrics) ToPointer() *MemoryModeWindowsMetrics {
	return &e
}
func (e *MemoryModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = MemoryModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MemoryModeWindowsMetrics: %v", v)
	}
}

type MemoryWindowsMetrics struct {
	// Select the level of details for memory metrics
	Mode *MemoryModeWindowsMetrics `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (m MemoryWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemoryWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *MemoryWindowsMetrics) GetMode() *MemoryModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *MemoryWindowsMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// NetworkModeWindowsMetrics - Select the level of details for network metrics
type NetworkModeWindowsMetrics string

const (
	NetworkModeWindowsMetricsBasic    NetworkModeWindowsMetrics = "basic"
	NetworkModeWindowsMetricsAll      NetworkModeWindowsMetrics = "all"
	NetworkModeWindowsMetricsCustom   NetworkModeWindowsMetrics = "custom"
	NetworkModeWindowsMetricsDisabled NetworkModeWindowsMetrics = "disabled"
)

func (e NetworkModeWindowsMetrics) ToPointer() *NetworkModeWindowsMetrics {
	return &e
}
func (e *NetworkModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = NetworkModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for NetworkModeWindowsMetrics: %v", v)
	}
}

type NetworkWindowsMetrics struct {
	// Select the level of details for network metrics
	Mode *NetworkModeWindowsMetrics `default:"basic" json:"mode"`
	// Network interfaces to include/exclude. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
}

func (n NetworkWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *NetworkWindowsMetrics) GetMode() *NetworkModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *NetworkWindowsMetrics) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *NetworkWindowsMetrics) GetPerInterface() *bool {
	if o == nil {
		return nil
	}
	return o.PerInterface
}

func (o *NetworkWindowsMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// DiskModeWindowsMetrics - Select the level of details for disk metrics
type DiskModeWindowsMetrics string

const (
	DiskModeWindowsMetricsBasic    DiskModeWindowsMetrics = "basic"
	DiskModeWindowsMetricsAll      DiskModeWindowsMetrics = "all"
	DiskModeWindowsMetricsCustom   DiskModeWindowsMetrics = "custom"
	DiskModeWindowsMetricsDisabled DiskModeWindowsMetrics = "disabled"
)

func (e DiskModeWindowsMetrics) ToPointer() *DiskModeWindowsMetrics {
	return &e
}
func (e *DiskModeWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = DiskModeWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiskModeWindowsMetrics: %v", v)
	}
}

type DiskWindowsMetrics struct {
	// Select the level of details for disk metrics
	Mode *DiskModeWindowsMetrics `default:"basic" json:"mode"`
	// Windows volumes to include/exclude. E.g.: C:, !E:, etc. Wildcards and ! (not) operators are supported. All volumes are included if this list is empty.
	Volumes []string `json:"volumes,omitempty"`
	// Generate separate metrics for each volume
	PerVolume *bool `default:"false" json:"perVolume"`
}

func (d DiskWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskWindowsMetrics) GetMode() *DiskModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *DiskWindowsMetrics) GetVolumes() []string {
	if o == nil {
		return nil
	}
	return o.Volumes
}

func (o *DiskWindowsMetrics) GetPerVolume() *bool {
	if o == nil {
		return nil
	}
	return o.PerVolume
}

type CustomWindowsMetrics struct {
	System  *SystemWindowsMetrics  `json:"system,omitempty"`
	CPU     *CPUWindowsMetrics     `json:"cpu,omitempty"`
	Memory  *MemoryWindowsMetrics  `json:"memory,omitempty"`
	Network *NetworkWindowsMetrics `json:"network,omitempty"`
	Disk    *DiskWindowsMetrics    `json:"disk,omitempty"`
}

func (o *CustomWindowsMetrics) GetSystem() *SystemWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.System
}

func (o *CustomWindowsMetrics) GetCPU() *CPUWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.CPU
}

func (o *CustomWindowsMetrics) GetMemory() *MemoryWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Memory
}

func (o *CustomWindowsMetrics) GetNetwork() *NetworkWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Network
}

func (o *CustomWindowsMetrics) GetDisk() *DiskWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Disk
}

type HostWindowsMetrics struct {
	// Select level of detail for host metrics
	Mode   *HostModeWindowsMetrics `default:"basic" json:"mode"`
	Custom *CustomWindowsMetrics   `json:"custom,omitempty"`
}

func (h HostWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostWindowsMetrics) GetMode() *HostModeWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *HostWindowsMetrics) GetCustom() *CustomWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Custom
}

type SetWindowsMetrics struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (s SetWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SetWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SetWindowsMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SetWindowsMetrics) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *SetWindowsMetrics) GetIncludeChildren() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeChildren
}

type ProcessWindowsMetrics struct {
	// Configure sets to collect process metrics
	Sets []SetWindowsMetrics `json:"sets,omitempty"`
}

func (o *ProcessWindowsMetrics) GetSets() []SetWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Sets
}

type MetadatumWindowsMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumWindowsMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumWindowsMetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type DataCompressionFormatWindowsMetrics string

const (
	DataCompressionFormatWindowsMetricsNone DataCompressionFormatWindowsMetrics = "none"
	DataCompressionFormatWindowsMetricsGzip DataCompressionFormatWindowsMetrics = "gzip"
)

func (e DataCompressionFormatWindowsMetrics) ToPointer() *DataCompressionFormatWindowsMetrics {
	return &e
}
func (e *DataCompressionFormatWindowsMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormatWindowsMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormatWindowsMetrics: %v", v)
	}
}

type PersistenceWindowsMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                              `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatWindowsMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/windows_metrics
	DestPath *string `default:"\\$CRIBL_HOME/state/windows_metrics" json:"destPath"`
}

func (p PersistenceWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PersistenceWindowsMetrics) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *PersistenceWindowsMetrics) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *PersistenceWindowsMetrics) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *PersistenceWindowsMetrics) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *PersistenceWindowsMetrics) GetCompress() *DataCompressionFormatWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *PersistenceWindowsMetrics) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputWindowsMetrics struct {
	// Unique ID for this input
	ID       string             `json:"id"`
	Type     TypeWindowsMetrics `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionWindowsMetrics `json:"connections,omitempty"`
	Pq          *PqWindowsMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval *float64               `default:"10" json:"interval"`
	Host     *HostWindowsMetrics    `json:"host,omitempty"`
	Process  *ProcessWindowsMetrics `json:"process,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumWindowsMetrics  `json:"metadata,omitempty"`
	Persistence *PersistenceWindowsMetrics `json:"persistence,omitempty"`
	// Enable to use built-in tools (PowerShell) to collect metrics instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-windows-metrics/#advanced-tab)
	DisableNativeModule *bool     `default:"false" json:"disableNativeModule"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputWindowsMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputWindowsMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputWindowsMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputWindowsMetrics) GetType() TypeWindowsMetrics {
	if o == nil {
		return TypeWindowsMetrics("")
	}
	return o.Type
}

func (o *InputWindowsMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputWindowsMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputWindowsMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputWindowsMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputWindowsMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputWindowsMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputWindowsMetrics) GetConnections() []ConnectionWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputWindowsMetrics) GetPq() *PqWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputWindowsMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputWindowsMetrics) GetHost() *HostWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputWindowsMetrics) GetProcess() *ProcessWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Process
}

func (o *InputWindowsMetrics) GetMetadata() []MetadatumWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputWindowsMetrics) GetPersistence() *PersistenceWindowsMetrics {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputWindowsMetrics) GetDisableNativeModule() *bool {
	if o == nil {
		return nil
	}
	return o.DisableNativeModule
}

func (o *InputWindowsMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputWindowsMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeKubeEvents string

const (
	TypeKubeEventsKubeEvents TypeKubeEvents = "kube_events"
)

func (e TypeKubeEvents) ToPointer() *TypeKubeEvents {
	return &e
}
func (e *TypeKubeEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_events":
		*e = TypeKubeEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeEvents: %v", v)
	}
}

type ConnectionKubeEvents struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKubeEvents) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKubeEvents) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeKubeEvents - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeEvents string

const (
	ModeKubeEventsSmart  ModeKubeEvents = "smart"
	ModeKubeEventsAlways ModeKubeEvents = "always"
)

func (e ModeKubeEvents) ToPointer() *ModeKubeEvents {
	return &e
}
func (e *ModeKubeEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeKubeEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeKubeEvents: %v", v)
	}
}

// CompressionKubeEvents - Codec to use to compress the persisted data
type CompressionKubeEvents string

const (
	CompressionKubeEventsNone CompressionKubeEvents = "none"
	CompressionKubeEventsGzip CompressionKubeEvents = "gzip"
)

func (e CompressionKubeEvents) ToPointer() *CompressionKubeEvents {
	return &e
}
func (e *CompressionKubeEvents) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionKubeEvents(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionKubeEvents: %v", v)
	}
}

type PqKubeEvents struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeEvents `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionKubeEvents `default:"none" json:"compress"`
}

func (p PqKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKubeEvents) GetMode() *ModeKubeEvents {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKubeEvents) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKubeEvents) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKubeEvents) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKubeEvents) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKubeEvents) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKubeEvents) GetCompress() *CompressionKubeEvents {
	if o == nil {
		return nil
	}
	return o.Compress
}

type RuleKubeEvents struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *RuleKubeEvents) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *RuleKubeEvents) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type MetadatumKubeEvents struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKubeEvents) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKubeEvents) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKubeEvents struct {
	// Unique ID for this input
	ID       string         `json:"id"`
	Type     TypeKubeEvents `json:"type"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeEvents `json:"connections,omitempty"`
	Pq          *PqKubeEvents          `json:"pq,omitempty"`
	// Filtering on event fields
	Rules []RuleKubeEvents `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumKubeEvents `json:"metadata,omitempty"`
	Description *string               `json:"description,omitempty"`
	Status      *TFStatus             `json:"status,omitempty"`
}

func (i InputKubeEvents) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeEvents) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeEvents) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeEvents) GetType() TypeKubeEvents {
	if o == nil {
		return TypeKubeEvents("")
	}
	return o.Type
}

func (o *InputKubeEvents) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeEvents) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeEvents) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeEvents) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeEvents) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeEvents) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeEvents) GetConnections() []ConnectionKubeEvents {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeEvents) GetPq() *PqKubeEvents {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeEvents) GetRules() []RuleKubeEvents {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeEvents) GetMetadata() []MetadatumKubeEvents {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeEvents) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeEvents) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeKubeLogs string

const (
	TypeKubeLogsKubeLogs TypeKubeLogs = "kube_logs"
)

func (e TypeKubeLogs) ToPointer() *TypeKubeLogs {
	return &e
}
func (e *TypeKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_logs":
		*e = TypeKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeLogs: %v", v)
	}
}

type ConnectionKubeLogs struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKubeLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKubeLogs) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeKubeLogs - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeLogs string

const (
	ModeKubeLogsSmart  ModeKubeLogs = "smart"
	ModeKubeLogsAlways ModeKubeLogs = "always"
)

func (e ModeKubeLogs) ToPointer() *ModeKubeLogs {
	return &e
}
func (e *ModeKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeKubeLogs: %v", v)
	}
}

// PqCompressionKubeLogs - Codec to use to compress the persisted data
type PqCompressionKubeLogs string

const (
	PqCompressionKubeLogsNone PqCompressionKubeLogs = "none"
	PqCompressionKubeLogsGzip PqCompressionKubeLogs = "gzip"
)

func (e PqCompressionKubeLogs) ToPointer() *PqCompressionKubeLogs {
	return &e
}
func (e *PqCompressionKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionKubeLogs: %v", v)
	}
}

type PqKubeLogs struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeLogs `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionKubeLogs `default:"none" json:"compress"`
}

func (p PqKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKubeLogs) GetMode() *ModeKubeLogs {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKubeLogs) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKubeLogs) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKubeLogs) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKubeLogs) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKubeLogs) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKubeLogs) GetCompress() *PqCompressionKubeLogs {
	if o == nil {
		return nil
	}
	return o.Compress
}

type RuleKubeLogs struct {
	// JavaScript expression applied to Pod objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *RuleKubeLogs) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *RuleKubeLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type MetadatumKubeLogs struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKubeLogs) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKubeLogs) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// PersistenceCompressionKubeLogs - Data compression format. Default is gzip.
type PersistenceCompressionKubeLogs string

const (
	PersistenceCompressionKubeLogsNone PersistenceCompressionKubeLogs = "none"
	PersistenceCompressionKubeLogsGzip PersistenceCompressionKubeLogs = "gzip"
)

func (e PersistenceCompressionKubeLogs) ToPointer() *PersistenceCompressionKubeLogs {
	return &e
}
func (e *PersistenceCompressionKubeLogs) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PersistenceCompressionKubeLogs(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PersistenceCompressionKubeLogs: %v", v)
	}
}

type DiskSpoolingKubeLogs struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *PersistenceCompressionKubeLogs `default:"gzip" json:"compress"`
}

func (d DiskSpoolingKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpoolingKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskSpoolingKubeLogs) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *DiskSpoolingKubeLogs) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *DiskSpoolingKubeLogs) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *DiskSpoolingKubeLogs) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *DiskSpoolingKubeLogs) GetCompress() *PersistenceCompressionKubeLogs {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputKubeLogs struct {
	// Unique ID for this input
	ID       string       `json:"id"`
	Type     TypeKubeLogs `json:"type"`
	Disabled *bool        `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeLogs `json:"connections,omitempty"`
	Pq          *PqKubeLogs          `json:"pq,omitempty"`
	// Time, in seconds, between checks for new containers. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Pods to collect logs from. Logs are collected if no rules are given or if all the rules' expressions evaluate to true.
	Rules []RuleKubeLogs `json:"rules,omitempty"`
	// For use when containers do not emit a timestamp, prefix each line of output with a timestamp. If you enable this setting, you can use the Kubernetes Logs Event Breaker and the kubernetes_logs Pre-processing Pipeline to remove them from the events after the timestamps are extracted.
	Timestamps *bool `default:"false" json:"timestamps"`
	// Fields to add to events from this input
	Metadata    []MetadatumKubeLogs   `json:"metadata,omitempty"`
	Persistence *DiskSpoolingKubeLogs `json:"persistence,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputKubeLogs) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeLogs) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeLogs) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeLogs) GetType() TypeKubeLogs {
	if o == nil {
		return TypeKubeLogs("")
	}
	return o.Type
}

func (o *InputKubeLogs) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeLogs) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeLogs) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeLogs) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeLogs) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeLogs) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeLogs) GetConnections() []ConnectionKubeLogs {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeLogs) GetPq() *PqKubeLogs {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeLogs) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputKubeLogs) GetRules() []RuleKubeLogs {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeLogs) GetTimestamps() *bool {
	if o == nil {
		return nil
	}
	return o.Timestamps
}

func (o *InputKubeLogs) GetMetadata() []MetadatumKubeLogs {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeLogs) GetPersistence() *DiskSpoolingKubeLogs {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputKubeLogs) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputKubeLogs) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputKubeLogs) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputKubeLogs) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeLogs) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeKubeMetrics string

const (
	TypeKubeMetricsKubeMetrics TypeKubeMetrics = "kube_metrics"
)

func (e TypeKubeMetrics) ToPointer() *TypeKubeMetrics {
	return &e
}
func (e *TypeKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kube_metrics":
		*e = TypeKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeKubeMetrics: %v", v)
	}
}

type ConnectionKubeMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKubeMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKubeMetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeKubeMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeKubeMetrics string

const (
	ModeKubeMetricsSmart  ModeKubeMetrics = "smart"
	ModeKubeMetricsAlways ModeKubeMetrics = "always"
)

func (e ModeKubeMetrics) ToPointer() *ModeKubeMetrics {
	return &e
}
func (e *ModeKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeKubeMetrics: %v", v)
	}
}

// CompressionKubeMetrics - Codec to use to compress the persisted data
type CompressionKubeMetrics string

const (
	CompressionKubeMetricsNone CompressionKubeMetrics = "none"
	CompressionKubeMetricsGzip CompressionKubeMetrics = "gzip"
)

func (e CompressionKubeMetrics) ToPointer() *CompressionKubeMetrics {
	return &e
}
func (e *CompressionKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionKubeMetrics: %v", v)
	}
}

type PqKubeMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeKubeMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionKubeMetrics `default:"none" json:"compress"`
}

func (p PqKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKubeMetrics) GetMode() *ModeKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKubeMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKubeMetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKubeMetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKubeMetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKubeMetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKubeMetrics) GetCompress() *CompressionKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

type RuleKubeMetrics struct {
	// JavaScript expression applied to Kubernetes objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *RuleKubeMetrics) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *RuleKubeMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type MetadatumKubeMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKubeMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKubeMetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type DataCompressionFormatKubeMetrics string

const (
	DataCompressionFormatKubeMetricsNone DataCompressionFormatKubeMetrics = "none"
	DataCompressionFormatKubeMetricsGzip DataCompressionFormatKubeMetrics = "gzip"
)

func (e DataCompressionFormatKubeMetrics) ToPointer() *DataCompressionFormatKubeMetrics {
	return &e
}
func (e *DataCompressionFormatKubeMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormatKubeMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormatKubeMetrics: %v", v)
	}
}

type PersistenceKubeMetrics struct {
	// Spool metrics on disk for Cribl Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                           `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatKubeMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/<id>
	DestPath *string `default:"\\$CRIBL_HOME/state/kube_metrics" json:"destPath"`
}

func (p PersistenceKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PersistenceKubeMetrics) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *PersistenceKubeMetrics) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *PersistenceKubeMetrics) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *PersistenceKubeMetrics) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *PersistenceKubeMetrics) GetCompress() *DataCompressionFormatKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *PersistenceKubeMetrics) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputKubeMetrics struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeKubeMetrics `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKubeMetrics `json:"connections,omitempty"`
	Pq          *PqKubeMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metrics collections. Default is 15 secs.
	Interval *float64 `default:"15" json:"interval"`
	// Add rules to decide which Kubernetes objects to generate metrics for. Events are generated if no rules are given or of all the rules' expressions evaluate to true.
	Rules []RuleKubeMetrics `json:"rules,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumKubeMetrics  `json:"metadata,omitempty"`
	Persistence *PersistenceKubeMetrics `json:"persistence,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputKubeMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKubeMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKubeMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputKubeMetrics) GetType() TypeKubeMetrics {
	if o == nil {
		return TypeKubeMetrics("")
	}
	return o.Type
}

func (o *InputKubeMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKubeMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKubeMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKubeMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKubeMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKubeMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKubeMetrics) GetConnections() []ConnectionKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKubeMetrics) GetPq() *PqKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKubeMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputKubeMetrics) GetRules() []RuleKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Rules
}

func (o *InputKubeMetrics) GetMetadata() []MetadatumKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKubeMetrics) GetPersistence() *PersistenceKubeMetrics {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputKubeMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKubeMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeSystemState string

const (
	TypeSystemStateSystemState TypeSystemState = "system_state"
)

func (e TypeSystemState) ToPointer() *TypeSystemState {
	return &e
}
func (e *TypeSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_state":
		*e = TypeSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemState: %v", v)
	}
}

type ConnectionSystemState struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSystemState) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSystemState) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSystemState - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSystemState string

const (
	ModeSystemStateSmart  ModeSystemState = "smart"
	ModeSystemStateAlways ModeSystemState = "always"
)

func (e ModeSystemState) ToPointer() *ModeSystemState {
	return &e
}
func (e *ModeSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSystemState: %v", v)
	}
}

// CompressionSystemState - Codec to use to compress the persisted data
type CompressionSystemState string

const (
	CompressionSystemStateNone CompressionSystemState = "none"
	CompressionSystemStateGzip CompressionSystemState = "gzip"
)

func (e CompressionSystemState) ToPointer() *CompressionSystemState {
	return &e
}
func (e *CompressionSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSystemState: %v", v)
	}
}

type PqSystemState struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSystemState `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSystemState `default:"none" json:"compress"`
}

func (p PqSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSystemState) GetMode() *ModeSystemState {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSystemState) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSystemState) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSystemState) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSystemState) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSystemState) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSystemState) GetCompress() *CompressionSystemState {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumSystemState struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSystemState) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSystemState) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// HostsFile - Creates events based on entries collected from the hosts file
type HostsFile struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostsFile) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostsFile) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostsFile) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// Interfaces - Creates events for each of the hosts network interfaces
type Interfaces struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i Interfaces) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *Interfaces) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Interfaces) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// DisksAndFileSystems - Creates events for physical disks, partitions, and file systems
type DisksAndFileSystems struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DisksAndFileSystems) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DisksAndFileSystems) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DisksAndFileSystems) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// HostInfo - Creates events based on the host systems current state
type HostInfo struct {
	Enable *bool `default:"true" json:"enable"`
}

func (h HostInfo) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostInfo) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostInfo) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// InputRoutes - Creates events based on entries collected from the hosts network routes
type InputRoutes struct {
	Enable *bool `default:"true" json:"enable"`
}

func (i InputRoutes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputRoutes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputRoutes) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// DNS - Creates events for DNS resolvers and search entries
type DNS struct {
	Enable *bool `default:"true" json:"enable"`
}

func (d DNS) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DNS) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DNS) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// UsersAndGroups - Creates events for local users and groups
type UsersAndGroups struct {
	Enable *bool `default:"true" json:"enable"`
}

func (u UsersAndGroups) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(u, "", false)
}

func (u *UsersAndGroups) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &u, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *UsersAndGroups) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// Firewall - Creates events for Firewall rules entries
type Firewall struct {
	Enable *bool `default:"true" json:"enable"`
}

func (f Firewall) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(f, "", false)
}

func (f *Firewall) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &f, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Firewall) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// Services - Creates events from the list of services
type Services struct {
	Enable *bool `default:"true" json:"enable"`
}

func (s Services) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *Services) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Services) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// ListeningPorts - Creates events from list of listening ports
type ListeningPorts struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l ListeningPorts) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *ListeningPorts) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ListeningPorts) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

// LoggedInUsers - Creates events from list of logged-in users
type LoggedInUsers struct {
	Enable *bool `default:"true" json:"enable"`
}

func (l LoggedInUsers) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(l, "", false)
}

func (l *LoggedInUsers) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &l, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *LoggedInUsers) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

type Collectors struct {
	// Creates events based on entries collected from the hosts file
	Hostsfile *HostsFile `json:"hostsfile,omitempty"`
	// Creates events for each of the hosts network interfaces
	Interfaces *Interfaces `json:"interfaces,omitempty"`
	// Creates events for physical disks, partitions, and file systems
	Disk *DisksAndFileSystems `json:"disk,omitempty"`
	// Creates events based on the host systems current state
	Metadata *HostInfo `json:"metadata,omitempty"`
	// Creates events based on entries collected from the hosts network routes
	Routes *InputRoutes `json:"routes,omitempty"`
	// Creates events for DNS resolvers and search entries
	DNS *DNS `json:"dns,omitempty"`
	// Creates events for local users and groups
	User *UsersAndGroups `json:"user,omitempty"`
	// Creates events for Firewall rules entries
	Firewall *Firewall `json:"firewall,omitempty"`
	// Creates events from the list of services
	Services *Services `json:"services,omitempty"`
	// Creates events from list of listening ports
	Ports *ListeningPorts `json:"ports,omitempty"`
	// Creates events from list of logged-in users
	LoginUsers *LoggedInUsers `json:"loginUsers,omitempty"`
}

func (o *Collectors) GetHostsfile() *HostsFile {
	if o == nil {
		return nil
	}
	return o.Hostsfile
}

func (o *Collectors) GetInterfaces() *Interfaces {
	if o == nil {
		return nil
	}
	return o.Interfaces
}

func (o *Collectors) GetDisk() *DisksAndFileSystems {
	if o == nil {
		return nil
	}
	return o.Disk
}

func (o *Collectors) GetMetadata() *HostInfo {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *Collectors) GetRoutes() *InputRoutes {
	if o == nil {
		return nil
	}
	return o.Routes
}

func (o *Collectors) GetDNS() *DNS {
	if o == nil {
		return nil
	}
	return o.DNS
}

func (o *Collectors) GetUser() *UsersAndGroups {
	if o == nil {
		return nil
	}
	return o.User
}

func (o *Collectors) GetFirewall() *Firewall {
	if o == nil {
		return nil
	}
	return o.Firewall
}

func (o *Collectors) GetServices() *Services {
	if o == nil {
		return nil
	}
	return o.Services
}

func (o *Collectors) GetPorts() *ListeningPorts {
	if o == nil {
		return nil
	}
	return o.Ports
}

func (o *Collectors) GetLoginUsers() *LoggedInUsers {
	if o == nil {
		return nil
	}
	return o.LoginUsers
}

type DataCompressionFormatSystemState string

const (
	DataCompressionFormatSystemStateNone DataCompressionFormatSystemState = "none"
	DataCompressionFormatSystemStateGzip DataCompressionFormatSystemState = "gzip"
)

func (e DataCompressionFormatSystemState) ToPointer() *DataCompressionFormatSystemState {
	return &e
}
func (e *DataCompressionFormatSystemState) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormatSystemState(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormatSystemState: %v", v)
	}
}

type PersistenceSystemState struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                           `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatSystemState `default:"none" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state
	DestPath *string `default:"\\$CRIBL_HOME/state/system_state" json:"destPath"`
}

func (p PersistenceSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PersistenceSystemState) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *PersistenceSystemState) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *PersistenceSystemState) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *PersistenceSystemState) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *PersistenceSystemState) GetCompress() *DataCompressionFormatSystemState {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *PersistenceSystemState) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputSystemState struct {
	// Unique ID for this input
	ID       string          `json:"id"`
	Type     TypeSystemState `json:"type"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSystemState `json:"connections,omitempty"`
	Pq          *PqSystemState          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes).
	Interval *float64 `default:"300" json:"interval"`
	// Fields to add to events from this input
	Metadata    []MetadatumSystemState  `json:"metadata,omitempty"`
	Collectors  *Collectors             `json:"collectors,omitempty"`
	Persistence *PersistenceSystemState `json:"persistence,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Status      *TFStatus               `json:"status,omitempty"`
}

func (i InputSystemState) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemState) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemState) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSystemState) GetType() TypeSystemState {
	if o == nil {
		return TypeSystemState("")
	}
	return o.Type
}

func (o *InputSystemState) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSystemState) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemState) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSystemState) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSystemState) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSystemState) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSystemState) GetConnections() []ConnectionSystemState {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSystemState) GetPq() *PqSystemState {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSystemState) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputSystemState) GetMetadata() []MetadatumSystemState {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSystemState) GetCollectors() *Collectors {
	if o == nil {
		return nil
	}
	return o.Collectors
}

func (o *InputSystemState) GetPersistence() *PersistenceSystemState {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputSystemState) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSystemState) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeSystemMetrics string

const (
	TypeSystemMetricsSystemMetrics TypeSystemMetrics = "system_metrics"
)

func (e TypeSystemMetrics) ToPointer() *TypeSystemMetrics {
	return &e
}
func (e *TypeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "system_metrics":
		*e = TypeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSystemMetrics: %v", v)
	}
}

type ConnectionSystemMetrics struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSystemMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSystemMetrics) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeSystemMetrics - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSystemMetrics string

const (
	PqModeSystemMetricsSmart  PqModeSystemMetrics = "smart"
	PqModeSystemMetricsAlways PqModeSystemMetrics = "always"
)

func (e PqModeSystemMetrics) ToPointer() *PqModeSystemMetrics {
	return &e
}
func (e *PqModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeSystemMetrics: %v", v)
	}
}

// CompressionSystemMetrics - Codec to use to compress the persisted data
type CompressionSystemMetrics string

const (
	CompressionSystemMetricsNone CompressionSystemMetrics = "none"
	CompressionSystemMetricsGzip CompressionSystemMetrics = "gzip"
)

func (e CompressionSystemMetrics) ToPointer() *CompressionSystemMetrics {
	return &e
}
func (e *CompressionSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSystemMetrics: %v", v)
	}
}

type PqSystemMetrics struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSystemMetrics `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSystemMetrics `default:"none" json:"compress"`
}

func (p PqSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSystemMetrics) GetMode() *PqModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSystemMetrics) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSystemMetrics) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSystemMetrics) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSystemMetrics) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSystemMetrics) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSystemMetrics) GetCompress() *CompressionSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

// HostModeSystemMetrics - Select level of detail for host metrics
type HostModeSystemMetrics string

const (
	HostModeSystemMetricsBasic    HostModeSystemMetrics = "basic"
	HostModeSystemMetricsAll      HostModeSystemMetrics = "all"
	HostModeSystemMetricsCustom   HostModeSystemMetrics = "custom"
	HostModeSystemMetricsDisabled HostModeSystemMetrics = "disabled"
)

func (e HostModeSystemMetrics) ToPointer() *HostModeSystemMetrics {
	return &e
}
func (e *HostModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = HostModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for HostModeSystemMetrics: %v", v)
	}
}

// SystemModeSystemMetrics - Select the level of detail for system metrics
type SystemModeSystemMetrics string

const (
	SystemModeSystemMetricsBasic    SystemModeSystemMetrics = "basic"
	SystemModeSystemMetricsAll      SystemModeSystemMetrics = "all"
	SystemModeSystemMetricsCustom   SystemModeSystemMetrics = "custom"
	SystemModeSystemMetricsDisabled SystemModeSystemMetrics = "disabled"
)

func (e SystemModeSystemMetrics) ToPointer() *SystemModeSystemMetrics {
	return &e
}
func (e *SystemModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = SystemModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SystemModeSystemMetrics: %v", v)
	}
}

type SystemSystemMetrics struct {
	// Select the level of detail for system metrics
	Mode *SystemModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for the numbers of processes in various states
	Processes *bool `default:"false" json:"processes"`
}

func (s SystemSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SystemSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SystemSystemMetrics) GetMode() *SystemModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *SystemSystemMetrics) GetProcesses() *bool {
	if o == nil {
		return nil
	}
	return o.Processes
}

// CPUModeSystemMetrics - Select the level of detail for CPU metrics
type CPUModeSystemMetrics string

const (
	CPUModeSystemMetricsBasic    CPUModeSystemMetrics = "basic"
	CPUModeSystemMetricsAll      CPUModeSystemMetrics = "all"
	CPUModeSystemMetricsCustom   CPUModeSystemMetrics = "custom"
	CPUModeSystemMetricsDisabled CPUModeSystemMetrics = "disabled"
)

func (e CPUModeSystemMetrics) ToPointer() *CPUModeSystemMetrics {
	return &e
}
func (e *CPUModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = CPUModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CPUModeSystemMetrics: %v", v)
	}
}

type CPUSystemMetrics struct {
	// Select the level of detail for CPU metrics
	Mode *CPUModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for each CPU
	PerCPU *bool `default:"false" json:"perCpu"`
	// Generate metrics for all CPU states
	Detail *bool `default:"false" json:"detail"`
	// Generate raw, monotonic CPU time counters
	Time *bool `default:"false" json:"time"`
}

func (c CPUSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CPUSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CPUSystemMetrics) GetMode() *CPUModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *CPUSystemMetrics) GetPerCPU() *bool {
	if o == nil {
		return nil
	}
	return o.PerCPU
}

func (o *CPUSystemMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

func (o *CPUSystemMetrics) GetTime() *bool {
	if o == nil {
		return nil
	}
	return o.Time
}

// MemoryModeSystemMetrics - Select the level of detail for memory metrics
type MemoryModeSystemMetrics string

const (
	MemoryModeSystemMetricsBasic    MemoryModeSystemMetrics = "basic"
	MemoryModeSystemMetricsAll      MemoryModeSystemMetrics = "all"
	MemoryModeSystemMetricsCustom   MemoryModeSystemMetrics = "custom"
	MemoryModeSystemMetricsDisabled MemoryModeSystemMetrics = "disabled"
)

func (e MemoryModeSystemMetrics) ToPointer() *MemoryModeSystemMetrics {
	return &e
}
func (e *MemoryModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = MemoryModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MemoryModeSystemMetrics: %v", v)
	}
}

type MemorySystemMetrics struct {
	// Select the level of detail for memory metrics
	Mode *MemoryModeSystemMetrics `default:"basic" json:"mode"`
	// Generate metrics for all memory states
	Detail *bool `default:"false" json:"detail"`
}

func (m MemorySystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(m, "", false)
}

func (m *MemorySystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &m, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *MemorySystemMetrics) GetMode() *MemoryModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *MemorySystemMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// NetworkModeSystemMetrics - Select the level of detail for network metrics
type NetworkModeSystemMetrics string

const (
	NetworkModeSystemMetricsBasic    NetworkModeSystemMetrics = "basic"
	NetworkModeSystemMetricsAll      NetworkModeSystemMetrics = "all"
	NetworkModeSystemMetricsCustom   NetworkModeSystemMetrics = "custom"
	NetworkModeSystemMetricsDisabled NetworkModeSystemMetrics = "disabled"
)

func (e NetworkModeSystemMetrics) ToPointer() *NetworkModeSystemMetrics {
	return &e
}
func (e *NetworkModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = NetworkModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for NetworkModeSystemMetrics: %v", v)
	}
}

type NetworkSystemMetrics struct {
	// Select the level of detail for network metrics
	Mode *NetworkModeSystemMetrics `default:"basic" json:"mode"`
	// Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Generate separate metrics for each interface
	PerInterface *bool `default:"false" json:"perInterface"`
	// Generate full network metrics
	Detail *bool `default:"false" json:"detail"`
}

func (n NetworkSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(n, "", false)
}

func (n *NetworkSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &n, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *NetworkSystemMetrics) GetMode() *NetworkModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *NetworkSystemMetrics) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *NetworkSystemMetrics) GetPerInterface() *bool {
	if o == nil {
		return nil
	}
	return o.PerInterface
}

func (o *NetworkSystemMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

// DiskModeSystemMetrics - Select the level of detail for disk metrics
type DiskModeSystemMetrics string

const (
	DiskModeSystemMetricsBasic    DiskModeSystemMetrics = "basic"
	DiskModeSystemMetricsAll      DiskModeSystemMetrics = "all"
	DiskModeSystemMetricsCustom   DiskModeSystemMetrics = "custom"
	DiskModeSystemMetricsDisabled DiskModeSystemMetrics = "disabled"
)

func (e DiskModeSystemMetrics) ToPointer() *DiskModeSystemMetrics {
	return &e
}
func (e *DiskModeSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = DiskModeSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiskModeSystemMetrics: %v", v)
	}
}

type DiskSystemMetrics struct {
	// Select the level of detail for disk metrics
	Mode *DiskModeSystemMetrics `default:"basic" json:"mode"`
	// Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty.
	Devices []string `json:"devices,omitempty"`
	// Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty.
	Mountpoints []string `json:"mountpoints,omitempty"`
	// Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty.
	Fstypes []string `json:"fstypes,omitempty"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
	// Generate full disk metrics
	Detail *bool `default:"false" json:"detail"`
}

func (d DiskSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskSystemMetrics) GetMode() *DiskModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *DiskSystemMetrics) GetDevices() []string {
	if o == nil {
		return nil
	}
	return o.Devices
}

func (o *DiskSystemMetrics) GetMountpoints() []string {
	if o == nil {
		return nil
	}
	return o.Mountpoints
}

func (o *DiskSystemMetrics) GetFstypes() []string {
	if o == nil {
		return nil
	}
	return o.Fstypes
}

func (o *DiskSystemMetrics) GetPerDevice() *bool {
	if o == nil {
		return nil
	}
	return o.PerDevice
}

func (o *DiskSystemMetrics) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

type CustomSystemMetrics struct {
	System  *SystemSystemMetrics  `json:"system,omitempty"`
	CPU     *CPUSystemMetrics     `json:"cpu,omitempty"`
	Memory  *MemorySystemMetrics  `json:"memory,omitempty"`
	Network *NetworkSystemMetrics `json:"network,omitempty"`
	Disk    *DiskSystemMetrics    `json:"disk,omitempty"`
}

func (o *CustomSystemMetrics) GetSystem() *SystemSystemMetrics {
	if o == nil {
		return nil
	}
	return o.System
}

func (o *CustomSystemMetrics) GetCPU() *CPUSystemMetrics {
	if o == nil {
		return nil
	}
	return o.CPU
}

func (o *CustomSystemMetrics) GetMemory() *MemorySystemMetrics {
	if o == nil {
		return nil
	}
	return o.Memory
}

func (o *CustomSystemMetrics) GetNetwork() *NetworkSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Network
}

func (o *CustomSystemMetrics) GetDisk() *DiskSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Disk
}

type HostSystemMetrics struct {
	// Select level of detail for host metrics
	Mode   *HostModeSystemMetrics `default:"basic" json:"mode"`
	Custom *CustomSystemMetrics   `json:"custom,omitempty"`
}

func (h HostSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(h, "", false)
}

func (h *HostSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &h, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *HostSystemMetrics) GetMode() *HostModeSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *HostSystemMetrics) GetCustom() *CustomSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Custom
}

type SetSystemMetrics struct {
	Name            string `json:"name"`
	Filter          string `json:"filter"`
	IncludeChildren *bool  `default:"false" json:"includeChildren"`
}

func (s SetSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(s, "", false)
}

func (s *SetSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &s, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *SetSystemMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SetSystemMetrics) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *SetSystemMetrics) GetIncludeChildren() *bool {
	if o == nil {
		return nil
	}
	return o.IncludeChildren
}

type ProcessSystemMetrics struct {
	// Configure sets to collect process metrics
	Sets []SetSystemMetrics `json:"sets,omitempty"`
}

func (o *ProcessSystemMetrics) GetSets() []SetSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Sets
}

// ContainerMode - Select the level of detail for container metrics
type ContainerMode string

const (
	ContainerModeBasic    ContainerMode = "basic"
	ContainerModeAll      ContainerMode = "all"
	ContainerModeCustom   ContainerMode = "custom"
	ContainerModeDisabled ContainerMode = "disabled"
)

func (e ContainerMode) ToPointer() *ContainerMode {
	return &e
}
func (e *ContainerMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "all":
		fallthrough
	case "custom":
		fallthrough
	case "disabled":
		*e = ContainerMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ContainerMode: %v", v)
	}
}

type ContainerFilter struct {
	Expr string `json:"expr"`
}

func (o *ContainerFilter) GetExpr() string {
	if o == nil {
		return ""
	}
	return o.Expr
}

type InputContainer struct {
	// Select the level of detail for container metrics
	Mode *ContainerMode `default:"basic" json:"mode"`
	// Full paths for Docker's UNIX-domain socket
	DockerSocket []string `json:"dockerSocket,omitempty"`
	// Timeout, in seconds, for the Docker API
	DockerTimeout *float64 `default:"5" json:"dockerTimeout"`
	// Containers matching any of these will be included. All are included if no filters are added.
	Filters []ContainerFilter `json:"filters,omitempty"`
	// Include stopped and paused containers
	AllContainers *bool `default:"false" json:"allContainers"`
	// Generate separate metrics for each device
	PerDevice *bool `default:"false" json:"perDevice"`
	// Generate full container metrics
	Detail *bool `default:"false" json:"detail"`
}

func (i InputContainer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputContainer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputContainer) GetMode() *ContainerMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputContainer) GetDockerSocket() []string {
	if o == nil {
		return nil
	}
	return o.DockerSocket
}

func (o *InputContainer) GetDockerTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.DockerTimeout
}

func (o *InputContainer) GetFilters() []ContainerFilter {
	if o == nil {
		return nil
	}
	return o.Filters
}

func (o *InputContainer) GetAllContainers() *bool {
	if o == nil {
		return nil
	}
	return o.AllContainers
}

func (o *InputContainer) GetPerDevice() *bool {
	if o == nil {
		return nil
	}
	return o.PerDevice
}

func (o *InputContainer) GetDetail() *bool {
	if o == nil {
		return nil
	}
	return o.Detail
}

type MetadatumSystemMetrics struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSystemMetrics) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSystemMetrics) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type DataCompressionFormatSystemMetrics string

const (
	DataCompressionFormatSystemMetricsNone DataCompressionFormatSystemMetrics = "none"
	DataCompressionFormatSystemMetricsGzip DataCompressionFormatSystemMetrics = "gzip"
)

func (e DataCompressionFormatSystemMetrics) ToPointer() *DataCompressionFormatSystemMetrics {
	return &e
}
func (e *DataCompressionFormatSystemMetrics) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = DataCompressionFormatSystemMetrics(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DataCompressionFormatSystemMetrics: %v", v)
	}
}

type PersistenceSystemMetrics struct {
	// Spool metrics to disk for Cribl Edge and Search
	Enable *bool `default:"false" json:"enable"`
	// Time span for each file bucket
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted.
	MaxDataTime *string                             `default:"24h" json:"maxDataTime"`
	Compress    *DataCompressionFormatSystemMetrics `default:"gzip" json:"compress"`
	// Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics
	DestPath *string `default:"\\$CRIBL_HOME/state/system_metrics" json:"destPath"`
}

func (p PersistenceSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PersistenceSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PersistenceSystemMetrics) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *PersistenceSystemMetrics) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *PersistenceSystemMetrics) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *PersistenceSystemMetrics) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *PersistenceSystemMetrics) GetCompress() *DataCompressionFormatSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *PersistenceSystemMetrics) GetDestPath() *string {
	if o == nil {
		return nil
	}
	return o.DestPath
}

type InputSystemMetrics struct {
	// Unique ID for this input
	ID       string            `json:"id"`
	Type     TypeSystemMetrics `json:"type"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSystemMetrics `json:"connections,omitempty"`
	Pq          *PqSystemMetrics          `json:"pq,omitempty"`
	// Time, in seconds, between consecutive metric collections. Default is 10 seconds.
	Interval  *float64              `default:"10" json:"interval"`
	Host      *HostSystemMetrics    `json:"host,omitempty"`
	Process   *ProcessSystemMetrics `json:"process,omitempty"`
	Container *InputContainer       `json:"container,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumSystemMetrics  `json:"metadata,omitempty"`
	Persistence *PersistenceSystemMetrics `json:"persistence,omitempty"`
	Description *string                   `json:"description,omitempty"`
	Status      *TFStatus                 `json:"status,omitempty"`
}

func (i InputSystemMetrics) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSystemMetrics) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSystemMetrics) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputSystemMetrics) GetType() TypeSystemMetrics {
	if o == nil {
		return TypeSystemMetrics("")
	}
	return o.Type
}

func (o *InputSystemMetrics) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSystemMetrics) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSystemMetrics) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSystemMetrics) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSystemMetrics) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSystemMetrics) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSystemMetrics) GetConnections() []ConnectionSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSystemMetrics) GetPq() *PqSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSystemMetrics) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputSystemMetrics) GetHost() *HostSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSystemMetrics) GetProcess() *ProcessSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Process
}

func (o *InputSystemMetrics) GetContainer() *InputContainer {
	if o == nil {
		return nil
	}
	return o.Container
}

func (o *InputSystemMetrics) GetMetadata() []MetadatumSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSystemMetrics) GetPersistence() *PersistenceSystemMetrics {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputSystemMetrics) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSystemMetrics) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeTcpjson string

const (
	InputTypeTcpjsonTcpjson InputTypeTcpjson = "tcpjson"
)

func (e InputTypeTcpjson) ToPointer() *InputTypeTcpjson {
	return &e
}
func (e *InputTypeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "tcpjson":
		*e = InputTypeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeTcpjson: %v", v)
	}
}

type ConnectionTcpjson struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionTcpjson) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeTcpjson - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeTcpjson string

const (
	PqModeTcpjsonSmart  PqModeTcpjson = "smart"
	PqModeTcpjsonAlways PqModeTcpjson = "always"
)

func (e PqModeTcpjson) ToPointer() *PqModeTcpjson {
	return &e
}
func (e *PqModeTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeTcpjson: %v", v)
	}
}

// PqCompressionTcpjson - Codec to use to compress the persisted data
type PqCompressionTcpjson string

const (
	PqCompressionTcpjsonNone PqCompressionTcpjson = "none"
	PqCompressionTcpjsonGzip PqCompressionTcpjson = "gzip"
)

func (e PqCompressionTcpjson) ToPointer() *PqCompressionTcpjson {
	return &e
}
func (e *PqCompressionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionTcpjson: %v", v)
	}
}

type PqTcpjson struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeTcpjson `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionTcpjson `default:"none" json:"compress"`
}

func (p PqTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqTcpjson) GetMode() *PqModeTcpjson {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqTcpjson) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqTcpjson) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqTcpjson) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqTcpjson) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqTcpjson) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqTcpjson) GetCompress() *PqCompressionTcpjson {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionTcpjson - Minimum TLS version to accept from connections
type InputMinimumTLSVersionTcpjson string

const (
	InputMinimumTLSVersionTcpjsonTlSv1  InputMinimumTLSVersionTcpjson = "TLSv1"
	InputMinimumTLSVersionTcpjsonTlSv11 InputMinimumTLSVersionTcpjson = "TLSv1.1"
	InputMinimumTLSVersionTcpjsonTlSv12 InputMinimumTLSVersionTcpjson = "TLSv1.2"
	InputMinimumTLSVersionTcpjsonTlSv13 InputMinimumTLSVersionTcpjson = "TLSv1.3"
)

func (e InputMinimumTLSVersionTcpjson) ToPointer() *InputMinimumTLSVersionTcpjson {
	return &e
}
func (e *InputMinimumTLSVersionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionTcpjson: %v", v)
	}
}

// InputMaximumTLSVersionTcpjson - Maximum TLS version to accept from connections
type InputMaximumTLSVersionTcpjson string

const (
	InputMaximumTLSVersionTcpjsonTlSv1  InputMaximumTLSVersionTcpjson = "TLSv1"
	InputMaximumTLSVersionTcpjsonTlSv11 InputMaximumTLSVersionTcpjson = "TLSv1.1"
	InputMaximumTLSVersionTcpjsonTlSv12 InputMaximumTLSVersionTcpjson = "TLSv1.2"
	InputMaximumTLSVersionTcpjsonTlSv13 InputMaximumTLSVersionTcpjson = "TLSv1.3"
)

func (e InputMaximumTLSVersionTcpjson) ToPointer() *InputMaximumTLSVersionTcpjson {
	return &e
}
func (e *InputMaximumTLSVersionTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionTcpjson: %v", v)
	}
}

type TLSSettingsServerSideTcpjson struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMinimumTLSVersionTcpjson `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMaximumTLSVersionTcpjson `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideTcpjson) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideTcpjson) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideTcpjson) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideTcpjson) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideTcpjson) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideTcpjson) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideTcpjson) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideTcpjson) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideTcpjson) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideTcpjson) GetMinVersion() *InputMinimumTLSVersionTcpjson {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideTcpjson) GetMaxVersion() *InputMaximumTLSVersionTcpjson {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumTcpjson struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumTcpjson) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumTcpjson) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputAuthenticationMethodTcpjson - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type InputAuthenticationMethodTcpjson string

const (
	InputAuthenticationMethodTcpjsonManual InputAuthenticationMethodTcpjson = "manual"
	InputAuthenticationMethodTcpjsonSecret InputAuthenticationMethodTcpjson = "secret"
)

func (e InputAuthenticationMethodTcpjson) ToPointer() *InputAuthenticationMethodTcpjson {
	return &e
}
func (e *InputAuthenticationMethodTcpjson) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodTcpjson(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodTcpjson: %v", v)
	}
}

type InputTcpjson struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputTypeTcpjson `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionTcpjson `json:"connections,omitempty"`
	Pq          *PqTcpjson          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideTcpjson `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumTcpjson `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool `default:"false" json:"enableLoadBalancing"`
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *InputAuthenticationMethodTcpjson `default:"manual" json:"authType"`
	Description *string                           `json:"description,omitempty"`
	// Shared secret to be provided by any client (in authToken header field). If empty, unauthorized access is permitted.
	AuthToken *string `default:"" json:"authToken"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputTcpjson) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTcpjson) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputTcpjson) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputTcpjson) GetType() *InputTypeTcpjson {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputTcpjson) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTcpjson) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputTcpjson) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputTcpjson) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputTcpjson) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputTcpjson) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputTcpjson) GetConnections() []ConnectionTcpjson {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputTcpjson) GetPq() *PqTcpjson {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputTcpjson) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputTcpjson) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputTcpjson) GetTLS() *TLSSettingsServerSideTcpjson {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputTcpjson) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputTcpjson) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputTcpjson) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputTcpjson) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputTcpjson) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputTcpjson) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputTcpjson) GetMetadata() []MetadatumTcpjson {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputTcpjson) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputTcpjson) GetAuthType() *InputAuthenticationMethodTcpjson {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputTcpjson) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputTcpjson) GetAuthToken() *string {
	if o == nil {
		return nil
	}
	return o.AuthToken
}

func (o *InputTcpjson) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputTcpjson) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeCriblHTTP string

const (
	InputTypeCriblHTTPCriblHTTP InputTypeCriblHTTP = "cribl_http"
)

func (e InputTypeCriblHTTP) ToPointer() *InputTypeCriblHTTP {
	return &e
}
func (e *InputTypeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_http":
		*e = InputTypeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCriblHTTP: %v", v)
	}
}

type ConnectionCriblHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblHTTP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeCriblHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeCriblHTTP string

const (
	PqModeCriblHTTPSmart  PqModeCriblHTTP = "smart"
	PqModeCriblHTTPAlways PqModeCriblHTTP = "always"
)

func (e PqModeCriblHTTP) ToPointer() *PqModeCriblHTTP {
	return &e
}
func (e *PqModeCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeCriblHTTP: %v", v)
	}
}

// PqCompressionCriblHTTP - Codec to use to compress the persisted data
type PqCompressionCriblHTTP string

const (
	PqCompressionCriblHTTPNone PqCompressionCriblHTTP = "none"
	PqCompressionCriblHTTPGzip PqCompressionCriblHTTP = "gzip"
)

func (e PqCompressionCriblHTTP) ToPointer() *PqCompressionCriblHTTP {
	return &e
}
func (e *PqCompressionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionCriblHTTP: %v", v)
	}
}

type PqCriblHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeCriblHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionCriblHTTP `default:"none" json:"compress"`
}

func (p PqCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblHTTP) GetMode() *PqModeCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblHTTP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblHTTP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblHTTP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblHTTP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblHTTP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblHTTP) GetCompress() *PqCompressionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionCriblHTTP - Minimum TLS version to accept from connections
type InputMinimumTLSVersionCriblHTTP string

const (
	InputMinimumTLSVersionCriblHTTPTlSv1  InputMinimumTLSVersionCriblHTTP = "TLSv1"
	InputMinimumTLSVersionCriblHTTPTlSv11 InputMinimumTLSVersionCriblHTTP = "TLSv1.1"
	InputMinimumTLSVersionCriblHTTPTlSv12 InputMinimumTLSVersionCriblHTTP = "TLSv1.2"
	InputMinimumTLSVersionCriblHTTPTlSv13 InputMinimumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e InputMinimumTLSVersionCriblHTTP) ToPointer() *InputMinimumTLSVersionCriblHTTP {
	return &e
}
func (e *InputMinimumTLSVersionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionCriblHTTP: %v", v)
	}
}

// InputMaximumTLSVersionCriblHTTP - Maximum TLS version to accept from connections
type InputMaximumTLSVersionCriblHTTP string

const (
	InputMaximumTLSVersionCriblHTTPTlSv1  InputMaximumTLSVersionCriblHTTP = "TLSv1"
	InputMaximumTLSVersionCriblHTTPTlSv11 InputMaximumTLSVersionCriblHTTP = "TLSv1.1"
	InputMaximumTLSVersionCriblHTTPTlSv12 InputMaximumTLSVersionCriblHTTP = "TLSv1.2"
	InputMaximumTLSVersionCriblHTTPTlSv13 InputMaximumTLSVersionCriblHTTP = "TLSv1.3"
)

func (e InputMaximumTLSVersionCriblHTTP) ToPointer() *InputMaximumTLSVersionCriblHTTP {
	return &e
}
func (e *InputMaximumTLSVersionCriblHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionCriblHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionCriblHTTP: %v", v)
	}
}

type TLSSettingsServerSideCriblHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMinimumTLSVersionCriblHTTP `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMaximumTLSVersionCriblHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideCriblHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideCriblHTTP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideCriblHTTP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideCriblHTTP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideCriblHTTP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideCriblHTTP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideCriblHTTP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideCriblHTTP) GetMinVersion() *InputMinimumTLSVersionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideCriblHTTP) GetMaxVersion() *InputMaximumTLSVersionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumCriblHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblHTTP struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     *InputTypeCriblHTTP `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblHTTP `json:"connections,omitempty"`
	Pq          *PqCriblHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                        `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideCriblHTTP `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []MetadatumCriblHTTP `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	Status      *TFStatus            `json:"status,omitempty"`
}

func (i InputCriblHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblHTTP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCriblHTTP) GetType() *InputTypeCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblHTTP) GetConnections() []ConnectionCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblHTTP) GetPq() *PqCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputCriblHTTP) GetTLS() *TLSSettingsServerSideCriblHTTP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputCriblHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputCriblHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputCriblHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputCriblHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputCriblHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputCriblHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputCriblHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputCriblHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputCriblHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputCriblHTTP) GetMetadata() []MetadatumCriblHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeCriblTCP string

const (
	InputTypeCriblTCPCriblTCP InputTypeCriblTCP = "cribl_tcp"
)

func (e InputTypeCriblTCP) ToPointer() *InputTypeCriblTCP {
	return &e
}
func (e *InputTypeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl_tcp":
		*e = InputTypeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCriblTCP: %v", v)
	}
}

type ConnectionCriblTCP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCriblTCP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeCriblTCP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeCriblTCP string

const (
	PqModeCriblTCPSmart  PqModeCriblTCP = "smart"
	PqModeCriblTCPAlways PqModeCriblTCP = "always"
)

func (e PqModeCriblTCP) ToPointer() *PqModeCriblTCP {
	return &e
}
func (e *PqModeCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeCriblTCP: %v", v)
	}
}

// PqCompressionCriblTCP - Codec to use to compress the persisted data
type PqCompressionCriblTCP string

const (
	PqCompressionCriblTCPNone PqCompressionCriblTCP = "none"
	PqCompressionCriblTCPGzip PqCompressionCriblTCP = "gzip"
)

func (e PqCompressionCriblTCP) ToPointer() *PqCompressionCriblTCP {
	return &e
}
func (e *PqCompressionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionCriblTCP: %v", v)
	}
}

type PqCriblTCP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeCriblTCP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionCriblTCP `default:"none" json:"compress"`
}

func (p PqCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCriblTCP) GetMode() *PqModeCriblTCP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCriblTCP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCriblTCP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCriblTCP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCriblTCP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCriblTCP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCriblTCP) GetCompress() *PqCompressionCriblTCP {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionCriblTCP - Minimum TLS version to accept from connections
type InputMinimumTLSVersionCriblTCP string

const (
	InputMinimumTLSVersionCriblTCPTlSv1  InputMinimumTLSVersionCriblTCP = "TLSv1"
	InputMinimumTLSVersionCriblTCPTlSv11 InputMinimumTLSVersionCriblTCP = "TLSv1.1"
	InputMinimumTLSVersionCriblTCPTlSv12 InputMinimumTLSVersionCriblTCP = "TLSv1.2"
	InputMinimumTLSVersionCriblTCPTlSv13 InputMinimumTLSVersionCriblTCP = "TLSv1.3"
)

func (e InputMinimumTLSVersionCriblTCP) ToPointer() *InputMinimumTLSVersionCriblTCP {
	return &e
}
func (e *InputMinimumTLSVersionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionCriblTCP: %v", v)
	}
}

// InputMaximumTLSVersionCriblTCP - Maximum TLS version to accept from connections
type InputMaximumTLSVersionCriblTCP string

const (
	InputMaximumTLSVersionCriblTCPTlSv1  InputMaximumTLSVersionCriblTCP = "TLSv1"
	InputMaximumTLSVersionCriblTCPTlSv11 InputMaximumTLSVersionCriblTCP = "TLSv1.1"
	InputMaximumTLSVersionCriblTCPTlSv12 InputMaximumTLSVersionCriblTCP = "TLSv1.2"
	InputMaximumTLSVersionCriblTCPTlSv13 InputMaximumTLSVersionCriblTCP = "TLSv1.3"
)

func (e InputMaximumTLSVersionCriblTCP) ToPointer() *InputMaximumTLSVersionCriblTCP {
	return &e
}
func (e *InputMaximumTLSVersionCriblTCP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionCriblTCP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionCriblTCP: %v", v)
	}
}

type TLSSettingsServerSideCriblTCP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMinimumTLSVersionCriblTCP `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMaximumTLSVersionCriblTCP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideCriblTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideCriblTCP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideCriblTCP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideCriblTCP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideCriblTCP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideCriblTCP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideCriblTCP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideCriblTCP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideCriblTCP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideCriblTCP) GetMinVersion() *InputMinimumTLSVersionCriblTCP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideCriblTCP) GetMaxVersion() *InputMaximumTLSVersionCriblTCP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumCriblTCP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCriblTCP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCriblTCP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCriblTCP struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputTypeCriblTCP `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCriblTCP `json:"connections,omitempty"`
	Pq          *PqCriblTCP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                        `json:"port"`
	TLS  *TLSSettingsServerSideCriblTCP `json:"tls,omitempty"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumCriblTCP `json:"metadata,omitempty"`
	// Load balance traffic across all Worker Processes
	EnableLoadBalancing *bool     `default:"false" json:"enableLoadBalancing"`
	Description         *string   `json:"description,omitempty"`
	Status              *TFStatus `json:"status,omitempty"`
}

func (i InputCriblTCP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCriblTCP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCriblTCP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputCriblTCP) GetType() *InputTypeCriblTCP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCriblTCP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCriblTCP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCriblTCP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCriblTCP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCriblTCP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCriblTCP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCriblTCP) GetConnections() []ConnectionCriblTCP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCriblTCP) GetPq() *PqCriblTCP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCriblTCP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputCriblTCP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputCriblTCP) GetTLS() *TLSSettingsServerSideCriblTCP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputCriblTCP) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputCriblTCP) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputCriblTCP) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputCriblTCP) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputCriblTCP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputCriblTCP) GetMetadata() []MetadatumCriblTCP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCriblTCP) GetEnableLoadBalancing() *bool {
	if o == nil {
		return nil
	}
	return o.EnableLoadBalancing
}

func (o *InputCriblTCP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCriblTCP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeCribl string

const (
	TypeCriblCribl TypeCribl = "cribl"
)

func (e TypeCribl) ToPointer() *TypeCribl {
	return &e
}
func (e *TypeCribl) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cribl":
		*e = TypeCribl(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeCribl: %v", v)
	}
}

type ConnectionCribl struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCribl) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCribl) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCribl - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCribl string

const (
	ModeCriblSmart  ModeCribl = "smart"
	ModeCriblAlways ModeCribl = "always"
)

func (e ModeCribl) ToPointer() *ModeCribl {
	return &e
}
func (e *ModeCribl) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCribl(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCribl: %v", v)
	}
}

// CompressionCribl - Codec to use to compress the persisted data
type CompressionCribl string

const (
	CompressionCriblNone CompressionCribl = "none"
	CompressionCriblGzip CompressionCribl = "gzip"
)

func (e CompressionCribl) ToPointer() *CompressionCribl {
	return &e
}
func (e *CompressionCribl) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCribl(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCribl: %v", v)
	}
}

type PqCribl struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCribl `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCribl `default:"none" json:"compress"`
}

func (p PqCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCribl) GetMode() *ModeCribl {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCribl) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCribl) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCribl) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCribl) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCribl) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCribl) GetCompress() *CompressionCribl {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumCribl struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumCribl) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumCribl) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCribl struct {
	// Unique ID for this input
	ID       string    `json:"id"`
	Type     TypeCribl `json:"type"`
	Disabled *bool     `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCribl `json:"connections,omitempty"`
	Pq          *PqCribl          `json:"pq,omitempty"`
	Filter      *string           `json:"filter,omitempty"`
	// Fields to add to events from this input
	Metadata    []MetadatumCribl `json:"metadata,omitempty"`
	Description *string          `json:"description,omitempty"`
	Status      *TFStatus        `json:"status,omitempty"`
}

func (i InputCribl) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCribl) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCribl) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCribl) GetType() TypeCribl {
	if o == nil {
		return TypeCribl("")
	}
	return o.Type
}

func (o *InputCribl) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCribl) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCribl) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCribl) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCribl) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCribl) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCribl) GetConnections() []ConnectionCribl {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCribl) GetPq() *PqCribl {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCribl) GetFilter() *string {
	if o == nil {
		return nil
	}
	return o.Filter
}

func (o *InputCribl) GetMetadata() []MetadatumCribl {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCribl) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputCribl) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeGooglePubsub string

const (
	InputTypeGooglePubsubGooglePubsub InputTypeGooglePubsub = "google_pubsub"
)

func (e InputTypeGooglePubsub) ToPointer() *InputTypeGooglePubsub {
	return &e
}
func (e *InputTypeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "google_pubsub":
		*e = InputTypeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeGooglePubsub: %v", v)
	}
}

type ConnectionGooglePubsub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionGooglePubsub) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeGooglePubsub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeGooglePubsub string

const (
	PqModeGooglePubsubSmart  PqModeGooglePubsub = "smart"
	PqModeGooglePubsubAlways PqModeGooglePubsub = "always"
)

func (e PqModeGooglePubsub) ToPointer() *PqModeGooglePubsub {
	return &e
}
func (e *PqModeGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeGooglePubsub: %v", v)
	}
}

// PqCompressionGooglePubsub - Codec to use to compress the persisted data
type PqCompressionGooglePubsub string

const (
	PqCompressionGooglePubsubNone PqCompressionGooglePubsub = "none"
	PqCompressionGooglePubsubGzip PqCompressionGooglePubsub = "gzip"
)

func (e PqCompressionGooglePubsub) ToPointer() *PqCompressionGooglePubsub {
	return &e
}
func (e *PqCompressionGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionGooglePubsub: %v", v)
	}
}

type PqGooglePubsub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeGooglePubsub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionGooglePubsub `default:"none" json:"compress"`
}

func (p PqGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqGooglePubsub) GetMode() *PqModeGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqGooglePubsub) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqGooglePubsub) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqGooglePubsub) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqGooglePubsub) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqGooglePubsub) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqGooglePubsub) GetCompress() *PqCompressionGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputAuthenticationMethodGooglePubsub - Google authentication method. Choose Auto to use Google Application Default Credentials.
type InputAuthenticationMethodGooglePubsub string

const (
	InputAuthenticationMethodGooglePubsubAuto   InputAuthenticationMethodGooglePubsub = "auto"
	InputAuthenticationMethodGooglePubsubManual InputAuthenticationMethodGooglePubsub = "manual"
	InputAuthenticationMethodGooglePubsubSecret InputAuthenticationMethodGooglePubsub = "secret"
)

func (e InputAuthenticationMethodGooglePubsub) ToPointer() *InputAuthenticationMethodGooglePubsub {
	return &e
}
func (e *InputAuthenticationMethodGooglePubsub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodGooglePubsub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodGooglePubsub: %v", v)
	}
}

type MetadatumGooglePubsub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumGooglePubsub) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumGooglePubsub) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGooglePubsub struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *InputTypeGooglePubsub `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionGooglePubsub `json:"connections,omitempty"`
	Pq          *PqGooglePubsub          `json:"pq,omitempty"`
	// ID of the topic to receive events from.
	TopicName string `json:"topicName"`
	// ID of the subscription to use when receiving events.
	SubscriptionName string `json:"subscriptionName"`
	// If enabled, create topic if it does not exist
	CreateTopic *bool `default:"false" json:"createTopic"`
	// If enabled, create subscription if it does not exist
	CreateSubscription *bool `default:"true" json:"createSubscription"`
	// Region to retrieve messages from. Select 'default' to allow Google to auto-select the nearest region. When using ordered delivery, the selected region must be allowed by message storage policy.
	Region *string `json:"region,omitempty"`
	// Google authentication method. Choose Auto to use Google Application Default Credentials.
	GoogleAuthMethod *InputAuthenticationMethodGooglePubsub `default:"manual" json:"googleAuthMethod"`
	// Contents of service account credentials (JSON keys) file downloaded from Google Cloud. To upload a file, click the upload button at this field's upper right.
	ServiceAccountCredentials *string `json:"serviceAccountCredentials,omitempty"`
	// Select or create a stored text secret
	Secret *string `json:"secret,omitempty"`
	// If Destination exerts backpressure, this setting limits how many inbound events Stream will queue for processing before it stops retrieving events.
	MaxBacklog *float64 `default:"1000" json:"maxBacklog"`
	// How many streams to pull messages from at one time. Doubling the value doubles the number of messages this Source pulls from the topic (if available), while consuming more CPU and memory. Defaults to 5.
	Concurrency *float64 `default:"5" json:"concurrency"`
	// Pull request timeout, in milliseconds.
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// Fields to add to events from this input
	Metadata    []MetadatumGooglePubsub `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	// If enabled, receive events in the order they were added to the queue. For this to work correctly, the process sending events must have ordering enabled.
	OrderedDelivery *bool     `default:"false" json:"orderedDelivery"`
	Status          *TFStatus `json:"status,omitempty"`
}

func (i InputGooglePubsub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGooglePubsub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGooglePubsub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGooglePubsub) GetType() *InputTypeGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGooglePubsub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGooglePubsub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGooglePubsub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGooglePubsub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGooglePubsub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGooglePubsub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGooglePubsub) GetConnections() []ConnectionGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGooglePubsub) GetPq() *PqGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGooglePubsub) GetTopicName() string {
	if o == nil {
		return ""
	}
	return o.TopicName
}

func (o *InputGooglePubsub) GetSubscriptionName() string {
	if o == nil {
		return ""
	}
	return o.SubscriptionName
}

func (o *InputGooglePubsub) GetCreateTopic() *bool {
	if o == nil {
		return nil
	}
	return o.CreateTopic
}

func (o *InputGooglePubsub) GetCreateSubscription() *bool {
	if o == nil {
		return nil
	}
	return o.CreateSubscription
}

func (o *InputGooglePubsub) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputGooglePubsub) GetGoogleAuthMethod() *InputAuthenticationMethodGooglePubsub {
	if o == nil {
		return nil
	}
	return o.GoogleAuthMethod
}

func (o *InputGooglePubsub) GetServiceAccountCredentials() *string {
	if o == nil {
		return nil
	}
	return o.ServiceAccountCredentials
}

func (o *InputGooglePubsub) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputGooglePubsub) GetMaxBacklog() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBacklog
}

func (o *InputGooglePubsub) GetConcurrency() *float64 {
	if o == nil {
		return nil
	}
	return o.Concurrency
}

func (o *InputGooglePubsub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGooglePubsub) GetMetadata() []MetadatumGooglePubsub {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGooglePubsub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGooglePubsub) GetOrderedDelivery() *bool {
	if o == nil {
		return nil
	}
	return o.OrderedDelivery
}

func (o *InputGooglePubsub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeFirehose string

const (
	TypeFirehoseFirehose TypeFirehose = "firehose"
)

func (e TypeFirehose) ToPointer() *TypeFirehose {
	return &e
}
func (e *TypeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "firehose":
		*e = TypeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeFirehose: %v", v)
	}
}

type ConnectionFirehose struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionFirehose) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionFirehose) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeFirehose - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeFirehose string

const (
	ModeFirehoseSmart  ModeFirehose = "smart"
	ModeFirehoseAlways ModeFirehose = "always"
)

func (e ModeFirehose) ToPointer() *ModeFirehose {
	return &e
}
func (e *ModeFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeFirehose: %v", v)
	}
}

// CompressionFirehose - Codec to use to compress the persisted data
type CompressionFirehose string

const (
	CompressionFirehoseNone CompressionFirehose = "none"
	CompressionFirehoseGzip CompressionFirehose = "gzip"
)

func (e CompressionFirehose) ToPointer() *CompressionFirehose {
	return &e
}
func (e *CompressionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionFirehose: %v", v)
	}
}

type PqFirehose struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeFirehose `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionFirehose `default:"none" json:"compress"`
}

func (p PqFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqFirehose) GetMode() *ModeFirehose {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqFirehose) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqFirehose) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqFirehose) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqFirehose) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqFirehose) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqFirehose) GetCompress() *CompressionFirehose {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionFirehose - Minimum TLS version to accept from connections
type MinimumTLSVersionFirehose string

const (
	MinimumTLSVersionFirehoseTlSv1  MinimumTLSVersionFirehose = "TLSv1"
	MinimumTLSVersionFirehoseTlSv11 MinimumTLSVersionFirehose = "TLSv1.1"
	MinimumTLSVersionFirehoseTlSv12 MinimumTLSVersionFirehose = "TLSv1.2"
	MinimumTLSVersionFirehoseTlSv13 MinimumTLSVersionFirehose = "TLSv1.3"
)

func (e MinimumTLSVersionFirehose) ToPointer() *MinimumTLSVersionFirehose {
	return &e
}
func (e *MinimumTLSVersionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionFirehose: %v", v)
	}
}

// MaximumTLSVersionFirehose - Maximum TLS version to accept from connections
type MaximumTLSVersionFirehose string

const (
	MaximumTLSVersionFirehoseTlSv1  MaximumTLSVersionFirehose = "TLSv1"
	MaximumTLSVersionFirehoseTlSv11 MaximumTLSVersionFirehose = "TLSv1.1"
	MaximumTLSVersionFirehoseTlSv12 MaximumTLSVersionFirehose = "TLSv1.2"
	MaximumTLSVersionFirehoseTlSv13 MaximumTLSVersionFirehose = "TLSv1.3"
)

func (e MaximumTLSVersionFirehose) ToPointer() *MaximumTLSVersionFirehose {
	return &e
}
func (e *MaximumTLSVersionFirehose) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionFirehose(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionFirehose: %v", v)
	}
}

type TLSSettingsServerSideFirehose struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionFirehose `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionFirehose `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideFirehose) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideFirehose) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideFirehose) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideFirehose) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideFirehose) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideFirehose) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideFirehose) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideFirehose) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideFirehose) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideFirehose) GetMinVersion() *MinimumTLSVersionFirehose {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideFirehose) GetMaxVersion() *MaximumTLSVersionFirehose {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumFirehose struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumFirehose) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumFirehose) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputFirehose struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *TypeFirehose `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionFirehose `json:"connections,omitempty"`
	Pq          *PqFirehose          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                       `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideFirehose `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Fields to add to events from this input
	Metadata    []MetadatumFirehose `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
	Status      *TFStatus           `json:"status,omitempty"`
}

func (i InputFirehose) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputFirehose) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputFirehose) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputFirehose) GetType() *TypeFirehose {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputFirehose) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputFirehose) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputFirehose) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputFirehose) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputFirehose) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputFirehose) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputFirehose) GetConnections() []ConnectionFirehose {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputFirehose) GetPq() *PqFirehose {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputFirehose) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputFirehose) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputFirehose) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputFirehose) GetTLS() *TLSSettingsServerSideFirehose {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputFirehose) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputFirehose) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputFirehose) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputFirehose) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputFirehose) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputFirehose) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputFirehose) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputFirehose) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputFirehose) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputFirehose) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputFirehose) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputFirehose) GetMetadata() []MetadatumFirehose {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputFirehose) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputFirehose) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputExecType string

const (
	InputExecTypeExec InputExecType = "exec"
)

func (e InputExecType) ToPointer() *InputExecType {
	return &e
}
func (e *InputExecType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "exec":
		*e = InputExecType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecType: %v", v)
	}
}

type InputExecConnection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputExecConnection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExecConnection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputExecMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputExecMode string

const (
	InputExecModeSmart  InputExecMode = "smart"
	InputExecModeAlways InputExecMode = "always"
)

func (e InputExecMode) ToPointer() *InputExecMode {
	return &e
}
func (e *InputExecMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputExecMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecMode: %v", v)
	}
}

// InputExecCompression - Codec to use to compress the persisted data
type InputExecCompression string

const (
	InputExecCompressionNone InputExecCompression = "none"
	InputExecCompressionGzip InputExecCompression = "gzip"
)

func (e InputExecCompression) ToPointer() *InputExecCompression {
	return &e
}
func (e *InputExecCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputExecCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecCompression: %v", v)
	}
}

type InputExecPq struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputExecMode `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputExecCompression `default:"none" json:"compress"`
}

func (i InputExecPq) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExecPq) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputExecPq) GetMode() *InputExecMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputExecPq) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputExecPq) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputExecPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputExecPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputExecPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputExecPq) GetCompress() *InputExecCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

// ScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type ScheduleType string

const (
	ScheduleTypeInterval     ScheduleType = "interval"
	ScheduleTypeCronSchedule ScheduleType = "cronSchedule"
)

func (e ScheduleType) ToPointer() *ScheduleType {
	return &e
}
func (e *ScheduleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "interval":
		fallthrough
	case "cronSchedule":
		*e = ScheduleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ScheduleType: %v", v)
	}
}

type InputExecMetadatum struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputExecMetadatum) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputExecMetadatum) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputExec struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     InputExecType `json:"type"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputExecConnection `json:"connections,omitempty"`
	Pq          *InputExecPq          `json:"pq,omitempty"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Maximum number of retry attempts in the event that the command fails
	Retries *float64 `default:"10" json:"retries"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *ScheduleType `default:"interval" json:"scheduleType"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Fields to add to events from this input
	Metadata    []InputExecMetadatum `json:"metadata,omitempty"`
	Description *string              `json:"description,omitempty"`
	// Interval between command executions in seconds.
	Interval *float64 `default:"60" json:"interval"`
	// Cron schedule to execute the command on.
	CronSchedule *string   `default:"* * * * *" json:"cronSchedule"`
	Status       *TFStatus `json:"status,omitempty"`
}

func (i InputExec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputExec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputExec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputExec) GetType() InputExecType {
	if o == nil {
		return InputExecType("")
	}
	return o.Type
}

func (o *InputExec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputExec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputExec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputExec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputExec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputExec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputExec) GetConnections() []InputExecConnection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputExec) GetPq() *InputExecPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputExec) GetCommand() string {
	if o == nil {
		return ""
	}
	return o.Command
}

func (o *InputExec) GetRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.Retries
}

func (o *InputExec) GetScheduleType() *ScheduleType {
	if o == nil {
		return nil
	}
	return o.ScheduleType
}

func (o *InputExec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputExec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputExec) GetMetadata() []InputExecMetadatum {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputExec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputExec) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputExec) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputExec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeEventhub string

const (
	TypeEventhubEventhub TypeEventhub = "eventhub"
)

func (e TypeEventhub) ToPointer() *TypeEventhub {
	return &e
}
func (e *TypeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "eventhub":
		*e = TypeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEventhub: %v", v)
	}
}

type ConnectionEventhub struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionEventhub) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeEventhub - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEventhub string

const (
	ModeEventhubSmart  ModeEventhub = "smart"
	ModeEventhubAlways ModeEventhub = "always"
)

func (e ModeEventhub) ToPointer() *ModeEventhub {
	return &e
}
func (e *ModeEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeEventhub: %v", v)
	}
}

// CompressionEventhub - Codec to use to compress the persisted data
type CompressionEventhub string

const (
	CompressionEventhubNone CompressionEventhub = "none"
	CompressionEventhubGzip CompressionEventhub = "gzip"
)

func (e CompressionEventhub) ToPointer() *CompressionEventhub {
	return &e
}
func (e *CompressionEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionEventhub: %v", v)
	}
}

type PqEventhub struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEventhub `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionEventhub `default:"none" json:"compress"`
}

func (p PqEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqEventhub) GetMode() *ModeEventhub {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqEventhub) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqEventhub) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqEventhub) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqEventhub) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqEventhub) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqEventhub) GetCompress() *CompressionEventhub {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SASLMechanismEventhub - SASL authentication mechanism to use
type SASLMechanismEventhub string

const (
	SASLMechanismEventhubPlain       SASLMechanismEventhub = "plain"
	SASLMechanismEventhubOauthbearer SASLMechanismEventhub = "oauthbearer"
)

func (e SASLMechanismEventhub) ToPointer() *SASLMechanismEventhub {
	return &e
}
func (e *SASLMechanismEventhub) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = SASLMechanismEventhub(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SASLMechanismEventhub: %v", v)
	}
}

// AuthenticationEventhub - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type AuthenticationEventhub struct {
	// Enable authentication.
	Disabled *bool `default:"false" json:"disabled"`
	// SASL authentication mechanism to use
	Mechanism *SASLMechanismEventhub `default:"plain" json:"mechanism"`
}

func (a AuthenticationEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthenticationEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthenticationEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *AuthenticationEventhub) GetMechanism() *SASLMechanismEventhub {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type TLSSettingsClientSideEventhub struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA).
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
}

func (t TLSSettingsClientSideEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsClientSideEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsClientSideEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsClientSideEventhub) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

type MetadatumEventhub struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumEventhub) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumEventhub) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputEventhub struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *TypeEventhub `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEventhub `json:"connections,omitempty"`
	Pq          *PqEventhub          `json:"pq,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, e.g., yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// The name of the Event Hub (a.k.a. Kafka topic) to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Event Hubs Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group this instance belongs to, default is 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Whether to start reading from earliest available data, relevant only during initial subscription.
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *AuthenticationEventhub        `json:"sasl,omitempty"`
	TLS  *TLSSettingsClientSideEventhub `json:"tls,omitempty"`
	//       Timeout (a.k.a session.timeout.ms in Kafka domain) used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires, the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be lower than rebalanceTimeout.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time (a.k.a rebalance.timeout.ms in Kafka domain) for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time (a.k.a heartbeat.interval.ms in Kafka domain) between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://github.com/Azure/azure-event-hubs-for-kafka/blob/master/CONFIGURATION.md).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Enable feature to minimize duplicate events by only starting one consumer for each topic partition.
	MinimizeDuplicates *bool `default:"false" json:"minimizeDuplicates"`
	// Fields to add to events from this input
	Metadata    []MetadatumEventhub `json:"metadata,omitempty"`
	Description *string             `json:"description,omitempty"`
	Status      *TFStatus           `json:"status,omitempty"`
}

func (i InputEventhub) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEventhub) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEventhub) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputEventhub) GetType() *TypeEventhub {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEventhub) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEventhub) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEventhub) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEventhub) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEventhub) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEventhub) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEventhub) GetConnections() []ConnectionEventhub {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEventhub) GetPq() *PqEventhub {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEventhub) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputEventhub) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputEventhub) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputEventhub) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputEventhub) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputEventhub) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputEventhub) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputEventhub) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputEventhub) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputEventhub) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputEventhub) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputEventhub) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputEventhub) GetSasl() *AuthenticationEventhub {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputEventhub) GetTLS() *TLSSettingsClientSideEventhub {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputEventhub) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputEventhub) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputEventhub) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputEventhub) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputEventhub) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputEventhub) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputEventhub) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputEventhub) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputEventhub) GetMinimizeDuplicates() *bool {
	if o == nil {
		return nil
	}
	return o.MinimizeDuplicates
}

func (o *InputEventhub) GetMetadata() []MetadatumEventhub {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEventhub) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputEventhub) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeOffice365MsgTrace string

const (
	TypeOffice365MsgTraceOffice365MsgTrace TypeOffice365MsgTrace = "office365_msg_trace"
)

func (e TypeOffice365MsgTrace) ToPointer() *TypeOffice365MsgTrace {
	return &e
}
func (e *TypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_msg_trace":
		*e = TypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365MsgTrace: %v", v)
	}
}

type ConnectionOffice365MsgTrace struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365MsgTrace) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365MsgTrace) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365MsgTrace - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365MsgTrace string

const (
	ModeOffice365MsgTraceSmart  ModeOffice365MsgTrace = "smart"
	ModeOffice365MsgTraceAlways ModeOffice365MsgTrace = "always"
)

func (e ModeOffice365MsgTrace) ToPointer() *ModeOffice365MsgTrace {
	return &e
}
func (e *ModeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365MsgTrace: %v", v)
	}
}

// CompressionOffice365MsgTrace - Codec to use to compress the persisted data
type CompressionOffice365MsgTrace string

const (
	CompressionOffice365MsgTraceNone CompressionOffice365MsgTrace = "none"
	CompressionOffice365MsgTraceGzip CompressionOffice365MsgTrace = "gzip"
)

func (e CompressionOffice365MsgTrace) ToPointer() *CompressionOffice365MsgTrace {
	return &e
}
func (e *CompressionOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365MsgTrace: %v", v)
	}
}

type PqOffice365MsgTrace struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365MsgTrace `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365MsgTrace `default:"none" json:"compress"`
}

func (p PqOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365MsgTrace) GetMode() *ModeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365MsgTrace) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365MsgTrace) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365MsgTrace) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365MsgTrace) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365MsgTrace) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365MsgTrace) GetCompress() *CompressionOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthenticationMethodOffice365MsgTrace - Select authentication method.
type AuthenticationMethodOffice365MsgTrace string

const (
	AuthenticationMethodOffice365MsgTraceManual      AuthenticationMethodOffice365MsgTrace = "manual"
	AuthenticationMethodOffice365MsgTraceSecret      AuthenticationMethodOffice365MsgTrace = "secret"
	AuthenticationMethodOffice365MsgTraceOauth       AuthenticationMethodOffice365MsgTrace = "oauth"
	AuthenticationMethodOffice365MsgTraceOauthSecret AuthenticationMethodOffice365MsgTrace = "oauthSecret"
	AuthenticationMethodOffice365MsgTraceOauthCert   AuthenticationMethodOffice365MsgTrace = "oauthCert"
)

func (e AuthenticationMethodOffice365MsgTrace) ToPointer() *AuthenticationMethodOffice365MsgTrace {
	return &e
}
func (e *AuthenticationMethodOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "oauth":
		fallthrough
	case "oauthSecret":
		fallthrough
	case "oauthCert":
		*e = AuthenticationMethodOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365MsgTrace: %v", v)
	}
}

// LogLevelOffice365MsgTrace - Log Level (verbosity) for collection runtime behavior.
type LogLevelOffice365MsgTrace string

const (
	LogLevelOffice365MsgTraceError LogLevelOffice365MsgTrace = "error"
	LogLevelOffice365MsgTraceWarn  LogLevelOffice365MsgTrace = "warn"
	LogLevelOffice365MsgTraceInfo  LogLevelOffice365MsgTrace = "info"
	LogLevelOffice365MsgTraceDebug LogLevelOffice365MsgTrace = "debug"
	LogLevelOffice365MsgTraceSilly LogLevelOffice365MsgTrace = "silly"
)

func (e LogLevelOffice365MsgTrace) ToPointer() *LogLevelOffice365MsgTrace {
	return &e
}
func (e *LogLevelOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		fallthrough
	case "silly":
		*e = LogLevelOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365MsgTrace: %v", v)
	}
}

type MetadatumOffice365MsgTrace struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365MsgTrace) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365MsgTrace) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeOffice365MsgTrace - The algorithm to use when performing HTTP retries
type RetryTypeOffice365MsgTrace string

const (
	RetryTypeOffice365MsgTraceNone    RetryTypeOffice365MsgTrace = "none"
	RetryTypeOffice365MsgTraceBackoff RetryTypeOffice365MsgTrace = "backoff"
	RetryTypeOffice365MsgTraceStatic  RetryTypeOffice365MsgTrace = "static"
)

func (e RetryTypeOffice365MsgTrace) ToPointer() *RetryTypeOffice365MsgTrace {
	return &e
}
func (e *RetryTypeOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365MsgTrace: %v", v)
	}
}

type RetryRulesOffice365MsgTrace struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365MsgTrace `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365MsgTrace) GetType() *RetryTypeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365MsgTrace) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365MsgTrace) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365MsgTrace) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365MsgTrace) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365MsgTrace) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365MsgTrace) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365MsgTrace) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// SubscriptionPlanOffice365MsgTrace - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365MsgTrace string

const (
	SubscriptionPlanOffice365MsgTraceEnterpriseGcc SubscriptionPlanOffice365MsgTrace = "enterprise_gcc"
	SubscriptionPlanOffice365MsgTraceGcc           SubscriptionPlanOffice365MsgTrace = "gcc"
	SubscriptionPlanOffice365MsgTraceGccHigh       SubscriptionPlanOffice365MsgTrace = "gcc_high"
	SubscriptionPlanOffice365MsgTraceDod           SubscriptionPlanOffice365MsgTrace = "dod"
)

func (e SubscriptionPlanOffice365MsgTrace) ToPointer() *SubscriptionPlanOffice365MsgTrace {
	return &e
}
func (e *SubscriptionPlanOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365MsgTrace(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365MsgTrace: %v", v)
	}
}

type CertOptions struct {
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path to the private key to use. Key should be in PEM format. Can reference $ENV_VARS.
	PrivKeyPath string `json:"privKeyPath"`
	// Passphrase to use to decrypt the private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path to the certificate to use. Certificate should be in PEM format. Can reference $ENV_VARS.
	CertPath string `json:"certPath"`
}

func (o *CertOptions) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *CertOptions) GetPrivKeyPath() string {
	if o == nil {
		return ""
	}
	return o.PrivKeyPath
}

func (o *CertOptions) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *CertOptions) GetCertPath() string {
	if o == nil {
		return ""
	}
	return o.CertPath
}

type InputOffice365MsgTrace struct {
	// Unique ID for this input
	ID       *string                `json:"id,omitempty"`
	Type     *TypeOffice365MsgTrace `json:"type,omitempty"`
	Disabled *bool                  `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365MsgTrace `json:"connections,omitempty"`
	Pq          *PqOffice365MsgTrace          `json:"pq,omitempty"`
	// URL to use when retrieving report data.
	URL *string `default:"https://reports.office365.com/ecp/reportingwebservice/reporting.svc/MessageTrace" json:"url"`
	// How often (in minutes) to run the report. Must divide evenly into 60 minutes to create a predictable schedule, or Save will fail.
	Interval *float64 `default:"60" json:"interval"`
	// Backward offset for the search range's head. (E.g.: -3h@h) Message Trace data is delayed; this parameter (with Date range end) compensates for delay and gaps.
	StartDate *string `json:"startDate,omitempty"`
	// Backward offset for the search range's tail. (E.g.: -2h@h) Message Trace data is delayed; this parameter (with Date range start) compensates for delay and gaps.
	EndDate *string `json:"endDate,omitempty"`
	// HTTP request inactivity timeout. Maximum is 2400 (40 minutes); enter 0 to wait indefinitely.
	Timeout *float64 `default:"300" json:"timeout"`
	// Disables time filtering of events when a date range is specified.
	DisableTimeFilter *bool `default:"true" json:"disableTimeFilter"`
	// Select authentication method.
	AuthType *AuthenticationMethodOffice365MsgTrace `default:"oauth" json:"authType"`
	// Reschedule tasks that failed with non-fatal errors
	RescheduleDroppedTasks *bool `default:"true" json:"rescheduleDroppedTasks"`
	// Maximum number of times a task can be rescheduled
	MaxTaskReschedule *float64 `default:"1" json:"maxTaskReschedule"`
	// Log Level (verbosity) for collection runtime behavior.
	LogLevel *LogLevelOffice365MsgTrace `default:"info" json:"logLevel"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata    []MetadatumOffice365MsgTrace `json:"metadata,omitempty"`
	RetryRules  *RetryRulesOffice365MsgTrace `json:"retryRules,omitempty"`
	Description *string                      `json:"description,omitempty"`
	// Username to run Message Trace API call.
	Username *string `json:"username,omitempty"`
	// Password to run Message Trace API call.
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials.
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// client_secret to pass in the OAuth request parameter.
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Directory ID (tenant identifier) in Azure Active Directory.
	TenantID *string `json:"tenantId,omitempty"`
	// client_id to pass in the OAuth request parameter.
	ClientID *string `json:"clientId,omitempty"`
	// Resource to pass in the OAuth request parameter.
	Resource *string `default:"https://outlook.office365.com" json:"resource"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365MsgTrace `default:"enterprise_gcc" json:"planType"`
	// Select or create a secret that references your client_secret to pass in the OAuth request parameter.
	TextSecret  *string      `json:"textSecret,omitempty"`
	CertOptions *CertOptions `json:"certOptions,omitempty"`
	Status      *TFStatus    `json:"status,omitempty"`
}

func (i InputOffice365MsgTrace) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365MsgTrace) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365MsgTrace) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365MsgTrace) GetType() *TypeOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365MsgTrace) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365MsgTrace) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365MsgTrace) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365MsgTrace) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365MsgTrace) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365MsgTrace) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365MsgTrace) GetConnections() []ConnectionOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365MsgTrace) GetPq() *PqOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365MsgTrace) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *InputOffice365MsgTrace) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputOffice365MsgTrace) GetStartDate() *string {
	if o == nil {
		return nil
	}
	return o.StartDate
}

func (o *InputOffice365MsgTrace) GetEndDate() *string {
	if o == nil {
		return nil
	}
	return o.EndDate
}

func (o *InputOffice365MsgTrace) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365MsgTrace) GetDisableTimeFilter() *bool {
	if o == nil {
		return nil
	}
	return o.DisableTimeFilter
}

func (o *InputOffice365MsgTrace) GetAuthType() *AuthenticationMethodOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365MsgTrace) GetRescheduleDroppedTasks() *bool {
	if o == nil {
		return nil
	}
	return o.RescheduleDroppedTasks
}

func (o *InputOffice365MsgTrace) GetMaxTaskReschedule() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxTaskReschedule
}

func (o *InputOffice365MsgTrace) GetLogLevel() *LogLevelOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputOffice365MsgTrace) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365MsgTrace) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365MsgTrace) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365MsgTrace) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365MsgTrace) GetMetadata() []MetadatumOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365MsgTrace) GetRetryRules() *RetryRulesOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365MsgTrace) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365MsgTrace) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputOffice365MsgTrace) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputOffice365MsgTrace) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputOffice365MsgTrace) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365MsgTrace) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputOffice365MsgTrace) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputOffice365MsgTrace) GetResource() *string {
	if o == nil {
		return nil
	}
	return o.Resource
}

func (o *InputOffice365MsgTrace) GetPlanType() *SubscriptionPlanOffice365MsgTrace {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365MsgTrace) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365MsgTrace) GetCertOptions() *CertOptions {
	if o == nil {
		return nil
	}
	return o.CertOptions
}

func (o *InputOffice365MsgTrace) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeOffice365Service string

const (
	TypeOffice365ServiceOffice365Service TypeOffice365Service = "office365_service"
)

func (e TypeOffice365Service) ToPointer() *TypeOffice365Service {
	return &e
}
func (e *TypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_service":
		*e = TypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Service: %v", v)
	}
}

type ConnectionOffice365Service struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365Service) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365Service) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365Service - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Service string

const (
	ModeOffice365ServiceSmart  ModeOffice365Service = "smart"
	ModeOffice365ServiceAlways ModeOffice365Service = "always"
)

func (e ModeOffice365Service) ToPointer() *ModeOffice365Service {
	return &e
}
func (e *ModeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365Service: %v", v)
	}
}

// CompressionOffice365Service - Codec to use to compress the persisted data
type CompressionOffice365Service string

const (
	CompressionOffice365ServiceNone CompressionOffice365Service = "none"
	CompressionOffice365ServiceGzip CompressionOffice365Service = "gzip"
)

func (e CompressionOffice365Service) ToPointer() *CompressionOffice365Service {
	return &e
}
func (e *CompressionOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365Service: %v", v)
	}
}

type PqOffice365Service struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Service `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365Service `default:"none" json:"compress"`
}

func (p PqOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365Service) GetMode() *ModeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365Service) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365Service) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365Service) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365Service) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365Service) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365Service) GetCompress() *CompressionOffice365Service {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SubscriptionPlanOffice365Service - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Service string

const (
	SubscriptionPlanOffice365ServiceEnterpriseGcc SubscriptionPlanOffice365Service = "enterprise_gcc"
	SubscriptionPlanOffice365ServiceGcc           SubscriptionPlanOffice365Service = "gcc"
	SubscriptionPlanOffice365ServiceGccHigh       SubscriptionPlanOffice365Service = "gcc_high"
	SubscriptionPlanOffice365ServiceDod           SubscriptionPlanOffice365Service = "dod"
)

func (e SubscriptionPlanOffice365Service) ToPointer() *SubscriptionPlanOffice365Service {
	return &e
}
func (e *SubscriptionPlanOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365Service: %v", v)
	}
}

type MetadatumOffice365Service struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365Service) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365Service) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelOffice365Service - Collector runtime Log Level
type LogLevelOffice365Service string

const (
	LogLevelOffice365ServiceError LogLevelOffice365Service = "error"
	LogLevelOffice365ServiceWarn  LogLevelOffice365Service = "warn"
	LogLevelOffice365ServiceInfo  LogLevelOffice365Service = "info"
	LogLevelOffice365ServiceDebug LogLevelOffice365Service = "debug"
)

func (e LogLevelOffice365Service) ToPointer() *LogLevelOffice365Service {
	return &e
}
func (e *LogLevelOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365Service: %v", v)
	}
}

type ContentConfigOffice365Service struct {
	// Office 365 Services API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Service `json:"logLevel,omitempty"`
	Enabled  *bool                     `json:"enabled,omitempty"`
}

func (o *ContentConfigOffice365Service) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *ContentConfigOffice365Service) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *ContentConfigOffice365Service) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *ContentConfigOffice365Service) GetLogLevel() *LogLevelOffice365Service {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *ContentConfigOffice365Service) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// RetryTypeOffice365Service - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Service string

const (
	RetryTypeOffice365ServiceNone    RetryTypeOffice365Service = "none"
	RetryTypeOffice365ServiceBackoff RetryTypeOffice365Service = "backoff"
	RetryTypeOffice365ServiceStatic  RetryTypeOffice365Service = "static"
)

func (e RetryTypeOffice365Service) ToPointer() *RetryTypeOffice365Service {
	return &e
}
func (e *RetryTypeOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365Service: %v", v)
	}
}

type RetryRulesOffice365Service struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Service `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365Service) GetType() *RetryTypeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365Service) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365Service) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365Service) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365Service) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365Service) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365Service) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365Service) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodOffice365Service - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Service string

const (
	AuthenticationMethodOffice365ServiceManual AuthenticationMethodOffice365Service = "manual"
	AuthenticationMethodOffice365ServiceSecret AuthenticationMethodOffice365Service = "secret"
)

func (e AuthenticationMethodOffice365Service) ToPointer() *AuthenticationMethodOffice365Service {
	return &e
}
func (e *AuthenticationMethodOffice365Service) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodOffice365Service(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365Service: %v", v)
	}
}

type InputOffice365Service struct {
	// Unique ID for this input
	ID       *string               `json:"id,omitempty"`
	Type     *TypeOffice365Service `json:"type,omitempty"`
	Disabled *bool                 `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Service `json:"connections,omitempty"`
	Pq          *PqOffice365Service          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Service `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Service `json:"metadata,omitempty"`
	// Enable Office 365 Service Communication API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered for current and historical status must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Service `json:"contentConfig,omitempty"`
	RetryRules    *RetryRulesOffice365Service     `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Service `default:"manual" json:"authType"`
	Description *string                               `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputOffice365Service) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Service) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Service) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365Service) GetType() *TypeOffice365Service {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Service) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Service) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Service) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Service) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Service) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Service) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Service) GetConnections() []ConnectionOffice365Service {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Service) GetPq() *PqOffice365Service {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Service) GetPlanType() *SubscriptionPlanOffice365Service {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Service) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Service) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Service) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Service) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Service) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Service) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Service) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Service) GetMetadata() []MetadatumOffice365Service {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Service) GetContentConfig() []ContentConfigOffice365Service {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Service) GetRetryRules() *RetryRulesOffice365Service {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Service) GetAuthType() *AuthenticationMethodOffice365Service {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Service) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Service) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Service) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365Service) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeOffice365Mgmt string

const (
	TypeOffice365MgmtOffice365Mgmt TypeOffice365Mgmt = "office365_mgmt"
)

func (e TypeOffice365Mgmt) ToPointer() *TypeOffice365Mgmt {
	return &e
}
func (e *TypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "office365_mgmt":
		*e = TypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeOffice365Mgmt: %v", v)
	}
}

type ConnectionOffice365Mgmt struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionOffice365Mgmt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionOffice365Mgmt) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeOffice365Mgmt - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeOffice365Mgmt string

const (
	ModeOffice365MgmtSmart  ModeOffice365Mgmt = "smart"
	ModeOffice365MgmtAlways ModeOffice365Mgmt = "always"
)

func (e ModeOffice365Mgmt) ToPointer() *ModeOffice365Mgmt {
	return &e
}
func (e *ModeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeOffice365Mgmt: %v", v)
	}
}

// CompressionOffice365Mgmt - Codec to use to compress the persisted data
type CompressionOffice365Mgmt string

const (
	CompressionOffice365MgmtNone CompressionOffice365Mgmt = "none"
	CompressionOffice365MgmtGzip CompressionOffice365Mgmt = "gzip"
)

func (e CompressionOffice365Mgmt) ToPointer() *CompressionOffice365Mgmt {
	return &e
}
func (e *CompressionOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionOffice365Mgmt: %v", v)
	}
}

type PqOffice365Mgmt struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeOffice365Mgmt `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionOffice365Mgmt `default:"none" json:"compress"`
}

func (p PqOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqOffice365Mgmt) GetMode() *ModeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqOffice365Mgmt) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqOffice365Mgmt) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqOffice365Mgmt) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqOffice365Mgmt) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqOffice365Mgmt) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqOffice365Mgmt) GetCompress() *CompressionOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Compress
}

// SubscriptionPlanOffice365Mgmt - Office 365 subscription plan for your organization, typically Office 365 Enterprise
type SubscriptionPlanOffice365Mgmt string

const (
	SubscriptionPlanOffice365MgmtEnterpriseGcc SubscriptionPlanOffice365Mgmt = "enterprise_gcc"
	SubscriptionPlanOffice365MgmtGcc           SubscriptionPlanOffice365Mgmt = "gcc"
	SubscriptionPlanOffice365MgmtGccHigh       SubscriptionPlanOffice365Mgmt = "gcc_high"
	SubscriptionPlanOffice365MgmtDod           SubscriptionPlanOffice365Mgmt = "dod"
)

func (e SubscriptionPlanOffice365Mgmt) ToPointer() *SubscriptionPlanOffice365Mgmt {
	return &e
}
func (e *SubscriptionPlanOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "enterprise_gcc":
		fallthrough
	case "gcc":
		fallthrough
	case "gcc_high":
		fallthrough
	case "dod":
		*e = SubscriptionPlanOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SubscriptionPlanOffice365Mgmt: %v", v)
	}
}

type MetadatumOffice365Mgmt struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumOffice365Mgmt) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumOffice365Mgmt) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelOffice365Mgmt - Collector runtime Log Level
type LogLevelOffice365Mgmt string

const (
	LogLevelOffice365MgmtError LogLevelOffice365Mgmt = "error"
	LogLevelOffice365MgmtWarn  LogLevelOffice365Mgmt = "warn"
	LogLevelOffice365MgmtInfo  LogLevelOffice365Mgmt = "info"
	LogLevelOffice365MgmtDebug LogLevelOffice365Mgmt = "debug"
)

func (e LogLevelOffice365Mgmt) ToPointer() *LogLevelOffice365Mgmt {
	return &e
}
func (e *LogLevelOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelOffice365Mgmt: %v", v)
	}
}

type ContentConfigOffice365Mgmt struct {
	// Office 365 Management Activity API Content Type
	ContentType *string `json:"contentType,omitempty"`
	// If interval type is minutes the value entered must evenly divisible by 60 or save will fail
	Description *string  `json:"description,omitempty"`
	Interval    *float64 `json:"interval,omitempty"`
	// Collector runtime Log Level
	LogLevel *LogLevelOffice365Mgmt `json:"logLevel,omitempty"`
	Enabled  *bool                  `json:"enabled,omitempty"`
}

func (o *ContentConfigOffice365Mgmt) GetContentType() *string {
	if o == nil {
		return nil
	}
	return o.ContentType
}

func (o *ContentConfigOffice365Mgmt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *ContentConfigOffice365Mgmt) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *ContentConfigOffice365Mgmt) GetLogLevel() *LogLevelOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *ContentConfigOffice365Mgmt) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

// RetryTypeOffice365Mgmt - The algorithm to use when performing HTTP retries
type RetryTypeOffice365Mgmt string

const (
	RetryTypeOffice365MgmtNone    RetryTypeOffice365Mgmt = "none"
	RetryTypeOffice365MgmtBackoff RetryTypeOffice365Mgmt = "backoff"
	RetryTypeOffice365MgmtStatic  RetryTypeOffice365Mgmt = "static"
)

func (e RetryTypeOffice365Mgmt) ToPointer() *RetryTypeOffice365Mgmt {
	return &e
}
func (e *RetryTypeOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeOffice365Mgmt: %v", v)
	}
}

type RetryRulesOffice365Mgmt struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeOffice365Mgmt `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of http codes that trigger a retry. Leave empty to use the default list of 429, 500, and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesOffice365Mgmt) GetType() *RetryTypeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesOffice365Mgmt) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesOffice365Mgmt) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesOffice365Mgmt) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesOffice365Mgmt) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesOffice365Mgmt) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesOffice365Mgmt) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesOffice365Mgmt) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationMethodOffice365Mgmt - Enter client secret directly, or select a stored secret
type AuthenticationMethodOffice365Mgmt string

const (
	AuthenticationMethodOffice365MgmtManual AuthenticationMethodOffice365Mgmt = "manual"
	AuthenticationMethodOffice365MgmtSecret AuthenticationMethodOffice365Mgmt = "secret"
)

func (e AuthenticationMethodOffice365Mgmt) ToPointer() *AuthenticationMethodOffice365Mgmt {
	return &e
}
func (e *AuthenticationMethodOffice365Mgmt) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthenticationMethodOffice365Mgmt(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationMethodOffice365Mgmt: %v", v)
	}
}

type InputOffice365Mgmt struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *TypeOffice365Mgmt `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionOffice365Mgmt `json:"connections,omitempty"`
	Pq          *PqOffice365Mgmt          `json:"pq,omitempty"`
	// Office 365 subscription plan for your organization, typically Office 365 Enterprise
	PlanType *SubscriptionPlanOffice365Mgmt `default:"enterprise_gcc" json:"planType"`
	// Office 365 Azure Tenant ID
	TenantID string `json:"tenantId"`
	// Office 365 Azure Application ID
	AppID string `json:"appId"`
	// HTTP request inactivity timeout, use 0 to disable
	Timeout *float64 `default:"300" json:"timeout"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []MetadatumOffice365Mgmt `json:"metadata,omitempty"`
	// Optional Publisher Identifier to use in API requests, defaults to tenant id if not defined. For more information see [here](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference#start-a-subscription)
	PublisherIdentifier *string `json:"publisherIdentifier,omitempty"`
	// Enable Office 365 Management Activity API content types and polling intervals. Polling intervals are used to set up search date range and cron schedule, e.g.: */${interval} * * * *. Because of this, intervals entered must be evenly divisible by 60 to give a predictable schedule.
	ContentConfig []ContentConfigOffice365Mgmt `json:"contentConfig,omitempty"`
	// Use this setting to account for ingestion lag. This is necessary because there can be a lag of 60 - 90 minutes (or longer) before Office 365 events are available for retrieval.
	IngestionLag *float64                 `default:"0" json:"ingestionLag"`
	RetryRules   *RetryRulesOffice365Mgmt `json:"retryRules,omitempty"`
	// Enter client secret directly, or select a stored secret
	AuthType    *AuthenticationMethodOffice365Mgmt `default:"manual" json:"authType"`
	Description *string                            `json:"description,omitempty"`
	// Office 365 Azure client secret
	ClientSecret *string `json:"clientSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string   `json:"textSecret,omitempty"`
	Status     *TFStatus `json:"status,omitempty"`
}

func (i InputOffice365Mgmt) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputOffice365Mgmt) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputOffice365Mgmt) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputOffice365Mgmt) GetType() *TypeOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputOffice365Mgmt) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputOffice365Mgmt) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputOffice365Mgmt) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputOffice365Mgmt) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputOffice365Mgmt) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputOffice365Mgmt) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputOffice365Mgmt) GetConnections() []ConnectionOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputOffice365Mgmt) GetPq() *PqOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputOffice365Mgmt) GetPlanType() *SubscriptionPlanOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.PlanType
}

func (o *InputOffice365Mgmt) GetTenantID() string {
	if o == nil {
		return ""
	}
	return o.TenantID
}

func (o *InputOffice365Mgmt) GetAppID() string {
	if o == nil {
		return ""
	}
	return o.AppID
}

func (o *InputOffice365Mgmt) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputOffice365Mgmt) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputOffice365Mgmt) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputOffice365Mgmt) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputOffice365Mgmt) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputOffice365Mgmt) GetMetadata() []MetadatumOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputOffice365Mgmt) GetPublisherIdentifier() *string {
	if o == nil {
		return nil
	}
	return o.PublisherIdentifier
}

func (o *InputOffice365Mgmt) GetContentConfig() []ContentConfigOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.ContentConfig
}

func (o *InputOffice365Mgmt) GetIngestionLag() *float64 {
	if o == nil {
		return nil
	}
	return o.IngestionLag
}

func (o *InputOffice365Mgmt) GetRetryRules() *RetryRulesOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputOffice365Mgmt) GetAuthType() *AuthenticationMethodOffice365Mgmt {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputOffice365Mgmt) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputOffice365Mgmt) GetClientSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientSecret
}

func (o *InputOffice365Mgmt) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputOffice365Mgmt) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeEdgePrometheus string

const (
	TypeEdgePrometheusEdgePrometheus TypeEdgePrometheus = "edge_prometheus"
)

func (e TypeEdgePrometheus) ToPointer() *TypeEdgePrometheus {
	return &e
}
func (e *TypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "edge_prometheus":
		*e = TypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeEdgePrometheus: %v", v)
	}
}

type ConnectionEdgePrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionEdgePrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionEdgePrometheus) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeEdgePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeEdgePrometheus string

const (
	ModeEdgePrometheusSmart  ModeEdgePrometheus = "smart"
	ModeEdgePrometheusAlways ModeEdgePrometheus = "always"
)

func (e ModeEdgePrometheus) ToPointer() *ModeEdgePrometheus {
	return &e
}
func (e *ModeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeEdgePrometheus: %v", v)
	}
}

// PqCompressionEdgePrometheus - Codec to use to compress the persisted data
type PqCompressionEdgePrometheus string

const (
	PqCompressionEdgePrometheusNone PqCompressionEdgePrometheus = "none"
	PqCompressionEdgePrometheusGzip PqCompressionEdgePrometheus = "gzip"
)

func (e PqCompressionEdgePrometheus) ToPointer() *PqCompressionEdgePrometheus {
	return &e
}
func (e *PqCompressionEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionEdgePrometheus: %v", v)
	}
}

type PqEdgePrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeEdgePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionEdgePrometheus `default:"none" json:"compress"`
}

func (p PqEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqEdgePrometheus) GetMode() *ModeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqEdgePrometheus) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqEdgePrometheus) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqEdgePrometheus) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqEdgePrometheus) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqEdgePrometheus) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqEdgePrometheus) GetCompress() *PqCompressionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Compress
}

// DiscoveryTypeEdgePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypeEdgePrometheus string

const (
	DiscoveryTypeEdgePrometheusStatic  DiscoveryTypeEdgePrometheus = "static"
	DiscoveryTypeEdgePrometheusDNS     DiscoveryTypeEdgePrometheus = "dns"
	DiscoveryTypeEdgePrometheusEc2     DiscoveryTypeEdgePrometheus = "ec2"
	DiscoveryTypeEdgePrometheusK8sNode DiscoveryTypeEdgePrometheus = "k8s-node"
	DiscoveryTypeEdgePrometheusK8sPods DiscoveryTypeEdgePrometheus = "k8s-pods"
)

func (e DiscoveryTypeEdgePrometheus) ToPointer() *DiscoveryTypeEdgePrometheus {
	return &e
}
func (e *DiscoveryTypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		fallthrough
	case "k8s-node":
		fallthrough
	case "k8s-pods":
		*e = DiscoveryTypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiscoveryTypeEdgePrometheus: %v", v)
	}
}

// PersistenceCompressionEdgePrometheus - Data compression format. Default is gzip.
type PersistenceCompressionEdgePrometheus string

const (
	PersistenceCompressionEdgePrometheusNone PersistenceCompressionEdgePrometheus = "none"
	PersistenceCompressionEdgePrometheusGzip PersistenceCompressionEdgePrometheus = "gzip"
)

func (e PersistenceCompressionEdgePrometheus) ToPointer() *PersistenceCompressionEdgePrometheus {
	return &e
}
func (e *PersistenceCompressionEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PersistenceCompressionEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PersistenceCompressionEdgePrometheus: %v", v)
	}
}

type DiskSpoolingEdgePrometheus struct {
	// Spool events on disk for Cribl Edge and Search. Default is disabled.
	Enable *bool `default:"false" json:"enable"`
	// Time period for grouping spooled events. Default is 10m.
	TimeWindow *string `default:"10m" json:"timeWindow"`
	// Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB.
	MaxDataSize *string `default:"1GB" json:"maxDataSize"`
	// Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h.
	MaxDataTime *string `default:"24h" json:"maxDataTime"`
	// Data compression format. Default is gzip.
	Compress *PersistenceCompressionEdgePrometheus `default:"gzip" json:"compress"`
}

func (d DiskSpoolingEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(d, "", false)
}

func (d *DiskSpoolingEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &d, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *DiskSpoolingEdgePrometheus) GetEnable() *bool {
	if o == nil {
		return nil
	}
	return o.Enable
}

func (o *DiskSpoolingEdgePrometheus) GetTimeWindow() *string {
	if o == nil {
		return nil
	}
	return o.TimeWindow
}

func (o *DiskSpoolingEdgePrometheus) GetMaxDataSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataSize
}

func (o *DiskSpoolingEdgePrometheus) GetMaxDataTime() *string {
	if o == nil {
		return nil
	}
	return o.MaxDataTime
}

func (o *DiskSpoolingEdgePrometheus) GetCompress() *PersistenceCompressionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumEdgePrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumEdgePrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumEdgePrometheus) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// AuthTypeAuthenticationMethodEdgePrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodEdgePrometheus string

const (
	AuthTypeAuthenticationMethodEdgePrometheusManual     AuthTypeAuthenticationMethodEdgePrometheus = "manual"
	AuthTypeAuthenticationMethodEdgePrometheusSecret     AuthTypeAuthenticationMethodEdgePrometheus = "secret"
	AuthTypeAuthenticationMethodEdgePrometheusKubernetes AuthTypeAuthenticationMethodEdgePrometheus = "kubernetes"
)

func (e AuthTypeAuthenticationMethodEdgePrometheus) ToPointer() *AuthTypeAuthenticationMethodEdgePrometheus {
	return &e
}
func (e *AuthTypeAuthenticationMethodEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "kubernetes":
		*e = AuthTypeAuthenticationMethodEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthTypeAuthenticationMethodEdgePrometheus: %v", v)
	}
}

// TargetProtocol - Protocol to use when collecting metrics
type TargetProtocol string

const (
	TargetProtocolHTTP  TargetProtocol = "http"
	TargetProtocolHTTPS TargetProtocol = "https"
)

func (e TargetProtocol) ToPointer() *TargetProtocol {
	return &e
}
func (e *TargetProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = TargetProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TargetProtocol: %v", v)
	}
}

type Target struct {
	// Protocol to use when collecting metrics
	Protocol *TargetProtocol `default:"http" json:"protocol"`
	// Name of host from which to pull metrics.
	Host string `json:"host"`
	// The port number in the metrics URL for discovered targets.
	Port *float64 `default:"9090" json:"port"`
	// Path to use when collecting metrics from discovered targets
	Path *string `default:"/metrics" json:"path"`
}

func (t Target) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Target) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *Target) GetProtocol() *TargetProtocol {
	if o == nil {
		return nil
	}
	return o.Protocol
}

func (o *Target) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *Target) GetPort() *float64 {
	if o == nil {
		return nil
	}
	return o.Port
}

func (o *Target) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

// RecordTypeEdgePrometheus - DNS Record type to resolve
type RecordTypeEdgePrometheus string

const (
	RecordTypeEdgePrometheusSrv  RecordTypeEdgePrometheus = "SRV"
	RecordTypeEdgePrometheusA    RecordTypeEdgePrometheus = "A"
	RecordTypeEdgePrometheusAaaa RecordTypeEdgePrometheus = "AAAA"
)

func (e RecordTypeEdgePrometheus) ToPointer() *RecordTypeEdgePrometheus {
	return &e
}
func (e *RecordTypeEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = RecordTypeEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordTypeEdgePrometheus: %v", v)
	}
}

// ScrapeProtocolProtocol - Protocol to use when collecting metrics
type ScrapeProtocolProtocol string

const (
	ScrapeProtocolProtocolHTTP  ScrapeProtocolProtocol = "http"
	ScrapeProtocolProtocolHTTPS ScrapeProtocolProtocol = "https"
)

func (e ScrapeProtocolProtocol) ToPointer() *ScrapeProtocolProtocol {
	return &e
}
func (e *ScrapeProtocolProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = ScrapeProtocolProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ScrapeProtocolProtocol: %v", v)
	}
}

type SearchFilterEdgePrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values,omitempty"`
}

func (o *SearchFilterEdgePrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SearchFilterEdgePrometheus) GetValues() []string {
	if o == nil {
		return nil
	}
	return o.Values
}

// AwsAuthenticationMethodAuthenticationMethodEdgePrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodEdgePrometheus string

const (
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusAuto   AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "auto"
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusManual AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "manual"
	AwsAuthenticationMethodAuthenticationMethodEdgePrometheusSecret AwsAuthenticationMethodAuthenticationMethodEdgePrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodEdgePrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	return &e
}
func (e *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AwsAuthenticationMethodAuthenticationMethodEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AwsAuthenticationMethodAuthenticationMethodEdgePrometheus: %v", v)
	}
}

// SignatureVersionEdgePrometheus - Signature version to use for signing EC2 requests
type SignatureVersionEdgePrometheus string

const (
	SignatureVersionEdgePrometheusV2 SignatureVersionEdgePrometheus = "v2"
	SignatureVersionEdgePrometheusV4 SignatureVersionEdgePrometheus = "v4"
)

func (e SignatureVersionEdgePrometheus) ToPointer() *SignatureVersionEdgePrometheus {
	return &e
}
func (e *SignatureVersionEdgePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionEdgePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionEdgePrometheus: %v", v)
	}
}

type PodFilter struct {
	// JavaScript expression applied to pods objects. Return 'true' to include it.
	Filter string `json:"filter"`
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
}

func (o *PodFilter) GetFilter() string {
	if o == nil {
		return ""
	}
	return o.Filter
}

func (o *PodFilter) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

type InputEdgePrometheus struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     *TypeEdgePrometheus `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionEdgePrometheus `json:"connections,omitempty"`
	Pq          *PqEdgePrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypeEdgePrometheus `default:"static" json:"discoveryType"`
	// How often in seconds to scrape targets for metrics.
	Interval *float64 `default:"15" json:"interval"`
	// Timeout, in milliseconds, before aborting HTTP connection attempts; 1-60000 or 0 to disable
	Timeout     *float64                    `default:"5000" json:"timeout"`
	Persistence *DiskSpoolingEdgePrometheus `json:"persistence,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumEdgePrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodEdgePrometheus `default:"manual" json:"authType"`
	Description *string                                     `json:"description,omitempty"`
	Targets     []Target                                    `json:"targets,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypeEdgePrometheus `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *ScrapeProtocolProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterEdgePrometheus `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                                    `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionEdgePrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Protocol to use when collecting metrics
	ScrapeProtocolExpr *string `default:"metadata.annotations['prometheus.io/scheme'] || 'http'" json:"scrapeProtocolExpr"`
	// The port number in the metrics URL for discovered targets.
	ScrapePortExpr *string `default:"metadata.annotations['prometheus.io/port'] || 9090" json:"scrapePortExpr"`
	// Path to use when collecting metrics from discovered targets
	ScrapePathExpr *string `default:"metadata.annotations['prometheus.io/path'] || '/metrics'" json:"scrapePathExpr"`
	//   Add rules to decide which pods to discover for metrics.
	//   Pods are searched if no rules are given or of all the rules'
	//   expressions evaluate to true.
	//
	PodFilter []PodFilter `json:"podFilter,omitempty"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string   `json:"credentialsSecret,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputEdgePrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputEdgePrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputEdgePrometheus) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputEdgePrometheus) GetType() *TypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputEdgePrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputEdgePrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputEdgePrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputEdgePrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputEdgePrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputEdgePrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputEdgePrometheus) GetConnections() []ConnectionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputEdgePrometheus) GetPq() *PqEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputEdgePrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputEdgePrometheus) GetDiscoveryType() *DiscoveryTypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputEdgePrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputEdgePrometheus) GetTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *InputEdgePrometheus) GetPersistence() *DiskSpoolingEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Persistence
}

func (o *InputEdgePrometheus) GetMetadata() []MetadatumEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputEdgePrometheus) GetAuthType() *AuthTypeAuthenticationMethodEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputEdgePrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputEdgePrometheus) GetTargets() []Target {
	if o == nil {
		return nil
	}
	return o.Targets
}

func (o *InputEdgePrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputEdgePrometheus) GetRecordType() *RecordTypeEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputEdgePrometheus) GetScrapeProtocol() *ScrapeProtocolProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputEdgePrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputEdgePrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputEdgePrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputEdgePrometheus) GetSearchFilter() []SearchFilterEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputEdgePrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputEdgePrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputEdgePrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputEdgePrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputEdgePrometheus) GetSignatureVersion() *SignatureVersionEdgePrometheus {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputEdgePrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputEdgePrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputEdgePrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputEdgePrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputEdgePrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputEdgePrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputEdgePrometheus) GetScrapeProtocolExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocolExpr
}

func (o *InputEdgePrometheus) GetScrapePortExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePortExpr
}

func (o *InputEdgePrometheus) GetScrapePathExpr() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePathExpr
}

func (o *InputEdgePrometheus) GetPodFilter() []PodFilter {
	if o == nil {
		return nil
	}
	return o.PodFilter
}

func (o *InputEdgePrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputEdgePrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputEdgePrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputEdgePrometheus) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypePrometheus string

const (
	InputTypePrometheusPrometheus InputTypePrometheus = "prometheus"
)

func (e InputTypePrometheus) ToPointer() *InputTypePrometheus {
	return &e
}
func (e *InputTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus":
		*e = InputTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypePrometheus: %v", v)
	}
}

type ConnectionPrometheus struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionPrometheus) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModePrometheus - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModePrometheus string

const (
	PqModePrometheusSmart  PqModePrometheus = "smart"
	PqModePrometheusAlways PqModePrometheus = "always"
)

func (e PqModePrometheus) ToPointer() *PqModePrometheus {
	return &e
}
func (e *PqModePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModePrometheus: %v", v)
	}
}

// PqCompressionPrometheus - Codec to use to compress the persisted data
type PqCompressionPrometheus string

const (
	PqCompressionPrometheusNone PqCompressionPrometheus = "none"
	PqCompressionPrometheusGzip PqCompressionPrometheus = "gzip"
)

func (e PqCompressionPrometheus) ToPointer() *PqCompressionPrometheus {
	return &e
}
func (e *PqCompressionPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionPrometheus: %v", v)
	}
}

type PqPrometheus struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModePrometheus `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionPrometheus `default:"none" json:"compress"`
}

func (p PqPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqPrometheus) GetMode() *PqModePrometheus {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqPrometheus) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqPrometheus) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqPrometheus) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqPrometheus) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqPrometheus) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqPrometheus) GetCompress() *PqCompressionPrometheus {
	if o == nil {
		return nil
	}
	return o.Compress
}

// DiscoveryTypePrometheus - Target discovery mechanism. Use static to manually enter a list of targets.
type DiscoveryTypePrometheus string

const (
	DiscoveryTypePrometheusStatic DiscoveryTypePrometheus = "static"
	DiscoveryTypePrometheusDNS    DiscoveryTypePrometheus = "dns"
	DiscoveryTypePrometheusEc2    DiscoveryTypePrometheus = "ec2"
)

func (e DiscoveryTypePrometheus) ToPointer() *DiscoveryTypePrometheus {
	return &e
}
func (e *DiscoveryTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "static":
		fallthrough
	case "dns":
		fallthrough
	case "ec2":
		*e = DiscoveryTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DiscoveryTypePrometheus: %v", v)
	}
}

// LogLevelPrometheus - Collector runtime Log Level
type LogLevelPrometheus string

const (
	LogLevelPrometheusError LogLevelPrometheus = "error"
	LogLevelPrometheusWarn  LogLevelPrometheus = "warn"
	LogLevelPrometheusInfo  LogLevelPrometheus = "info"
	LogLevelPrometheusDebug LogLevelPrometheus = "debug"
)

func (e LogLevelPrometheus) ToPointer() *LogLevelPrometheus {
	return &e
}
func (e *LogLevelPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelPrometheus: %v", v)
	}
}

type MetadatumPrometheus struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumPrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumPrometheus) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// AuthTypeAuthenticationMethodPrometheus - Enter credentials directly, or select a stored secret
type AuthTypeAuthenticationMethodPrometheus string

const (
	AuthTypeAuthenticationMethodPrometheusManual AuthTypeAuthenticationMethodPrometheus = "manual"
	AuthTypeAuthenticationMethodPrometheusSecret AuthTypeAuthenticationMethodPrometheus = "secret"
)

func (e AuthTypeAuthenticationMethodPrometheus) ToPointer() *AuthTypeAuthenticationMethodPrometheus {
	return &e
}
func (e *AuthTypeAuthenticationMethodPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthTypeAuthenticationMethodPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthTypeAuthenticationMethodPrometheus: %v", v)
	}
}

// RecordTypePrometheus - DNS Record type to resolve
type RecordTypePrometheus string

const (
	RecordTypePrometheusSrv  RecordTypePrometheus = "SRV"
	RecordTypePrometheusA    RecordTypePrometheus = "A"
	RecordTypePrometheusAaaa RecordTypePrometheus = "AAAA"
)

func (e RecordTypePrometheus) ToPointer() *RecordTypePrometheus {
	return &e
}
func (e *RecordTypePrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SRV":
		fallthrough
	case "A":
		fallthrough
	case "AAAA":
		*e = RecordTypePrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RecordTypePrometheus: %v", v)
	}
}

// MetricsProtocol - Protocol to use when collecting metrics
type MetricsProtocol string

const (
	MetricsProtocolHTTP  MetricsProtocol = "http"
	MetricsProtocolHTTPS MetricsProtocol = "https"
)

func (e MetricsProtocol) ToPointer() *MetricsProtocol {
	return &e
}
func (e *MetricsProtocol) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		fallthrough
	case "https":
		*e = MetricsProtocol(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MetricsProtocol: %v", v)
	}
}

type SearchFilterPrometheus struct {
	// Search filter attribute name, see: https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html for more information. Attributes can be manually entered if not present in the drop down list
	Name string `json:"Name"`
	// Search Filter Values, if empty only "running" EC2 instances will be returned
	Values []string `json:"Values,omitempty"`
}

func (o *SearchFilterPrometheus) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *SearchFilterPrometheus) GetValues() []string {
	if o == nil {
		return nil
	}
	return o.Values
}

// AwsAuthenticationMethodAuthenticationMethodPrometheus - AWS authentication method. Choose Auto to use IAM roles.
type AwsAuthenticationMethodAuthenticationMethodPrometheus string

const (
	AwsAuthenticationMethodAuthenticationMethodPrometheusAuto   AwsAuthenticationMethodAuthenticationMethodPrometheus = "auto"
	AwsAuthenticationMethodAuthenticationMethodPrometheusManual AwsAuthenticationMethodAuthenticationMethodPrometheus = "manual"
	AwsAuthenticationMethodAuthenticationMethodPrometheusSecret AwsAuthenticationMethodAuthenticationMethodPrometheus = "secret"
)

func (e AwsAuthenticationMethodAuthenticationMethodPrometheus) ToPointer() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	return &e
}
func (e *AwsAuthenticationMethodAuthenticationMethodPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = AwsAuthenticationMethodAuthenticationMethodPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AwsAuthenticationMethodAuthenticationMethodPrometheus: %v", v)
	}
}

// SignatureVersionPrometheus - Signature version to use for signing EC2 requests
type SignatureVersionPrometheus string

const (
	SignatureVersionPrometheusV2 SignatureVersionPrometheus = "v2"
	SignatureVersionPrometheusV4 SignatureVersionPrometheus = "v4"
)

func (e SignatureVersionPrometheus) ToPointer() *SignatureVersionPrometheus {
	return &e
}
func (e *SignatureVersionPrometheus) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = SignatureVersionPrometheus(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SignatureVersionPrometheus: %v", v)
	}
}

type InputPrometheus struct {
	// Unique ID for this input
	ID       *string              `json:"id,omitempty"`
	Type     *InputTypePrometheus `json:"type,omitempty"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheus `json:"connections,omitempty"`
	Pq          *PqPrometheus          `json:"pq,omitempty"`
	// Other dimensions to include in events
	DimensionList []string `json:"dimensionList,omitempty"`
	// Target discovery mechanism. Use static to manually enter a list of targets.
	DiscoveryType *DiscoveryTypePrometheus `default:"static" json:"discoveryType"`
	// How often in minutes to scrape targets for metrics, 60 must be evenly divisible by the value or save will fail.
	Interval *float64 `default:"15" json:"interval"`
	// Collector runtime Log Level
	LogLevel *LogLevelPrometheus `default:"info" json:"logLevel"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata []MetadatumPrometheus `json:"metadata,omitempty"`
	// Enter credentials directly, or select a stored secret
	AuthType    *AuthTypeAuthenticationMethodPrometheus `default:"manual" json:"authType"`
	Description *string                                 `json:"description,omitempty"`
	// List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'.
	TargetList []string `json:"targetList,omitempty"`
	// List of DNS names to resolve
	NameList []string `json:"nameList,omitempty"`
	// DNS Record type to resolve
	RecordType *RecordTypePrometheus `default:"SRV" json:"recordType"`
	// Protocol to use when collecting metrics
	ScrapeProtocol *MetricsProtocol `default:"http" json:"scrapeProtocol"`
	// Path to use when collecting metrics from discovered targets
	ScrapePath *string `default:"/metrics" json:"scrapePath"`
	// Use public IP address for discovered targets. Set to false if the private IP address should be used.
	UsePublicIP *bool `default:"true" json:"usePublicIp"`
	// The port number in the metrics URL for discovered targets.
	ScrapePort *float64 `default:"9090" json:"scrapePort"`
	// EC2 Instance Search Filter
	SearchFilter []SearchFilterPrometheus `json:"searchFilter,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *AwsAuthenticationMethodAuthenticationMethodPrometheus `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                                                `json:"awsSecretKey,omitempty"`
	// Region where the EC2 is located
	Region *string `json:"region,omitempty"`
	// EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing EC2 requests
	SignatureVersion *SignatureVersionPrometheus `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Use Assume Role credentials to access EC2
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64 `default:"3600" json:"durationSeconds"`
	// Username for Prometheus Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Prometheus Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string   `json:"credentialsSecret,omitempty"`
	Status            *TFStatus `json:"status,omitempty"`
}

func (i InputPrometheus) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheus) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheus) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputPrometheus) GetType() *InputTypePrometheus {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheus) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheus) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheus) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheus) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheus) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheus) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheus) GetConnections() []ConnectionPrometheus {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheus) GetPq() *PqPrometheus {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheus) GetDimensionList() []string {
	if o == nil {
		return nil
	}
	return o.DimensionList
}

func (o *InputPrometheus) GetDiscoveryType() *DiscoveryTypePrometheus {
	if o == nil {
		return nil
	}
	return o.DiscoveryType
}

func (o *InputPrometheus) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *InputPrometheus) GetLogLevel() *LogLevelPrometheus {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputPrometheus) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputPrometheus) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputPrometheus) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputPrometheus) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputPrometheus) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputPrometheus) GetMetadata() []MetadatumPrometheus {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheus) GetAuthType() *AuthTypeAuthenticationMethodPrometheus {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheus) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheus) GetTargetList() []string {
	if o == nil {
		return nil
	}
	return o.TargetList
}

func (o *InputPrometheus) GetNameList() []string {
	if o == nil {
		return nil
	}
	return o.NameList
}

func (o *InputPrometheus) GetRecordType() *RecordTypePrometheus {
	if o == nil {
		return nil
	}
	return o.RecordType
}

func (o *InputPrometheus) GetScrapeProtocol() *MetricsProtocol {
	if o == nil {
		return nil
	}
	return o.ScrapeProtocol
}

func (o *InputPrometheus) GetScrapePath() *string {
	if o == nil {
		return nil
	}
	return o.ScrapePath
}

func (o *InputPrometheus) GetUsePublicIP() *bool {
	if o == nil {
		return nil
	}
	return o.UsePublicIP
}

func (o *InputPrometheus) GetScrapePort() *float64 {
	if o == nil {
		return nil
	}
	return o.ScrapePort
}

func (o *InputPrometheus) GetSearchFilter() []SearchFilterPrometheus {
	if o == nil {
		return nil
	}
	return o.SearchFilter
}

func (o *InputPrometheus) GetAwsAuthenticationMethod() *AwsAuthenticationMethodAuthenticationMethodPrometheus {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputPrometheus) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputPrometheus) GetRegion() *string {
	if o == nil {
		return nil
	}
	return o.Region
}

func (o *InputPrometheus) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputPrometheus) GetSignatureVersion() *SignatureVersionPrometheus {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputPrometheus) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputPrometheus) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputPrometheus) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputPrometheus) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputPrometheus) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputPrometheus) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheus) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheus) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheus) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypePrometheusRw string

const (
	TypePrometheusRwPrometheusRw TypePrometheusRw = "prometheus_rw"
)

func (e TypePrometheusRw) ToPointer() *TypePrometheusRw {
	return &e
}
func (e *TypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "prometheus_rw":
		*e = TypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypePrometheusRw: %v", v)
	}
}

type ConnectionPrometheusRw struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionPrometheusRw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionPrometheusRw) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModePrometheusRw - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModePrometheusRw string

const (
	ModePrometheusRwSmart  ModePrometheusRw = "smart"
	ModePrometheusRwAlways ModePrometheusRw = "always"
)

func (e ModePrometheusRw) ToPointer() *ModePrometheusRw {
	return &e
}
func (e *ModePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModePrometheusRw: %v", v)
	}
}

// CompressionPrometheusRw - Codec to use to compress the persisted data
type CompressionPrometheusRw string

const (
	CompressionPrometheusRwNone CompressionPrometheusRw = "none"
	CompressionPrometheusRwGzip CompressionPrometheusRw = "gzip"
)

func (e CompressionPrometheusRw) ToPointer() *CompressionPrometheusRw {
	return &e
}
func (e *CompressionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionPrometheusRw: %v", v)
	}
}

type PqPrometheusRw struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModePrometheusRw `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionPrometheusRw `default:"none" json:"compress"`
}

func (p PqPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqPrometheusRw) GetMode() *ModePrometheusRw {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqPrometheusRw) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqPrometheusRw) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqPrometheusRw) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqPrometheusRw) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqPrometheusRw) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqPrometheusRw) GetCompress() *CompressionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionPrometheusRw - Minimum TLS version to accept from connections
type MinimumTLSVersionPrometheusRw string

const (
	MinimumTLSVersionPrometheusRwTlSv1  MinimumTLSVersionPrometheusRw = "TLSv1"
	MinimumTLSVersionPrometheusRwTlSv11 MinimumTLSVersionPrometheusRw = "TLSv1.1"
	MinimumTLSVersionPrometheusRwTlSv12 MinimumTLSVersionPrometheusRw = "TLSv1.2"
	MinimumTLSVersionPrometheusRwTlSv13 MinimumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MinimumTLSVersionPrometheusRw) ToPointer() *MinimumTLSVersionPrometheusRw {
	return &e
}
func (e *MinimumTLSVersionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionPrometheusRw: %v", v)
	}
}

// MaximumTLSVersionPrometheusRw - Maximum TLS version to accept from connections
type MaximumTLSVersionPrometheusRw string

const (
	MaximumTLSVersionPrometheusRwTlSv1  MaximumTLSVersionPrometheusRw = "TLSv1"
	MaximumTLSVersionPrometheusRwTlSv11 MaximumTLSVersionPrometheusRw = "TLSv1.1"
	MaximumTLSVersionPrometheusRwTlSv12 MaximumTLSVersionPrometheusRw = "TLSv1.2"
	MaximumTLSVersionPrometheusRwTlSv13 MaximumTLSVersionPrometheusRw = "TLSv1.3"
)

func (e MaximumTLSVersionPrometheusRw) ToPointer() *MaximumTLSVersionPrometheusRw {
	return &e
}
func (e *MaximumTLSVersionPrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionPrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionPrometheusRw: %v", v)
	}
}

type TLSSettingsServerSidePrometheusRw struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionPrometheusRw `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionPrometheusRw `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSidePrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSidePrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSidePrometheusRw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSidePrometheusRw) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSidePrometheusRw) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSidePrometheusRw) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSidePrometheusRw) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSidePrometheusRw) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSidePrometheusRw) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSidePrometheusRw) GetMinVersion() *MinimumTLSVersionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSidePrometheusRw) GetMaxVersion() *MaximumTLSVersionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// AuthenticationTypePrometheusRw - Remote Write authentication type
type AuthenticationTypePrometheusRw string

const (
	AuthenticationTypePrometheusRwNone              AuthenticationTypePrometheusRw = "none"
	AuthenticationTypePrometheusRwBasic             AuthenticationTypePrometheusRw = "basic"
	AuthenticationTypePrometheusRwCredentialsSecret AuthenticationTypePrometheusRw = "credentialsSecret"
	AuthenticationTypePrometheusRwToken             AuthenticationTypePrometheusRw = "token"
	AuthenticationTypePrometheusRwTextSecret        AuthenticationTypePrometheusRw = "textSecret"
	AuthenticationTypePrometheusRwOauth             AuthenticationTypePrometheusRw = "oauth"
)

func (e AuthenticationTypePrometheusRw) ToPointer() *AuthenticationTypePrometheusRw {
	return &e
}
func (e *AuthenticationTypePrometheusRw) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = AuthenticationTypePrometheusRw(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypePrometheusRw: %v", v)
	}
}

type MetadatumPrometheusRw struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthParamPrometheusRw struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderPrometheusRw struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderPrometheusRw) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderPrometheusRw) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusRw struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *TypePrometheusRw `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionPrometheusRw `json:"connections,omitempty"`
	Pq          *PqPrometheusRw          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                            `json:"port"`
	TLS  *TLSSettingsServerSidePrometheusRw `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Prometheus requests. Defaults to /write, which will expand as: http://<yourupstreamURL>:<yourport>/write.
	PrometheusAPI *string `default:"/write" json:"prometheusAPI"`
	// Remote Write authentication type
	AuthType *AuthenticationTypePrometheusRw `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumPrometheusRw `json:"metadata,omitempty"`
	Description *string                 `json:"description,omitempty"`
	Username    *string                 `json:"username,omitempty"`
	Password    *string                 `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamPrometheusRw `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderPrometheusRw `json:"oauthHeaders,omitempty"`
	Status       *TFStatus                 `json:"status,omitempty"`
}

func (i InputPrometheusRw) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusRw) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusRw) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputPrometheusRw) GetType() *TypePrometheusRw {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputPrometheusRw) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPrometheusRw) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputPrometheusRw) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputPrometheusRw) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputPrometheusRw) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputPrometheusRw) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputPrometheusRw) GetConnections() []ConnectionPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputPrometheusRw) GetPq() *PqPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputPrometheusRw) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputPrometheusRw) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputPrometheusRw) GetTLS() *TLSSettingsServerSidePrometheusRw {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputPrometheusRw) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputPrometheusRw) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputPrometheusRw) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputPrometheusRw) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputPrometheusRw) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputPrometheusRw) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputPrometheusRw) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputPrometheusRw) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputPrometheusRw) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputPrometheusRw) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputPrometheusRw) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputPrometheusRw) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputPrometheusRw) GetAuthType() *AuthenticationTypePrometheusRw {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheusRw) GetMetadata() []MetadatumPrometheusRw {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputPrometheusRw) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputPrometheusRw) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheusRw) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheusRw) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputPrometheusRw) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheusRw) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputPrometheusRw) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputPrometheusRw) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputPrometheusRw) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputPrometheusRw) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputPrometheusRw) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputPrometheusRw) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputPrometheusRw) GetOauthParams() []OauthParamPrometheusRw {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputPrometheusRw) GetOauthHeaders() []OauthHeaderPrometheusRw {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputPrometheusRw) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeLoki string

const (
	InputTypeLokiLoki InputTypeLoki = "loki"
)

func (e InputTypeLoki) ToPointer() *InputTypeLoki {
	return &e
}
func (e *InputTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "loki":
		*e = InputTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeLoki: %v", v)
	}
}

type ConnectionLoki struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionLoki) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeLoki - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeLoki string

const (
	PqModeLokiSmart  PqModeLoki = "smart"
	PqModeLokiAlways PqModeLoki = "always"
)

func (e PqModeLoki) ToPointer() *PqModeLoki {
	return &e
}
func (e *PqModeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeLoki: %v", v)
	}
}

// PqCompressionLoki - Codec to use to compress the persisted data
type PqCompressionLoki string

const (
	PqCompressionLokiNone PqCompressionLoki = "none"
	PqCompressionLokiGzip PqCompressionLoki = "gzip"
)

func (e PqCompressionLoki) ToPointer() *PqCompressionLoki {
	return &e
}
func (e *PqCompressionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionLoki: %v", v)
	}
}

type PqLoki struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeLoki `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionLoki `default:"none" json:"compress"`
}

func (p PqLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqLoki) GetMode() *PqModeLoki {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqLoki) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqLoki) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqLoki) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqLoki) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqLoki) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqLoki) GetCompress() *PqCompressionLoki {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionLoki - Minimum TLS version to accept from connections
type MinimumTLSVersionLoki string

const (
	MinimumTLSVersionLokiTlSv1  MinimumTLSVersionLoki = "TLSv1"
	MinimumTLSVersionLokiTlSv11 MinimumTLSVersionLoki = "TLSv1.1"
	MinimumTLSVersionLokiTlSv12 MinimumTLSVersionLoki = "TLSv1.2"
	MinimumTLSVersionLokiTlSv13 MinimumTLSVersionLoki = "TLSv1.3"
)

func (e MinimumTLSVersionLoki) ToPointer() *MinimumTLSVersionLoki {
	return &e
}
func (e *MinimumTLSVersionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionLoki: %v", v)
	}
}

// MaximumTLSVersionLoki - Maximum TLS version to accept from connections
type MaximumTLSVersionLoki string

const (
	MaximumTLSVersionLokiTlSv1  MaximumTLSVersionLoki = "TLSv1"
	MaximumTLSVersionLokiTlSv11 MaximumTLSVersionLoki = "TLSv1.1"
	MaximumTLSVersionLokiTlSv12 MaximumTLSVersionLoki = "TLSv1.2"
	MaximumTLSVersionLokiTlSv13 MaximumTLSVersionLoki = "TLSv1.3"
)

func (e MaximumTLSVersionLoki) ToPointer() *MaximumTLSVersionLoki {
	return &e
}
func (e *MaximumTLSVersionLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionLoki: %v", v)
	}
}

type TLSSettingsServerSideLoki struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionLoki `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionLoki `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideLoki) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideLoki) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideLoki) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideLoki) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideLoki) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideLoki) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideLoki) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideLoki) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideLoki) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideLoki) GetMinVersion() *MinimumTLSVersionLoki {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideLoki) GetMaxVersion() *MaximumTLSVersionLoki {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputAuthenticationTypeLoki - Loki logs authentication type
type InputAuthenticationTypeLoki string

const (
	InputAuthenticationTypeLokiNone              InputAuthenticationTypeLoki = "none"
	InputAuthenticationTypeLokiBasic             InputAuthenticationTypeLoki = "basic"
	InputAuthenticationTypeLokiCredentialsSecret InputAuthenticationTypeLoki = "credentialsSecret"
	InputAuthenticationTypeLokiToken             InputAuthenticationTypeLoki = "token"
	InputAuthenticationTypeLokiTextSecret        InputAuthenticationTypeLoki = "textSecret"
	InputAuthenticationTypeLokiOauth             InputAuthenticationTypeLoki = "oauth"
)

func (e InputAuthenticationTypeLoki) ToPointer() *InputAuthenticationTypeLoki {
	return &e
}
func (e *InputAuthenticationTypeLoki) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputAuthenticationTypeLoki(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationTypeLoki: %v", v)
	}
}

type MetadatumLoki struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthParamLoki struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderLoki struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderLoki) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderLoki) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLoki struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputTypeLoki `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionLoki `json:"connections,omitempty"`
	Pq          *PqLoki          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                    `json:"port"`
	TLS  *TLSSettingsServerSideLoki `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'.
	LokiAPI *string `default:"/loki/api/v1/push" json:"lokiAPI"`
	// Loki logs authentication type
	AuthType *InputAuthenticationTypeLoki `default:"none" json:"authType"`
	// Fields to add to events from this input
	Metadata    []MetadatumLoki `json:"metadata,omitempty"`
	Description *string         `json:"description,omitempty"`
	Username    *string         `json:"username,omitempty"`
	Password    *string         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamLoki `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderLoki `json:"oauthHeaders,omitempty"`
	Status       *TFStatus         `json:"status,omitempty"`
}

func (i InputLoki) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLoki) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputLoki) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputLoki) GetType() *InputTypeLoki {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputLoki) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputLoki) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputLoki) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputLoki) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputLoki) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputLoki) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputLoki) GetConnections() []ConnectionLoki {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputLoki) GetPq() *PqLoki {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputLoki) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputLoki) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputLoki) GetTLS() *TLSSettingsServerSideLoki {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputLoki) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputLoki) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputLoki) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputLoki) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputLoki) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputLoki) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputLoki) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputLoki) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputLoki) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputLoki) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputLoki) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputLoki) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputLoki) GetAuthType() *InputAuthenticationTypeLoki {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputLoki) GetMetadata() []MetadatumLoki {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputLoki) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputLoki) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputLoki) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputLoki) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputLoki) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputLoki) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputLoki) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputLoki) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputLoki) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputLoki) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputLoki) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputLoki) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputLoki) GetOauthParams() []OauthParamLoki {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputLoki) GetOauthHeaders() []OauthHeaderLoki {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputLoki) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGrafanaType2 string

const (
	InputGrafanaType2Grafana InputGrafanaType2 = "grafana"
)

func (e InputGrafanaType2) ToPointer() *InputGrafanaType2 {
	return &e
}
func (e *InputGrafanaType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType2: %v", v)
	}
}

type InputGrafanaConnection2 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGrafanaConnection2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaConnection2) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGrafanaMode2 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode2 string

const (
	InputGrafanaMode2Smart  InputGrafanaMode2 = "smart"
	InputGrafanaMode2Always InputGrafanaMode2 = "always"
)

func (e InputGrafanaMode2) ToPointer() *InputGrafanaMode2 {
	return &e
}
func (e *InputGrafanaMode2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGrafanaMode2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMode2: %v", v)
	}
}

// InputGrafanaCompression2 - Codec to use to compress the persisted data
type InputGrafanaCompression2 string

const (
	InputGrafanaCompression2None InputGrafanaCompression2 = "none"
	InputGrafanaCompression2Gzip InputGrafanaCompression2 = "gzip"
)

func (e InputGrafanaCompression2) ToPointer() *InputGrafanaCompression2 {
	return &e
}
func (e *InputGrafanaCompression2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGrafanaCompression2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaCompression2: %v", v)
	}
}

type InputGrafanaPq2 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode2 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGrafanaCompression2 `default:"none" json:"compress"`
}

func (i InputGrafanaPq2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPq2) GetMode() *InputGrafanaMode2 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGrafanaPq2) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGrafanaPq2) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGrafanaPq2) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGrafanaPq2) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGrafanaPq2) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGrafanaPq2) GetCompress() *InputGrafanaCompression2 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputGrafanaMinimumTLSVersion2 - Minimum TLS version to accept from connections
type InputGrafanaMinimumTLSVersion2 string

const (
	InputGrafanaMinimumTLSVersion2TlSv1  InputGrafanaMinimumTLSVersion2 = "TLSv1"
	InputGrafanaMinimumTLSVersion2TlSv11 InputGrafanaMinimumTLSVersion2 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion2TlSv12 InputGrafanaMinimumTLSVersion2 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion2TlSv13 InputGrafanaMinimumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion2) ToPointer() *InputGrafanaMinimumTLSVersion2 {
	return &e
}
func (e *InputGrafanaMinimumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMinimumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMinimumTLSVersion2: %v", v)
	}
}

// InputGrafanaMaximumTLSVersion2 - Maximum TLS version to accept from connections
type InputGrafanaMaximumTLSVersion2 string

const (
	InputGrafanaMaximumTLSVersion2TlSv1  InputGrafanaMaximumTLSVersion2 = "TLSv1"
	InputGrafanaMaximumTLSVersion2TlSv11 InputGrafanaMaximumTLSVersion2 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion2TlSv12 InputGrafanaMaximumTLSVersion2 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion2TlSv13 InputGrafanaMaximumTLSVersion2 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion2) ToPointer() *InputGrafanaMaximumTLSVersion2 {
	return &e
}
func (e *InputGrafanaMaximumTLSVersion2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMaximumTLSVersion2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMaximumTLSVersion2: %v", v)
	}
}

type InputGrafanaTLSSettingsServerSide2 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputGrafanaMinimumTLSVersion2 `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputGrafanaMaximumTLSVersion2 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaTLSSettingsServerSide2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputGrafanaTLSSettingsServerSide2) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputGrafanaTLSSettingsServerSide2) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputGrafanaTLSSettingsServerSide2) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputGrafanaTLSSettingsServerSide2) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputGrafanaTLSSettingsServerSide2) GetMinVersion() *InputGrafanaMinimumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputGrafanaTLSSettingsServerSide2) GetMaxVersion() *InputGrafanaMaximumTLSVersion2 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputGrafanaPrometheusAuthAuthenticationType2 - Remote Write authentication type
type InputGrafanaPrometheusAuthAuthenticationType2 string

const (
	InputGrafanaPrometheusAuthAuthenticationType2None              InputGrafanaPrometheusAuthAuthenticationType2 = "none"
	InputGrafanaPrometheusAuthAuthenticationType2Basic             InputGrafanaPrometheusAuthAuthenticationType2 = "basic"
	InputGrafanaPrometheusAuthAuthenticationType2CredentialsSecret InputGrafanaPrometheusAuthAuthenticationType2 = "credentialsSecret"
	InputGrafanaPrometheusAuthAuthenticationType2Token             InputGrafanaPrometheusAuthAuthenticationType2 = "token"
	InputGrafanaPrometheusAuthAuthenticationType2TextSecret        InputGrafanaPrometheusAuthAuthenticationType2 = "textSecret"
	InputGrafanaPrometheusAuthAuthenticationType2Oauth             InputGrafanaPrometheusAuthAuthenticationType2 = "oauth"
)

func (e InputGrafanaPrometheusAuthAuthenticationType2) ToPointer() *InputGrafanaPrometheusAuthAuthenticationType2 {
	return &e
}
func (e *InputGrafanaPrometheusAuthAuthenticationType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputGrafanaPrometheusAuthAuthenticationType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaPrometheusAuthAuthenticationType2: %v", v)
	}
}

type PrometheusAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthParam2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthParam2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthHeader2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthHeader2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusAuth2 struct {
	// Remote Write authentication type
	AuthType *InputGrafanaPrometheusAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                                        `json:"username,omitempty"`
	Password *string                                        `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (i InputPrometheusAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusAuth2) GetAuthType() *InputGrafanaPrometheusAuthAuthenticationType2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheusAuth2) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheusAuth2) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheusAuth2) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputPrometheusAuth2) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheusAuth2) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputPrometheusAuth2) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputPrometheusAuth2) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputPrometheusAuth2) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputPrometheusAuth2) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputPrometheusAuth2) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputPrometheusAuth2) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputPrometheusAuth2) GetOauthParams() []PrometheusAuthOauthParam2 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputPrometheusAuth2) GetOauthHeaders() []PrometheusAuthOauthHeader2 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// InputGrafanaLokiAuthAuthenticationType2 - Loki logs authentication type
type InputGrafanaLokiAuthAuthenticationType2 string

const (
	InputGrafanaLokiAuthAuthenticationType2None              InputGrafanaLokiAuthAuthenticationType2 = "none"
	InputGrafanaLokiAuthAuthenticationType2Basic             InputGrafanaLokiAuthAuthenticationType2 = "basic"
	InputGrafanaLokiAuthAuthenticationType2CredentialsSecret InputGrafanaLokiAuthAuthenticationType2 = "credentialsSecret"
	InputGrafanaLokiAuthAuthenticationType2Token             InputGrafanaLokiAuthAuthenticationType2 = "token"
	InputGrafanaLokiAuthAuthenticationType2TextSecret        InputGrafanaLokiAuthAuthenticationType2 = "textSecret"
	InputGrafanaLokiAuthAuthenticationType2Oauth             InputGrafanaLokiAuthAuthenticationType2 = "oauth"
)

func (e InputGrafanaLokiAuthAuthenticationType2) ToPointer() *InputGrafanaLokiAuthAuthenticationType2 {
	return &e
}
func (e *InputGrafanaLokiAuthAuthenticationType2) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputGrafanaLokiAuthAuthenticationType2(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaLokiAuthAuthenticationType2: %v", v)
	}
}

type LokiAuthOauthParam2 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *LokiAuthOauthParam2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthParam2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuthOauthHeader2 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *LokiAuthOauthHeader2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthHeader2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLokiAuth2 struct {
	// Loki logs authentication type
	AuthType *InputGrafanaLokiAuthAuthenticationType2 `default:"none" json:"authType"`
	Username *string                                  `json:"username,omitempty"`
	Password *string                                  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam2 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader2 `json:"oauthHeaders,omitempty"`
}

func (i InputLokiAuth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiAuth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputLokiAuth2) GetAuthType() *InputGrafanaLokiAuthAuthenticationType2 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputLokiAuth2) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputLokiAuth2) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputLokiAuth2) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputLokiAuth2) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputLokiAuth2) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputLokiAuth2) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputLokiAuth2) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputLokiAuth2) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputLokiAuth2) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputLokiAuth2) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputLokiAuth2) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputLokiAuth2) GetOauthParams() []LokiAuthOauthParam2 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputLokiAuth2) GetOauthHeaders() []LokiAuthOauthHeader2 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaMetadatum2 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGrafanaMetadatum2) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaMetadatum2) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaGrafana2 struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputGrafanaType2 `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection2 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq2          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide2 `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string               `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *InputPrometheusAuth2 `json:"prometheusAuth,omitempty"`
	LokiAuth       *InputLokiAuth2       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputGrafanaMetadatum2 `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
	Status      *TFStatus                `json:"status,omitempty"`
}

func (i InputGrafanaGrafana2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaGrafana2) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGrafanaGrafana2) GetType() *InputGrafanaType2 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafanaGrafana2) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaGrafana2) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaGrafana2) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafanaGrafana2) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafanaGrafana2) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafanaGrafana2) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafanaGrafana2) GetConnections() []InputGrafanaConnection2 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafanaGrafana2) GetPq() *InputGrafanaPq2 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafanaGrafana2) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafanaGrafana2) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafanaGrafana2) GetTLS() *InputGrafanaTLSSettingsServerSide2 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafanaGrafana2) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafanaGrafana2) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafanaGrafana2) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafanaGrafana2) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafanaGrafana2) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafanaGrafana2) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafanaGrafana2) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafanaGrafana2) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafanaGrafana2) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafanaGrafana2) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafanaGrafana2) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafanaGrafana2) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafanaGrafana2) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafanaGrafana2) GetPrometheusAuth() *InputPrometheusAuth2 {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafanaGrafana2) GetLokiAuth() *InputLokiAuth2 {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafanaGrafana2) GetMetadata() []InputGrafanaMetadatum2 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafanaGrafana2) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGrafanaGrafana2) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGrafanaType1 string

const (
	InputGrafanaType1Grafana InputGrafanaType1 = "grafana"
)

func (e InputGrafanaType1) ToPointer() *InputGrafanaType1 {
	return &e
}
func (e *InputGrafanaType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grafana":
		*e = InputGrafanaType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaType1: %v", v)
	}
}

type InputGrafanaConnection1 struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *InputGrafanaConnection1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaConnection1) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// InputGrafanaMode1 - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputGrafanaMode1 string

const (
	InputGrafanaMode1Smart  InputGrafanaMode1 = "smart"
	InputGrafanaMode1Always InputGrafanaMode1 = "always"
)

func (e InputGrafanaMode1) ToPointer() *InputGrafanaMode1 {
	return &e
}
func (e *InputGrafanaMode1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputGrafanaMode1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMode1: %v", v)
	}
}

// InputGrafanaCompression1 - Codec to use to compress the persisted data
type InputGrafanaCompression1 string

const (
	InputGrafanaCompression1None InputGrafanaCompression1 = "none"
	InputGrafanaCompression1Gzip InputGrafanaCompression1 = "gzip"
)

func (e InputGrafanaCompression1) ToPointer() *InputGrafanaCompression1 {
	return &e
}
func (e *InputGrafanaCompression1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputGrafanaCompression1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaCompression1: %v", v)
	}
}

type InputGrafanaPq1 struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputGrafanaMode1 `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *InputGrafanaCompression1 `default:"none" json:"compress"`
}

func (i InputGrafanaPq1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaPq1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaPq1) GetMode() *InputGrafanaMode1 {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputGrafanaPq1) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputGrafanaPq1) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputGrafanaPq1) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputGrafanaPq1) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputGrafanaPq1) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *InputGrafanaPq1) GetCompress() *InputGrafanaCompression1 {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputGrafanaMinimumTLSVersion1 - Minimum TLS version to accept from connections
type InputGrafanaMinimumTLSVersion1 string

const (
	InputGrafanaMinimumTLSVersion1TlSv1  InputGrafanaMinimumTLSVersion1 = "TLSv1"
	InputGrafanaMinimumTLSVersion1TlSv11 InputGrafanaMinimumTLSVersion1 = "TLSv1.1"
	InputGrafanaMinimumTLSVersion1TlSv12 InputGrafanaMinimumTLSVersion1 = "TLSv1.2"
	InputGrafanaMinimumTLSVersion1TlSv13 InputGrafanaMinimumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMinimumTLSVersion1) ToPointer() *InputGrafanaMinimumTLSVersion1 {
	return &e
}
func (e *InputGrafanaMinimumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMinimumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMinimumTLSVersion1: %v", v)
	}
}

// InputGrafanaMaximumTLSVersion1 - Maximum TLS version to accept from connections
type InputGrafanaMaximumTLSVersion1 string

const (
	InputGrafanaMaximumTLSVersion1TlSv1  InputGrafanaMaximumTLSVersion1 = "TLSv1"
	InputGrafanaMaximumTLSVersion1TlSv11 InputGrafanaMaximumTLSVersion1 = "TLSv1.1"
	InputGrafanaMaximumTLSVersion1TlSv12 InputGrafanaMaximumTLSVersion1 = "TLSv1.2"
	InputGrafanaMaximumTLSVersion1TlSv13 InputGrafanaMaximumTLSVersion1 = "TLSv1.3"
)

func (e InputGrafanaMaximumTLSVersion1) ToPointer() *InputGrafanaMaximumTLSVersion1 {
	return &e
}
func (e *InputGrafanaMaximumTLSVersion1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputGrafanaMaximumTLSVersion1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaMaximumTLSVersion1: %v", v)
	}
}

type InputGrafanaTLSSettingsServerSide1 struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputGrafanaMinimumTLSVersion1 `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputGrafanaMaximumTLSVersion1 `json:"maxVersion,omitempty"`
}

func (i InputGrafanaTLSSettingsServerSide1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaTLSSettingsServerSide1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaTLSSettingsServerSide1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputGrafanaTLSSettingsServerSide1) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputGrafanaTLSSettingsServerSide1) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *InputGrafanaTLSSettingsServerSide1) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputGrafanaTLSSettingsServerSide1) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *InputGrafanaTLSSettingsServerSide1) GetMinVersion() *InputGrafanaMinimumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputGrafanaTLSSettingsServerSide1) GetMaxVersion() *InputGrafanaMaximumTLSVersion1 {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputGrafanaPrometheusAuthAuthenticationType1 - Remote Write authentication type
type InputGrafanaPrometheusAuthAuthenticationType1 string

const (
	InputGrafanaPrometheusAuthAuthenticationType1None              InputGrafanaPrometheusAuthAuthenticationType1 = "none"
	InputGrafanaPrometheusAuthAuthenticationType1Basic             InputGrafanaPrometheusAuthAuthenticationType1 = "basic"
	InputGrafanaPrometheusAuthAuthenticationType1CredentialsSecret InputGrafanaPrometheusAuthAuthenticationType1 = "credentialsSecret"
	InputGrafanaPrometheusAuthAuthenticationType1Token             InputGrafanaPrometheusAuthAuthenticationType1 = "token"
	InputGrafanaPrometheusAuthAuthenticationType1TextSecret        InputGrafanaPrometheusAuthAuthenticationType1 = "textSecret"
	InputGrafanaPrometheusAuthAuthenticationType1Oauth             InputGrafanaPrometheusAuthAuthenticationType1 = "oauth"
)

func (e InputGrafanaPrometheusAuthAuthenticationType1) ToPointer() *InputGrafanaPrometheusAuthAuthenticationType1 {
	return &e
}
func (e *InputGrafanaPrometheusAuthAuthenticationType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputGrafanaPrometheusAuthAuthenticationType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaPrometheusAuthAuthenticationType1: %v", v)
	}
}

type PrometheusAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthParam1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthParam1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type PrometheusAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *PrometheusAuthOauthHeader1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *PrometheusAuthOauthHeader1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputPrometheusAuth1 struct {
	// Remote Write authentication type
	AuthType *InputGrafanaPrometheusAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                                        `json:"username,omitempty"`
	Password *string                                        `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []PrometheusAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []PrometheusAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (i InputPrometheusAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPrometheusAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPrometheusAuth1) GetAuthType() *InputGrafanaPrometheusAuthAuthenticationType1 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputPrometheusAuth1) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputPrometheusAuth1) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputPrometheusAuth1) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputPrometheusAuth1) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputPrometheusAuth1) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputPrometheusAuth1) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputPrometheusAuth1) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputPrometheusAuth1) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputPrometheusAuth1) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputPrometheusAuth1) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputPrometheusAuth1) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputPrometheusAuth1) GetOauthParams() []PrometheusAuthOauthParam1 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputPrometheusAuth1) GetOauthHeaders() []PrometheusAuthOauthHeader1 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

// InputGrafanaLokiAuthAuthenticationType1 - Loki logs authentication type
type InputGrafanaLokiAuthAuthenticationType1 string

const (
	InputGrafanaLokiAuthAuthenticationType1None              InputGrafanaLokiAuthAuthenticationType1 = "none"
	InputGrafanaLokiAuthAuthenticationType1Basic             InputGrafanaLokiAuthAuthenticationType1 = "basic"
	InputGrafanaLokiAuthAuthenticationType1CredentialsSecret InputGrafanaLokiAuthAuthenticationType1 = "credentialsSecret"
	InputGrafanaLokiAuthAuthenticationType1Token             InputGrafanaLokiAuthAuthenticationType1 = "token"
	InputGrafanaLokiAuthAuthenticationType1TextSecret        InputGrafanaLokiAuthAuthenticationType1 = "textSecret"
	InputGrafanaLokiAuthAuthenticationType1Oauth             InputGrafanaLokiAuthAuthenticationType1 = "oauth"
)

func (e InputGrafanaLokiAuthAuthenticationType1) ToPointer() *InputGrafanaLokiAuthAuthenticationType1 {
	return &e
}
func (e *InputGrafanaLokiAuthAuthenticationType1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = InputGrafanaLokiAuthAuthenticationType1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputGrafanaLokiAuthAuthenticationType1: %v", v)
	}
}

type LokiAuthOauthParam1 struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *LokiAuthOauthParam1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthParam1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type LokiAuthOauthHeader1 struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *LokiAuthOauthHeader1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *LokiAuthOauthHeader1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputLokiAuth1 struct {
	// Loki logs authentication type
	AuthType *InputGrafanaLokiAuthAuthenticationType1 `default:"none" json:"authType"`
	Username *string                                  `json:"username,omitempty"`
	Password *string                                  `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []LokiAuthOauthParam1 `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []LokiAuthOauthHeader1 `json:"oauthHeaders,omitempty"`
}

func (i InputLokiAuth1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputLokiAuth1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputLokiAuth1) GetAuthType() *InputGrafanaLokiAuthAuthenticationType1 {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputLokiAuth1) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputLokiAuth1) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputLokiAuth1) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputLokiAuth1) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputLokiAuth1) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputLokiAuth1) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputLokiAuth1) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputLokiAuth1) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputLokiAuth1) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputLokiAuth1) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputLokiAuth1) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputLokiAuth1) GetOauthParams() []LokiAuthOauthParam1 {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputLokiAuth1) GetOauthHeaders() []LokiAuthOauthHeader1 {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

type InputGrafanaMetadatum1 struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputGrafanaMetadatum1) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputGrafanaMetadatum1) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputGrafanaGrafana1 struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     *InputGrafanaType1 `json:"type,omitempty"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []InputGrafanaConnection1 `json:"connections,omitempty"`
	Pq          *InputGrafanaPq1          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                             `json:"port"`
	TLS  *InputGrafanaTLSSettingsServerSide1 `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// Maximum time to wait for additional data, after the last response was sent, before closing a socket connection. This can be very useful when Grafana Agent remote write's request frequency is high so, reusing connections, would help mitigating the cost of creating a new connection per request. Note that Grafana Agent's embedded Prometheus would attempt to keep connections open for up to 5 minutes.
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Grafana Agent's Remote Write requests. Defaults to /api/prom/push, which will expand as: 'http://<yourupstreamURL>:<yourport>/api/prom/push'. Either this field or 'Logs API endpoint' must be configured.
	PrometheusAPI *string `default:"/api/prom/push" json:"prometheusAPI"`
	// Absolute path on which to listen for Loki logs requests. Defaults to /loki/api/v1/push, which will (in this example) expand as: 'http://<yourupstreamURL>:<yourport>/loki/api/v1/push'. Either this field or 'Remote Write API endpoint' must be configured.
	LokiAPI        *string               `default:"/loki/api/v1/push" json:"lokiAPI"`
	PrometheusAuth *InputPrometheusAuth1 `json:"prometheusAuth,omitempty"`
	LokiAuth       *InputLokiAuth1       `json:"lokiAuth,omitempty"`
	// Fields to add to events from this input
	Metadata    []InputGrafanaMetadatum1 `json:"metadata,omitempty"`
	Description *string                  `json:"description,omitempty"`
	Status      *TFStatus                `json:"status,omitempty"`
}

func (i InputGrafanaGrafana1) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputGrafanaGrafana1) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputGrafanaGrafana1) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputGrafanaGrafana1) GetType() *InputGrafanaType1 {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputGrafanaGrafana1) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputGrafanaGrafana1) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputGrafanaGrafana1) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputGrafanaGrafana1) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputGrafanaGrafana1) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputGrafanaGrafana1) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputGrafanaGrafana1) GetConnections() []InputGrafanaConnection1 {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputGrafanaGrafana1) GetPq() *InputGrafanaPq1 {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputGrafanaGrafana1) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputGrafanaGrafana1) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputGrafanaGrafana1) GetTLS() *InputGrafanaTLSSettingsServerSide1 {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputGrafanaGrafana1) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputGrafanaGrafana1) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputGrafanaGrafana1) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputGrafanaGrafana1) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputGrafanaGrafana1) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputGrafanaGrafana1) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputGrafanaGrafana1) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputGrafanaGrafana1) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputGrafanaGrafana1) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputGrafanaGrafana1) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputGrafanaGrafana1) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputGrafanaGrafana1) GetPrometheusAPI() *string {
	if o == nil {
		return nil
	}
	return o.PrometheusAPI
}

func (o *InputGrafanaGrafana1) GetLokiAPI() *string {
	if o == nil {
		return nil
	}
	return o.LokiAPI
}

func (o *InputGrafanaGrafana1) GetPrometheusAuth() *InputPrometheusAuth1 {
	if o == nil {
		return nil
	}
	return o.PrometheusAuth
}

func (o *InputGrafanaGrafana1) GetLokiAuth() *InputLokiAuth1 {
	if o == nil {
		return nil
	}
	return o.LokiAuth
}

func (o *InputGrafanaGrafana1) GetMetadata() []InputGrafanaMetadatum1 {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputGrafanaGrafana1) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputGrafanaGrafana1) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputGrafanaType string

const (
	InputGrafanaTypeInputGrafanaGrafana1 InputGrafanaType = "InputGrafana_Grafana_1"
	InputGrafanaTypeInputGrafanaGrafana2 InputGrafanaType = "InputGrafana_Grafana_2"
)

type InputGrafana struct {
	InputGrafanaGrafana1 *InputGrafanaGrafana1 `queryParam:"inline"`
	InputGrafanaGrafana2 *InputGrafanaGrafana2 `queryParam:"inline"`

	Type InputGrafanaType
}

func CreateInputGrafanaInputGrafanaGrafana1(inputGrafanaGrafana1 InputGrafanaGrafana1) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana1

	return InputGrafana{
		InputGrafanaGrafana1: &inputGrafanaGrafana1,
		Type:                 typ,
	}
}

func CreateInputGrafanaInputGrafanaGrafana2(inputGrafanaGrafana2 InputGrafanaGrafana2) InputGrafana {
	typ := InputGrafanaTypeInputGrafanaGrafana2

	return InputGrafana{
		InputGrafanaGrafana2: &inputGrafanaGrafana2,
		Type:                 typ,
	}
}

func (u *InputGrafana) UnmarshalJSON(data []byte) error {

	var inputGrafanaGrafana1 InputGrafanaGrafana1 = InputGrafanaGrafana1{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana1, "", true, true); err == nil {
		u.InputGrafanaGrafana1 = &inputGrafanaGrafana1
		u.Type = InputGrafanaTypeInputGrafanaGrafana1
		return nil
	}

	var inputGrafanaGrafana2 InputGrafanaGrafana2 = InputGrafanaGrafana2{}
	if err := utils.UnmarshalJSON(data, &inputGrafanaGrafana2, "", true, true); err == nil {
		u.InputGrafanaGrafana2 = &inputGrafanaGrafana2
		u.Type = InputGrafanaTypeInputGrafanaGrafana2
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for InputGrafana", string(data))
}

func (u InputGrafana) MarshalJSON() ([]byte, error) {
	if u.InputGrafanaGrafana1 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana1, "", true)
	}

	if u.InputGrafanaGrafana2 != nil {
		return utils.MarshalJSON(u.InputGrafanaGrafana2, "", true)
	}

	return nil, errors.New("could not marshal union type InputGrafana: all fields are null")
}

type InputTypeConfluentCloud string

const (
	InputTypeConfluentCloudConfluentCloud InputTypeConfluentCloud = "confluent_cloud"
)

func (e InputTypeConfluentCloud) ToPointer() *InputTypeConfluentCloud {
	return &e
}
func (e *InputTypeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = InputTypeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeConfluentCloud: %v", v)
	}
}

type ConnectionConfluentCloud struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionConfluentCloud) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeConfluentCloud - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeConfluentCloud string

const (
	PqModeConfluentCloudSmart  PqModeConfluentCloud = "smart"
	PqModeConfluentCloudAlways PqModeConfluentCloud = "always"
)

func (e PqModeConfluentCloud) ToPointer() *PqModeConfluentCloud {
	return &e
}
func (e *PqModeConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeConfluentCloud: %v", v)
	}
}

// PqCompressionConfluentCloud - Codec to use to compress the persisted data
type PqCompressionConfluentCloud string

const (
	PqCompressionConfluentCloudNone PqCompressionConfluentCloud = "none"
	PqCompressionConfluentCloudGzip PqCompressionConfluentCloud = "gzip"
)

func (e PqCompressionConfluentCloud) ToPointer() *PqCompressionConfluentCloud {
	return &e
}
func (e *PqCompressionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionConfluentCloud: %v", v)
	}
}

type PqConfluentCloud struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeConfluentCloud `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionConfluentCloud `default:"none" json:"compress"`
}

func (p PqConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqConfluentCloud) GetMode() *PqModeConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqConfluentCloud) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqConfluentCloud) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqConfluentCloud) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqConfluentCloud) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqConfluentCloud) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqConfluentCloud) GetCompress() *PqCompressionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionConfluentCloud - Minimum TLS version to use when connecting
type InputMinimumTLSVersionConfluentCloud string

const (
	InputMinimumTLSVersionConfluentCloudTlSv1  InputMinimumTLSVersionConfluentCloud = "TLSv1"
	InputMinimumTLSVersionConfluentCloudTlSv11 InputMinimumTLSVersionConfluentCloud = "TLSv1.1"
	InputMinimumTLSVersionConfluentCloudTlSv12 InputMinimumTLSVersionConfluentCloud = "TLSv1.2"
	InputMinimumTLSVersionConfluentCloudTlSv13 InputMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputMinimumTLSVersionConfluentCloud) ToPointer() *InputMinimumTLSVersionConfluentCloud {
	return &e
}
func (e *InputMinimumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionConfluentCloud: %v", v)
	}
}

// InputMaximumTLSVersionConfluentCloud - Maximum TLS version to use when connecting
type InputMaximumTLSVersionConfluentCloud string

const (
	InputMaximumTLSVersionConfluentCloudTlSv1  InputMaximumTLSVersionConfluentCloud = "TLSv1"
	InputMaximumTLSVersionConfluentCloudTlSv11 InputMaximumTLSVersionConfluentCloud = "TLSv1.1"
	InputMaximumTLSVersionConfluentCloudTlSv12 InputMaximumTLSVersionConfluentCloud = "TLSv1.2"
	InputMaximumTLSVersionConfluentCloudTlSv13 InputMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputMaximumTLSVersionConfluentCloud) ToPointer() *InputMaximumTLSVersionConfluentCloud {
	return &e
}
func (e *InputMaximumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionConfluentCloud: %v", v)
	}
}

type InputTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetMinVersion() *InputMinimumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputTLSSettingsClientSideConfluentCloud) GetMaxVersion() *InputMaximumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// InputAuthConfluentCloud - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthConfluentCloud struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAuthConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAuthConfluentCloud) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud - Minimum TLS version to use when connecting
type InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloudTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	return &e
}
func (e *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud: %v", v)
	}
}

// InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud - Maximum TLS version to use when connecting
type InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloudTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	return &e
}
func (e *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud: %v", v)
	}
}

type InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationConfluentCloud struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthConfluentCloud                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetAuth() *InputAuthConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *InputKafkaSchemaRegistryAuthenticationConfluentCloud) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideConfluentCloud {
	if o == nil {
		return nil
	}
	return o.TLS
}

// InputSASLMechanismConfluentCloud - SASL authentication mechanism to use.
type InputSASLMechanismConfluentCloud string

const (
	InputSASLMechanismConfluentCloudPlain       InputSASLMechanismConfluentCloud = "plain"
	InputSASLMechanismConfluentCloudScramSha256 InputSASLMechanismConfluentCloud = "scram-sha-256"
	InputSASLMechanismConfluentCloudScramSha512 InputSASLMechanismConfluentCloud = "scram-sha-512"
	InputSASLMechanismConfluentCloudKerberos    InputSASLMechanismConfluentCloud = "kerberos"
)

func (e InputSASLMechanismConfluentCloud) ToPointer() *InputSASLMechanismConfluentCloud {
	return &e
}
func (e *InputSASLMechanismConfluentCloud) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = InputSASLMechanismConfluentCloud(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSASLMechanismConfluentCloud: %v", v)
	}
}

// InputAuthenticationConfluentCloud - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputAuthenticationConfluentCloud struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *InputSASLMechanismConfluentCloud `default:"plain" json:"mechanism"`
}

func (i InputAuthenticationConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthenticationConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAuthenticationConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAuthenticationConfluentCloud) GetMechanism() *InputSASLMechanismConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

type MetadatumConfluentCloud struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumConfluentCloud) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumConfluentCloud) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputConfluentCloud struct {
	// Unique ID for this input
	ID       *string                  `json:"id,omitempty"`
	Type     *InputTypeConfluentCloud `json:"type,omitempty"`
	Disabled *bool                    `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionConfluentCloud `json:"connections,omitempty"`
	Pq          *PqConfluentCloud          `json:"pq,omitempty"`
	// List of Confluent Cloud bootstrap servers to use, such as yourAccount.confluent.cloud:9092
	Brokers []string                                  `json:"brokers"`
	TLS     *InputTLSSettingsClientSideConfluentCloud `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                                 `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationConfluentCloud `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputAuthenticationConfluentCloud `json:"sasl,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []MetadatumConfluentCloud `json:"metadata,omitempty"`
	Description *string                   `json:"description,omitempty"`
	Status      *TFStatus                 `json:"status,omitempty"`
}

func (i InputConfluentCloud) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputConfluentCloud) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputConfluentCloud) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputConfluentCloud) GetType() *InputTypeConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputConfluentCloud) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputConfluentCloud) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputConfluentCloud) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputConfluentCloud) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputConfluentCloud) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputConfluentCloud) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputConfluentCloud) GetConnections() []ConnectionConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputConfluentCloud) GetPq() *PqConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputConfluentCloud) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputConfluentCloud) GetTLS() *InputTLSSettingsClientSideConfluentCloud {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputConfluentCloud) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputConfluentCloud) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputConfluentCloud) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputConfluentCloud) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationConfluentCloud {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputConfluentCloud) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputConfluentCloud) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputConfluentCloud) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputConfluentCloud) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputConfluentCloud) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputConfluentCloud) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputConfluentCloud) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputConfluentCloud) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputConfluentCloud) GetSasl() *InputAuthenticationConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputConfluentCloud) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputConfluentCloud) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputConfluentCloud) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputConfluentCloud) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputConfluentCloud) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputConfluentCloud) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputConfluentCloud) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputConfluentCloud) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputConfluentCloud) GetMetadata() []MetadatumConfluentCloud {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputConfluentCloud) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputConfluentCloud) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeElastic string

const (
	InputTypeElasticElastic InputTypeElastic = "elastic"
)

func (e InputTypeElastic) ToPointer() *InputTypeElastic {
	return &e
}
func (e *InputTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "elastic":
		*e = InputTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeElastic: %v", v)
	}
}

type ConnectionElastic struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionElastic) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeElastic - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeElastic string

const (
	PqModeElasticSmart  PqModeElastic = "smart"
	PqModeElasticAlways PqModeElastic = "always"
)

func (e PqModeElastic) ToPointer() *PqModeElastic {
	return &e
}
func (e *PqModeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeElastic: %v", v)
	}
}

// PqCompressionElastic - Codec to use to compress the persisted data
type PqCompressionElastic string

const (
	PqCompressionElasticNone PqCompressionElastic = "none"
	PqCompressionElasticGzip PqCompressionElastic = "gzip"
)

func (e PqCompressionElastic) ToPointer() *PqCompressionElastic {
	return &e
}
func (e *PqCompressionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionElastic: %v", v)
	}
}

type PqElastic struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeElastic `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionElastic `default:"none" json:"compress"`
}

func (p PqElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqElastic) GetMode() *PqModeElastic {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqElastic) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqElastic) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqElastic) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqElastic) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqElastic) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqElastic) GetCompress() *PqCompressionElastic {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionElastic - Minimum TLS version to accept from connections
type MinimumTLSVersionElastic string

const (
	MinimumTLSVersionElasticTlSv1  MinimumTLSVersionElastic = "TLSv1"
	MinimumTLSVersionElasticTlSv11 MinimumTLSVersionElastic = "TLSv1.1"
	MinimumTLSVersionElasticTlSv12 MinimumTLSVersionElastic = "TLSv1.2"
	MinimumTLSVersionElasticTlSv13 MinimumTLSVersionElastic = "TLSv1.3"
)

func (e MinimumTLSVersionElastic) ToPointer() *MinimumTLSVersionElastic {
	return &e
}
func (e *MinimumTLSVersionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionElastic: %v", v)
	}
}

// MaximumTLSVersionElastic - Maximum TLS version to accept from connections
type MaximumTLSVersionElastic string

const (
	MaximumTLSVersionElasticTlSv1  MaximumTLSVersionElastic = "TLSv1"
	MaximumTLSVersionElasticTlSv11 MaximumTLSVersionElastic = "TLSv1.1"
	MaximumTLSVersionElasticTlSv12 MaximumTLSVersionElastic = "TLSv1.2"
	MaximumTLSVersionElasticTlSv13 MaximumTLSVersionElastic = "TLSv1.3"
)

func (e MaximumTLSVersionElastic) ToPointer() *MaximumTLSVersionElastic {
	return &e
}
func (e *MaximumTLSVersionElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionElastic: %v", v)
	}
}

type TLSSettingsServerSideElastic struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionElastic `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionElastic `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideElastic) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideElastic) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideElastic) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideElastic) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideElastic) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideElastic) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideElastic) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideElastic) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideElastic) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideElastic) GetMinVersion() *MinimumTLSVersionElastic {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideElastic) GetMaxVersion() *MaximumTLSVersionElastic {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

// AuthenticationTypeElastic - Elastic authentication type
type AuthenticationTypeElastic string

const (
	AuthenticationTypeElasticNone              AuthenticationTypeElastic = "none"
	AuthenticationTypeElasticBasic             AuthenticationTypeElastic = "basic"
	AuthenticationTypeElasticCredentialsSecret AuthenticationTypeElastic = "credentialsSecret"
	AuthenticationTypeElasticAuthTokens        AuthenticationTypeElastic = "authTokens"
)

func (e AuthenticationTypeElastic) ToPointer() *AuthenticationTypeElastic {
	return &e
}
func (e *AuthenticationTypeElastic) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "authTokens":
		*e = AuthenticationTypeElastic(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypeElastic: %v", v)
	}
}

// InputAPIVersion - The API version to use for communicating with the server.
type InputAPIVersion string

const (
	InputAPIVersionSixDot8Dot4   InputAPIVersion = "6.8.4"
	InputAPIVersionEightDot3Dot2 InputAPIVersion = "8.3.2"
	InputAPIVersionCustom        InputAPIVersion = "custom"
)

func (e InputAPIVersion) ToPointer() *InputAPIVersion {
	return &e
}
func (e *InputAPIVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "6.8.4":
		fallthrough
	case "8.3.2":
		fallthrough
	case "custom":
		*e = InputAPIVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAPIVersion: %v", v)
	}
}

type InputExtraHTTPHeader struct {
	// Field name
	Name *string `json:"name,omitempty"`
	// Field value
	Value string `json:"value"`
}

func (o *InputExtraHTTPHeader) GetName() *string {
	if o == nil {
		return nil
	}
	return o.Name
}

func (o *InputExtraHTTPHeader) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type MetadatumElastic struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumElastic) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumElastic) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// ProxyModeAuthenticationMethod - Enter credentials directly, or select a stored secret
type ProxyModeAuthenticationMethod string

const (
	ProxyModeAuthenticationMethodNone   ProxyModeAuthenticationMethod = "none"
	ProxyModeAuthenticationMethodManual ProxyModeAuthenticationMethod = "manual"
	ProxyModeAuthenticationMethodSecret ProxyModeAuthenticationMethod = "secret"
)

func (e ProxyModeAuthenticationMethod) ToPointer() *ProxyModeAuthenticationMethod {
	return &e
}
func (e *ProxyModeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = ProxyModeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ProxyModeAuthenticationMethod: %v", v)
	}
}

type ProxyModeElastic struct {
	// Enable proxying of non-bulk API requests to an external Elastic server. Enable this only if you understand the implications; see docs for more details.
	Enabled *bool `default:"false" json:"enabled"`
	// URL of the Elastic server to proxy non-bulk requests to, e.g., http://elastic:9200
	URL *string `json:"url,omitempty"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// List of headers to remove from the request to proxy
	RemoveHeaders []string `json:"removeHeaders,omitempty"`
	// Amount of time, in seconds, to wait for a proxy request to complete before canceling it.
	TimeoutSec *float64 `default:"60" json:"timeoutSec"`
	// Enter credentials directly, or select a stored secret
	AuthType *ProxyModeAuthenticationMethod `default:"none" json:"authType"`
}

func (p ProxyModeElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *ProxyModeElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *ProxyModeElastic) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *ProxyModeElastic) GetURL() *string {
	if o == nil {
		return nil
	}
	return o.URL
}

func (o *ProxyModeElastic) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *ProxyModeElastic) GetRemoveHeaders() []string {
	if o == nil {
		return nil
	}
	return o.RemoveHeaders
}

func (o *ProxyModeElastic) GetTimeoutSec() *float64 {
	if o == nil {
		return nil
	}
	return o.TimeoutSec
}

func (o *ProxyModeElastic) GetAuthType() *ProxyModeAuthenticationMethod {
	if o == nil {
		return nil
	}
	return o.AuthType
}

type InputElastic struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *InputTypeElastic `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionElastic `json:"connections,omitempty"`
	Pq          *PqElastic          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                       `json:"port"`
	TLS  *TLSSettingsServerSideElastic `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for Elasticsearch API requests. Defaults to /. _bulk will be appended automatically, e.g., /myPath becomes /myPath/_bulk. Requests can then be made to either /myPath/_bulk or /myPath/<myIndexName>/_bulk. Other entries are faked as success.
	ElasticAPI *string `default:"/" json:"elasticAPI"`
	// Elastic authentication type
	AuthType *AuthenticationTypeElastic `default:"none" json:"authType"`
	// The API version to use for communicating with the server.
	APIVersion *InputAPIVersion `default:"8.3.2" json:"apiVersion"`
	// Headers to add to all events.
	ExtraHTTPHeaders []InputExtraHTTPHeader `json:"extraHttpHeaders,omitempty"`
	// Fields to add to events from this input
	Metadata []MetadatumElastic `json:"metadata,omitempty"`
	// Whether to ignore extra HTTP headers that don't start with X- or x-
	IgnoreStandardHeaders *bool             `default:"false" json:"ignoreStandardHeaders"`
	ProxyMode             *ProxyModeElastic `json:"proxyMode,omitempty"`
	Description           *string           `json:"description,omitempty"`
	// Username for Basic authentication
	Username *string `json:"username,omitempty"`
	// Password for Basic authentication
	Password *string `json:"password,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Bearer tokens to include in the authorization header
	AuthTokens []string `json:"authTokens,omitempty"`
	// Custom version information to respond to requests
	CustomAPIVersion *string   `default:"{\n    \"name\": \"AzU84iL\",\n    \"cluster_name\": \"cribl\",\n    \"cluster_uuid\": \"Js6_Z2VKS3KbfRSxPmPbaw\",\n    \"version\": {\n        \"number\": \"8.3.2\",\n        \"build_type\": \"tar\",\n        \"build_hash\": \"bca0c8d\",\n        \"build_date\": \"2019-10-16T06:19:49.319352Z\",\n        \"build_snapshot\": false,\n        \"lucene_version\": \"9.7.2\",\n        \"minimum_wire_compatibility_version\": \"7.17.0\",\n        \"minimum_index_compatibility_version\": \"7.0.0\"\n    },\n    \"tagline\": \"You Know, for Search\"\n}" json:"customAPIVersion"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputElastic) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputElastic) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputElastic) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputElastic) GetType() *InputTypeElastic {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputElastic) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputElastic) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputElastic) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputElastic) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputElastic) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputElastic) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputElastic) GetConnections() []ConnectionElastic {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputElastic) GetPq() *PqElastic {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputElastic) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputElastic) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputElastic) GetTLS() *TLSSettingsServerSideElastic {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputElastic) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputElastic) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputElastic) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputElastic) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputElastic) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputElastic) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputElastic) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputElastic) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputElastic) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputElastic) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputElastic) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputElastic) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputElastic) GetAuthType() *AuthenticationTypeElastic {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputElastic) GetAPIVersion() *InputAPIVersion {
	if o == nil {
		return nil
	}
	return o.APIVersion
}

func (o *InputElastic) GetExtraHTTPHeaders() []InputExtraHTTPHeader {
	if o == nil {
		return nil
	}
	return o.ExtraHTTPHeaders
}

func (o *InputElastic) GetMetadata() []MetadatumElastic {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputElastic) GetIgnoreStandardHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.IgnoreStandardHeaders
}

func (o *InputElastic) GetProxyMode() *ProxyModeElastic {
	if o == nil {
		return nil
	}
	return o.ProxyMode
}

func (o *InputElastic) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputElastic) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputElastic) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputElastic) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputElastic) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputElastic) GetCustomAPIVersion() *string {
	if o == nil {
		return nil
	}
	return o.CustomAPIVersion
}

func (o *InputElastic) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeAzureBlob string

const (
	InputTypeAzureBlobAzureBlob InputTypeAzureBlob = "azure_blob"
)

func (e InputTypeAzureBlob) ToPointer() *InputTypeAzureBlob {
	return &e
}
func (e *InputTypeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = InputTypeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeAzureBlob: %v", v)
	}
}

type ConnectionAzureBlob struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionAzureBlob) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeAzureBlob - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeAzureBlob string

const (
	ModeAzureBlobSmart  ModeAzureBlob = "smart"
	ModeAzureBlobAlways ModeAzureBlob = "always"
)

func (e ModeAzureBlob) ToPointer() *ModeAzureBlob {
	return &e
}
func (e *ModeAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeAzureBlob: %v", v)
	}
}

// CompressionAzureBlob - Codec to use to compress the persisted data
type CompressionAzureBlob string

const (
	CompressionAzureBlobNone CompressionAzureBlob = "none"
	CompressionAzureBlobGzip CompressionAzureBlob = "gzip"
)

func (e CompressionAzureBlob) ToPointer() *CompressionAzureBlob {
	return &e
}
func (e *CompressionAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionAzureBlob: %v", v)
	}
}

type PqAzureBlob struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeAzureBlob `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionAzureBlob `default:"none" json:"compress"`
}

func (p PqAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqAzureBlob) GetMode() *ModeAzureBlob {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqAzureBlob) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqAzureBlob) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqAzureBlob) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqAzureBlob) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqAzureBlob) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqAzureBlob) GetCompress() *CompressionAzureBlob {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumAzureBlob struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumAzureBlob) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumAzureBlob) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputAuthenticationMethodAzureBlob - Enter connection string directly, or select a stored secret
type InputAuthenticationMethodAzureBlob string

const (
	InputAuthenticationMethodAzureBlobManual       InputAuthenticationMethodAzureBlob = "manual"
	InputAuthenticationMethodAzureBlobSecret       InputAuthenticationMethodAzureBlob = "secret"
	InputAuthenticationMethodAzureBlobClientSecret InputAuthenticationMethodAzureBlob = "clientSecret"
	InputAuthenticationMethodAzureBlobClientCert   InputAuthenticationMethodAzureBlob = "clientCert"
)

func (e InputAuthenticationMethodAzureBlob) ToPointer() *InputAuthenticationMethodAzureBlob {
	return &e
}
func (e *InputAuthenticationMethodAzureBlob) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		fallthrough
	case "clientSecret":
		fallthrough
	case "clientCert":
		*e = InputAuthenticationMethodAzureBlob(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodAzureBlob: %v", v)
	}
}

type InputCertificate struct {
	// The certificate you registered as credentials for your app in the Azure portal
	CertificateName string `json:"certificateName"`
}

func (o *InputCertificate) GetCertificateName() string {
	if o == nil {
		return ""
	}
	return o.CertificateName
}

type InputAzureBlob struct {
	// Unique ID for this input
	ID       *string            `json:"id,omitempty"`
	Type     InputTypeAzureBlob `json:"type"`
	Disabled *bool              `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionAzureBlob `json:"connections,omitempty"`
	Pq          *PqAzureBlob          `json:"pq,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `default:"/.*/" json:"fileFilter"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *float64 `default:"600" json:"visibilityTimeout"`
	// How many receiver processes to run. The higher the number, the better the throughput - at the expense of CPU overhead.
	NumReceivers *float64 `default:"1" json:"numReceivers"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *float64 `default:"1" json:"maxMessages"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *float64 `default:"5" json:"servicePeriodSecs"`
	// Skip files that trigger a processing error. Disabled by default, which allows retries after processing errors.
	SkipOnError *bool `default:"false" json:"skipOnError"`
	// Fields to add to events from this input
	Metadata []MetadatumAzureBlob `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Maximum file size for each Parquet chunk
	ParquetChunkSizeMB *float64 `default:"5" json:"parquetChunkSizeMB"`
	// The maximum time allowed for downloading a Parquet chunk. Processing will stop if a chunk cannot be downloaded within the time specified.
	ParquetChunkDownloadTimeout *float64 `default:"600" json:"parquetChunkDownloadTimeout"`
	// Enter connection string directly, or select a stored secret
	AuthType    *InputAuthenticationMethodAzureBlob `default:"manual" json:"authType"`
	Description *string                             `json:"description,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// The name of your Azure storage account
	StorageAccountName *string `json:"storageAccountName,omitempty"`
	// The service principal's tenant ID
	TenantID *string `json:"tenantId,omitempty"`
	// The service principal's client ID
	ClientID *string `json:"clientId,omitempty"`
	// Endpoint suffix for the service URL. Defaults to core.windows.net.
	EndpointSuffix *string `json:"endpointSuffix,omitempty"`
	// Select or create a stored text secret
	ClientTextSecret *string           `json:"clientTextSecret,omitempty"`
	Certificate      *InputCertificate `json:"certificate,omitempty"`
	Status           *TFStatus         `json:"status,omitempty"`
}

func (i InputAzureBlob) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAzureBlob) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputAzureBlob) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputAzureBlob) GetType() InputTypeAzureBlob {
	if o == nil {
		return InputTypeAzureBlob("")
	}
	return o.Type
}

func (o *InputAzureBlob) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAzureBlob) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputAzureBlob) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputAzureBlob) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputAzureBlob) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputAzureBlob) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputAzureBlob) GetConnections() []ConnectionAzureBlob {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputAzureBlob) GetPq() *PqAzureBlob {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputAzureBlob) GetQueueName() string {
	if o == nil {
		return ""
	}
	return o.QueueName
}

func (o *InputAzureBlob) GetFileFilter() *string {
	if o == nil {
		return nil
	}
	return o.FileFilter
}

func (o *InputAzureBlob) GetVisibilityTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.VisibilityTimeout
}

func (o *InputAzureBlob) GetNumReceivers() *float64 {
	if o == nil {
		return nil
	}
	return o.NumReceivers
}

func (o *InputAzureBlob) GetMaxMessages() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMessages
}

func (o *InputAzureBlob) GetServicePeriodSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.ServicePeriodSecs
}

func (o *InputAzureBlob) GetSkipOnError() *bool {
	if o == nil {
		return nil
	}
	return o.SkipOnError
}

func (o *InputAzureBlob) GetMetadata() []MetadatumAzureBlob {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputAzureBlob) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputAzureBlob) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputAzureBlob) GetParquetChunkSizeMB() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkSizeMB
}

func (o *InputAzureBlob) GetParquetChunkDownloadTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ParquetChunkDownloadTimeout
}

func (o *InputAzureBlob) GetAuthType() *InputAuthenticationMethodAzureBlob {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputAzureBlob) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputAzureBlob) GetConnectionString() *string {
	if o == nil {
		return nil
	}
	return o.ConnectionString
}

func (o *InputAzureBlob) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputAzureBlob) GetStorageAccountName() *string {
	if o == nil {
		return nil
	}
	return o.StorageAccountName
}

func (o *InputAzureBlob) GetTenantID() *string {
	if o == nil {
		return nil
	}
	return o.TenantID
}

func (o *InputAzureBlob) GetClientID() *string {
	if o == nil {
		return nil
	}
	return o.ClientID
}

func (o *InputAzureBlob) GetEndpointSuffix() *string {
	if o == nil {
		return nil
	}
	return o.EndpointSuffix
}

func (o *InputAzureBlob) GetClientTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.ClientTextSecret
}

func (o *InputAzureBlob) GetCertificate() *InputCertificate {
	if o == nil {
		return nil
	}
	return o.Certificate
}

func (o *InputAzureBlob) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeSplunkHec string

const (
	InputTypeSplunkHecSplunkHec InputTypeSplunkHec = "splunk_hec"
)

func (e InputTypeSplunkHec) ToPointer() *InputTypeSplunkHec {
	return &e
}
func (e *InputTypeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_hec":
		*e = InputTypeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSplunkHec: %v", v)
	}
}

type ConnectionSplunkHec struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunkHec) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeSplunkHec - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSplunkHec string

const (
	PqModeSplunkHecSmart  PqModeSplunkHec = "smart"
	PqModeSplunkHecAlways PqModeSplunkHec = "always"
)

func (e PqModeSplunkHec) ToPointer() *PqModeSplunkHec {
	return &e
}
func (e *PqModeSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeSplunkHec: %v", v)
	}
}

// PqCompressionSplunkHec - Codec to use to compress the persisted data
type PqCompressionSplunkHec string

const (
	PqCompressionSplunkHecNone PqCompressionSplunkHec = "none"
	PqCompressionSplunkHecGzip PqCompressionSplunkHec = "gzip"
)

func (e PqCompressionSplunkHec) ToPointer() *PqCompressionSplunkHec {
	return &e
}
func (e *PqCompressionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionSplunkHec: %v", v)
	}
}

type PqSplunkHec struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSplunkHec `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionSplunkHec `default:"none" json:"compress"`
}

func (p PqSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunkHec) GetMode() *PqModeSplunkHec {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunkHec) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunkHec) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunkHec) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunkHec) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunkHec) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunkHec) GetCompress() *PqCompressionSplunkHec {
	if o == nil {
		return nil
	}
	return o.Compress
}

// AuthTokenAuthenticationMethodSplunkHec - Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
type AuthTokenAuthenticationMethodSplunkHec string

const (
	AuthTokenAuthenticationMethodSplunkHecManual AuthTokenAuthenticationMethodSplunkHec = "manual"
	AuthTokenAuthenticationMethodSplunkHecSecret AuthTokenAuthenticationMethodSplunkHec = "secret"
)

func (e AuthTokenAuthenticationMethodSplunkHec) ToPointer() *AuthTokenAuthenticationMethodSplunkHec {
	return &e
}
func (e *AuthTokenAuthenticationMethodSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "manual":
		fallthrough
	case "secret":
		*e = AuthTokenAuthenticationMethodSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthTokenAuthenticationMethodSplunkHec: %v", v)
	}
}

type AuthTokenMetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokenMetadatumSplunkHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokenMetadatumSplunkHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenSplunkHec struct {
	// Select Manual to enter an auth token directly, or select Secret to use a text secret to authenticate
	AuthType    *AuthTokenAuthenticationMethodSplunkHec `default:"manual" json:"authType"`
	TokenSecret any                                     `json:"tokenSecret,omitempty"`
	Token       any                                     `json:"token"`
	Enabled     *bool                                   `default:"true" json:"enabled"`
	// Optional token description
	Description *string `json:"description,omitempty"`
	// Enter the values you want to allow in the HEC event index field at the token level. Supports wildcards. To skip validation, leave blank.
	AllowedIndexesAtToken []string `json:"allowedIndexesAtToken,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokenMetadatumSplunkHec `json:"metadata,omitempty"`
}

func (a AuthTokenSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AuthTokenSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *AuthTokenSplunkHec) GetAuthType() *AuthTokenAuthenticationMethodSplunkHec {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *AuthTokenSplunkHec) GetTokenSecret() any {
	if o == nil {
		return nil
	}
	return o.TokenSecret
}

func (o *AuthTokenSplunkHec) GetToken() any {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *AuthTokenSplunkHec) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *AuthTokenSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokenSplunkHec) GetAllowedIndexesAtToken() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexesAtToken
}

func (o *AuthTokenSplunkHec) GetMetadata() []AuthTokenMetadatumSplunkHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

// MinimumTLSVersionSplunkHec - Minimum TLS version to accept from connections
type MinimumTLSVersionSplunkHec string

const (
	MinimumTLSVersionSplunkHecTlSv1  MinimumTLSVersionSplunkHec = "TLSv1"
	MinimumTLSVersionSplunkHecTlSv11 MinimumTLSVersionSplunkHec = "TLSv1.1"
	MinimumTLSVersionSplunkHecTlSv12 MinimumTLSVersionSplunkHec = "TLSv1.2"
	MinimumTLSVersionSplunkHecTlSv13 MinimumTLSVersionSplunkHec = "TLSv1.3"
)

func (e MinimumTLSVersionSplunkHec) ToPointer() *MinimumTLSVersionSplunkHec {
	return &e
}
func (e *MinimumTLSVersionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionSplunkHec: %v", v)
	}
}

// MaximumTLSVersionSplunkHec - Maximum TLS version to accept from connections
type MaximumTLSVersionSplunkHec string

const (
	MaximumTLSVersionSplunkHecTlSv1  MaximumTLSVersionSplunkHec = "TLSv1"
	MaximumTLSVersionSplunkHecTlSv11 MaximumTLSVersionSplunkHec = "TLSv1.1"
	MaximumTLSVersionSplunkHecTlSv12 MaximumTLSVersionSplunkHec = "TLSv1.2"
	MaximumTLSVersionSplunkHecTlSv13 MaximumTLSVersionSplunkHec = "TLSv1.3"
)

func (e MaximumTLSVersionSplunkHec) ToPointer() *MaximumTLSVersionSplunkHec {
	return &e
}
func (e *MaximumTLSVersionSplunkHec) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionSplunkHec(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionSplunkHec: %v", v)
	}
}

type TLSSettingsServerSideSplunkHec struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionSplunkHec `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionSplunkHec `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideSplunkHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideSplunkHec) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideSplunkHec) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideSplunkHec) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideSplunkHec) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideSplunkHec) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideSplunkHec) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideSplunkHec) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideSplunkHec) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideSplunkHec) GetMinVersion() *MinimumTLSVersionSplunkHec {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideSplunkHec) GetMaxVersion() *MaximumTLSVersionSplunkHec {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumSplunkHec struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunkHec) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunkHec) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkHec struct {
	// Unique ID for this input
	ID       *string             `json:"id,omitempty"`
	Type     *InputTypeSplunkHec `json:"type,omitempty"`
	Disabled *bool               `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkHec `json:"connections,omitempty"`
	Pq          *PqSplunkHec          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunkHec            `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideSplunkHec `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout  *float64 `default:"5" json:"keepAliveTimeout"`
	EnableHealthCheck any      `json:"enableHealthCheck,omitempty"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Splunk HTTP Event Collector API requests. This input supports the /event, /raw and /s2s endpoints.
	SplunkHecAPI *string `default:"/services/collector" json:"splunkHecAPI"`
	// Fields to add to every event. Overrides fields added at the token or request level. See [the Source documentation](https://docs.cribl.io/stream/sources-splunk-hec/#fields) for more info.
	Metadata []MetadatumSplunkHec `json:"metadata,omitempty"`
	// List values allowed in HEC event index field. Leave blank to skip validation. Supports wildcards. The values here can expand index validation at the token level.
	AllowedIndexes []string `json:"allowedIndexes,omitempty"`
	// Enable Splunk HEC acknowledgements
	SplunkHecAcks *bool `default:"false" json:"splunkHecAcks"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Optionally, list HTTP origins to which @{product} should send CORS (cross-origin resource sharing) Access-Control-Allow-* headers. Supports wildcards.
	AccessControlAllowOrigin []string `json:"accessControlAllowOrigin,omitempty"`
	// Optionally, list HTTP headers that @{product} will send to allowed origins as "Access-Control-Allow-Headers" in a CORS preflight response. Use "*" to allow all headers.
	AccessControlAllowHeaders []string `json:"accessControlAllowHeaders,omitempty"`
	// Emit per-token (<prefix>.http.perToken) and summary (<prefix>.http.summary) request metrics
	EmitTokenMetrics *bool     `default:"false" json:"emitTokenMetrics"`
	Description      *string   `json:"description,omitempty"`
	Status           *TFStatus `json:"status,omitempty"`
}

func (i InputSplunkHec) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkHec) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkHec) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunkHec) GetType() *InputTypeSplunkHec {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkHec) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkHec) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkHec) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkHec) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkHec) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkHec) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkHec) GetConnections() []ConnectionSplunkHec {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkHec) GetPq() *PqSplunkHec {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkHec) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunkHec) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunkHec) GetAuthTokens() []AuthTokenSplunkHec {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunkHec) GetTLS() *TLSSettingsServerSideSplunkHec {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunkHec) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputSplunkHec) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputSplunkHec) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunkHec) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputSplunkHec) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputSplunkHec) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkHec) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputSplunkHec) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputSplunkHec) GetEnableHealthCheck() any {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputSplunkHec) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputSplunkHec) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputSplunkHec) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputSplunkHec) GetMetadata() []MetadatumSplunkHec {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkHec) GetAllowedIndexes() []string {
	if o == nil {
		return nil
	}
	return o.AllowedIndexes
}

func (o *InputSplunkHec) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputSplunkHec) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkHec) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkHec) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunkHec) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunkHec) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunkHec) GetAccessControlAllowOrigin() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowOrigin
}

func (o *InputSplunkHec) GetAccessControlAllowHeaders() []string {
	if o == nil {
		return nil
	}
	return o.AccessControlAllowHeaders
}

func (o *InputSplunkHec) GetEmitTokenMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.EmitTokenMetrics
}

func (o *InputSplunkHec) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkHec) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type TypeSplunkSearch string

const (
	TypeSplunkSearchSplunkSearch TypeSplunkSearch = "splunk_search"
)

func (e TypeSplunkSearch) ToPointer() *TypeSplunkSearch {
	return &e
}
func (e *TypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk_search":
		*e = TypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TypeSplunkSearch: %v", v)
	}
}

type ConnectionSplunkSearch struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunkSearch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunkSearch) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeSplunkSearch - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeSplunkSearch string

const (
	ModeSplunkSearchSmart  ModeSplunkSearch = "smart"
	ModeSplunkSearchAlways ModeSplunkSearch = "always"
)

func (e ModeSplunkSearch) ToPointer() *ModeSplunkSearch {
	return &e
}
func (e *ModeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeSplunkSearch: %v", v)
	}
}

// CompressionSplunkSearch - Codec to use to compress the persisted data
type CompressionSplunkSearch string

const (
	CompressionSplunkSearchNone CompressionSplunkSearch = "none"
	CompressionSplunkSearchGzip CompressionSplunkSearch = "gzip"
)

func (e CompressionSplunkSearch) ToPointer() *CompressionSplunkSearch {
	return &e
}
func (e *CompressionSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionSplunkSearch: %v", v)
	}
}

type PqSplunkSearch struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeSplunkSearch `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionSplunkSearch `default:"none" json:"compress"`
}

func (p PqSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunkSearch) GetMode() *ModeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunkSearch) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunkSearch) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunkSearch) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunkSearch) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunkSearch) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunkSearch) GetCompress() *CompressionSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Compress
}

// OutputMode - Format of the returned output
type OutputMode string

const (
	OutputModeCsv  OutputMode = "csv"
	OutputModeJSON OutputMode = "json"
)

func (e OutputMode) ToPointer() *OutputMode {
	return &e
}
func (e *OutputMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "csv":
		fallthrough
	case "json":
		*e = OutputMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputMode: %v", v)
	}
}

type EndpointParam struct {
	Name string `json:"name"`
	// JavaScript expression to compute the parameter's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointParam) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointParam) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type EndpointHeader struct {
	Name string `json:"name"`
	// JavaScript expression to compute the header's value, normally enclosed in backticks (e.g., `${earliest}`). If a constant, use single quotes (e.g., 'earliest'). Values without delimiters (e.g., earliest) are evaluated as strings.
	Value string `json:"value"`
}

func (o *EndpointHeader) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *EndpointHeader) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// LogLevelSplunkSearch - Collector runtime log level (verbosity)
type LogLevelSplunkSearch string

const (
	LogLevelSplunkSearchError LogLevelSplunkSearch = "error"
	LogLevelSplunkSearchWarn  LogLevelSplunkSearch = "warn"
	LogLevelSplunkSearchInfo  LogLevelSplunkSearch = "info"
	LogLevelSplunkSearchDebug LogLevelSplunkSearch = "debug"
)

func (e LogLevelSplunkSearch) ToPointer() *LogLevelSplunkSearch {
	return &e
}
func (e *LogLevelSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "warn":
		fallthrough
	case "info":
		fallthrough
	case "debug":
		*e = LogLevelSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LogLevelSplunkSearch: %v", v)
	}
}

type MetadatumSplunkSearch struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// RetryTypeSplunkSearch - The algorithm to use when performing HTTP retries
type RetryTypeSplunkSearch string

const (
	RetryTypeSplunkSearchNone    RetryTypeSplunkSearch = "none"
	RetryTypeSplunkSearchBackoff RetryTypeSplunkSearch = "backoff"
	RetryTypeSplunkSearchStatic  RetryTypeSplunkSearch = "static"
)

func (e RetryTypeSplunkSearch) ToPointer() *RetryTypeSplunkSearch {
	return &e
}
func (e *RetryTypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "backoff":
		fallthrough
	case "static":
		*e = RetryTypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for RetryTypeSplunkSearch: %v", v)
	}
}

type RetryRulesSplunkSearch struct {
	// The algorithm to use when performing HTTP retries
	Type *RetryTypeSplunkSearch `default:"backoff" json:"type"`
	// Time interval between failed request and first retry (kickoff). Maximum allowed value is 20,000 ms (1/3 minute).
	Interval *float64 `default:"1000" json:"interval"`
	// The maximum number of times to retry a failed HTTP request
	Limit *float64 `default:"5" json:"limit"`
	// Base for exponential backoff, e.g., base 2 means that retries will occur after 2, then 4, then 8 seconds, and so on
	Multiplier *float64 `default:"2" json:"multiplier"`
	// List of HTTP codes that trigger a retry. Leave empty to use the default list of 429 and 503.
	Codes []float64 `json:"codes,omitempty"`
	// Honor any Retry-After header that specifies a delay (in seconds) or a timestamp after which to retry the request. The delay is limited to 20 seconds, even if the Retry-After header specifies a longer delay. When disabled, all Retry-After headers are ignored.
	EnableHeader *bool `default:"true" json:"enableHeader"`
	// Make a single retry attempt when a connection timeout (ETIMEDOUT) error occurs
	RetryConnectTimeout *bool `default:"false" json:"retryConnectTimeout"`
	// Retry request when a connection reset (ECONNRESET) error occurs
	RetryConnectReset *bool `default:"false" json:"retryConnectReset"`
}

func (r RetryRulesSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(r, "", false)
}

func (r *RetryRulesSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &r, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *RetryRulesSplunkSearch) GetType() *RetryTypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *RetryRulesSplunkSearch) GetInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.Interval
}

func (o *RetryRulesSplunkSearch) GetLimit() *float64 {
	if o == nil {
		return nil
	}
	return o.Limit
}

func (o *RetryRulesSplunkSearch) GetMultiplier() *float64 {
	if o == nil {
		return nil
	}
	return o.Multiplier
}

func (o *RetryRulesSplunkSearch) GetCodes() []float64 {
	if o == nil {
		return nil
	}
	return o.Codes
}

func (o *RetryRulesSplunkSearch) GetEnableHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHeader
}

func (o *RetryRulesSplunkSearch) GetRetryConnectTimeout() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectTimeout
}

func (o *RetryRulesSplunkSearch) GetRetryConnectReset() *bool {
	if o == nil {
		return nil
	}
	return o.RetryConnectReset
}

// AuthenticationTypeSplunkSearch - Splunk Search authentication type
type AuthenticationTypeSplunkSearch string

const (
	AuthenticationTypeSplunkSearchNone              AuthenticationTypeSplunkSearch = "none"
	AuthenticationTypeSplunkSearchBasic             AuthenticationTypeSplunkSearch = "basic"
	AuthenticationTypeSplunkSearchCredentialsSecret AuthenticationTypeSplunkSearch = "credentialsSecret"
	AuthenticationTypeSplunkSearchToken             AuthenticationTypeSplunkSearch = "token"
	AuthenticationTypeSplunkSearchTextSecret        AuthenticationTypeSplunkSearch = "textSecret"
	AuthenticationTypeSplunkSearchOauth             AuthenticationTypeSplunkSearch = "oauth"
)

func (e AuthenticationTypeSplunkSearch) ToPointer() *AuthenticationTypeSplunkSearch {
	return &e
}
func (e *AuthenticationTypeSplunkSearch) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "basic":
		fallthrough
	case "credentialsSecret":
		fallthrough
	case "token":
		fallthrough
	case "textSecret":
		fallthrough
	case "oauth":
		*e = AuthenticationTypeSplunkSearch(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AuthenticationTypeSplunkSearch: %v", v)
	}
}

type OauthParamSplunkSearch struct {
	// OAuth parameter name
	Name string `json:"name"`
	// OAuth parameter value
	Value string `json:"value"`
}

func (o *OauthParamSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthParamSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type OauthHeaderSplunkSearch struct {
	// OAuth header name
	Name string `json:"name"`
	// OAuth header value
	Value string `json:"value"`
}

func (o *OauthHeaderSplunkSearch) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *OauthHeaderSplunkSearch) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputSplunkSearch struct {
	// Unique ID for this input
	ID       *string           `json:"id,omitempty"`
	Type     *TypeSplunkSearch `json:"type,omitempty"`
	Disabled *bool             `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunkSearch `json:"connections,omitempty"`
	Pq          *PqSplunkSearch          `json:"pq,omitempty"`
	// Search head base URL. Can be an expression. Default is https://localhost:8089.
	SearchHead *string `default:"https://localhost:8089" json:"searchHead"`
	// Enter Splunk search here. Examples: 'index=myAppLogs level=error channel=myApp' OR '| mstats avg(myStat) as myStat WHERE index=myStatsIndex.'
	Search string `json:"search"`
	// The earliest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-16m@m'
	Earliest *string `default:"-16m@m" json:"earliest"`
	// The latest time boundary for the search. Can be an exact or relative time. Examples: '2022-01-14T12:00:00Z' or '-1m@m'
	Latest *string `default:"-1m@m" json:"latest"`
	// A cron schedule on which to run this job
	CronSchedule *string `default:"*/15 * * * *" json:"cronSchedule"`
	// REST API used to create a search
	Endpoint *string `default:"/services/search/v2/jobs/export" json:"endpoint"`
	// Format of the returned output
	OutputMode *OutputMode `default:"json" json:"outputMode"`
	// Optional request parameters to send to the endpoint
	EndpointParams []EndpointParam `json:"endpointParams,omitempty"`
	// Optional request headers to send to the endpoint
	EndpointHeaders []EndpointHeader `json:"endpointHeaders,omitempty"`
	// Collector runtime log level (verbosity)
	LogLevel *LogLevelSplunkSearch `json:"logLevel,omitempty"`
	// HTTP request inactivity timeout. Use 0 for no timeout.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// When a DNS server returns multiple addresses, @{product} will cycle through them in the order returned
	UseRoundRobinDNS *bool `default:"false" json:"useRoundRobinDns"`
	// Reject certificates that cannot be verified against a valid CA (such as self-signed certificates)
	RejectUnauthorized *bool `default:"false" json:"rejectUnauthorized"`
	// Character encoding to use when parsing ingested data. When not set, @{product} will default to UTF-8 but may incorrectly interpret multi-byte characters.
	Encoding *string `json:"encoding,omitempty"`
	// How often workers should check in with the scheduler to keep job subscription alive
	KeepAliveTime *float64 `default:"30" json:"keepAliveTime"`
	// Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time.
	JobTimeout *string `default:"0" json:"jobTimeout"`
	// The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked.
	MaxMissedKeepAlives *float64 `default:"3" json:"maxMissedKeepAlives"`
	// Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector.
	TTL *string `default:"4h" json:"ttl"`
	// Fields to add to events from this input
	Metadata   []MetadatumSplunkSearch `json:"metadata,omitempty"`
	RetryRules *RetryRulesSplunkSearch `json:"retryRules,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Splunk Search authentication type
	AuthType    *AuthenticationTypeSplunkSearch `default:"basic" json:"authType"`
	Description *string                         `json:"description,omitempty"`
	Username    *string                         `json:"username,omitempty"`
	Password    *string                         `json:"password,omitempty"`
	// Bearer token to include in the authorization header
	Token *string `json:"token,omitempty"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
	// Select or create a stored text secret
	TextSecret *string `json:"textSecret,omitempty"`
	// URL for OAuth
	LoginURL *string `json:"loginUrl,omitempty"`
	// Secret parameter name to pass in request body
	SecretParamName *string `json:"secretParamName,omitempty"`
	// Secret parameter value to pass in request body
	Secret *string `json:"secret,omitempty"`
	// Name of the auth token attribute in the OAuth response. Can be top-level (e.g., 'token'); or nested, using a period (e.g., 'data.token').
	TokenAttributeName *string `json:"tokenAttributeName,omitempty"`
	// JavaScript expression to compute the Authorization header value to pass in requests. The value `${token}` is used to reference the token obtained from authentication, e.g.: `Bearer ${token}`.
	AuthHeaderExpr *string `default:"Bearer \\${token}" json:"authHeaderExpr"`
	// How often the OAuth token should be refreshed.
	TokenTimeoutSecs *float64 `default:"3600" json:"tokenTimeoutSecs"`
	// Additional parameters to send in the OAuth login request. @{product} will combine the secret with these parameters, and will send the URL-encoded result in a POST request to the endpoint specified in the 'Login URL'. We'll automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthParams []OauthParamSplunkSearch `json:"oauthParams,omitempty"`
	// Additional headers to send in the OAuth login request. @{product} will automatically add the content-type header 'application/x-www-form-urlencoded' when sending this request.
	OauthHeaders []OauthHeaderSplunkSearch `json:"oauthHeaders,omitempty"`
	Status       *TFStatus                 `json:"status,omitempty"`
}

func (i InputSplunkSearch) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunkSearch) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunkSearch) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunkSearch) GetType() *TypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunkSearch) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunkSearch) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunkSearch) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunkSearch) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunkSearch) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunkSearch) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunkSearch) GetConnections() []ConnectionSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunkSearch) GetPq() *PqSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunkSearch) GetSearchHead() *string {
	if o == nil {
		return nil
	}
	return o.SearchHead
}

func (o *InputSplunkSearch) GetSearch() string {
	if o == nil {
		return ""
	}
	return o.Search
}

func (o *InputSplunkSearch) GetEarliest() *string {
	if o == nil {
		return nil
	}
	return o.Earliest
}

func (o *InputSplunkSearch) GetLatest() *string {
	if o == nil {
		return nil
	}
	return o.Latest
}

func (o *InputSplunkSearch) GetCronSchedule() *string {
	if o == nil {
		return nil
	}
	return o.CronSchedule
}

func (o *InputSplunkSearch) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputSplunkSearch) GetOutputMode() *OutputMode {
	if o == nil {
		return nil
	}
	return o.OutputMode
}

func (o *InputSplunkSearch) GetEndpointParams() []EndpointParam {
	if o == nil {
		return nil
	}
	return o.EndpointParams
}

func (o *InputSplunkSearch) GetEndpointHeaders() []EndpointHeader {
	if o == nil {
		return nil
	}
	return o.EndpointHeaders
}

func (o *InputSplunkSearch) GetLogLevel() *LogLevelSplunkSearch {
	if o == nil {
		return nil
	}
	return o.LogLevel
}

func (o *InputSplunkSearch) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputSplunkSearch) GetUseRoundRobinDNS() *bool {
	if o == nil {
		return nil
	}
	return o.UseRoundRobinDNS
}

func (o *InputSplunkSearch) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputSplunkSearch) GetEncoding() *string {
	if o == nil {
		return nil
	}
	return o.Encoding
}

func (o *InputSplunkSearch) GetKeepAliveTime() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTime
}

func (o *InputSplunkSearch) GetJobTimeout() *string {
	if o == nil {
		return nil
	}
	return o.JobTimeout
}

func (o *InputSplunkSearch) GetMaxMissedKeepAlives() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxMissedKeepAlives
}

func (o *InputSplunkSearch) GetTTL() *string {
	if o == nil {
		return nil
	}
	return o.TTL
}

func (o *InputSplunkSearch) GetMetadata() []MetadatumSplunkSearch {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunkSearch) GetRetryRules() *RetryRulesSplunkSearch {
	if o == nil {
		return nil
	}
	return o.RetryRules
}

func (o *InputSplunkSearch) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunkSearch) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunkSearch) GetAuthType() *AuthenticationTypeSplunkSearch {
	if o == nil {
		return nil
	}
	return o.AuthType
}

func (o *InputSplunkSearch) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunkSearch) GetUsername() *string {
	if o == nil {
		return nil
	}
	return o.Username
}

func (o *InputSplunkSearch) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *InputSplunkSearch) GetToken() *string {
	if o == nil {
		return nil
	}
	return o.Token
}

func (o *InputSplunkSearch) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

func (o *InputSplunkSearch) GetTextSecret() *string {
	if o == nil {
		return nil
	}
	return o.TextSecret
}

func (o *InputSplunkSearch) GetLoginURL() *string {
	if o == nil {
		return nil
	}
	return o.LoginURL
}

func (o *InputSplunkSearch) GetSecretParamName() *string {
	if o == nil {
		return nil
	}
	return o.SecretParamName
}

func (o *InputSplunkSearch) GetSecret() *string {
	if o == nil {
		return nil
	}
	return o.Secret
}

func (o *InputSplunkSearch) GetTokenAttributeName() *string {
	if o == nil {
		return nil
	}
	return o.TokenAttributeName
}

func (o *InputSplunkSearch) GetAuthHeaderExpr() *string {
	if o == nil {
		return nil
	}
	return o.AuthHeaderExpr
}

func (o *InputSplunkSearch) GetTokenTimeoutSecs() *float64 {
	if o == nil {
		return nil
	}
	return o.TokenTimeoutSecs
}

func (o *InputSplunkSearch) GetOauthParams() []OauthParamSplunkSearch {
	if o == nil {
		return nil
	}
	return o.OauthParams
}

func (o *InputSplunkSearch) GetOauthHeaders() []OauthHeaderSplunkSearch {
	if o == nil {
		return nil
	}
	return o.OauthHeaders
}

func (o *InputSplunkSearch) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeSplunk string

const (
	InputTypeSplunkSplunk InputTypeSplunk = "splunk"
)

func (e InputTypeSplunk) ToPointer() *InputTypeSplunk {
	return &e
}
func (e *InputTypeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		*e = InputTypeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeSplunk: %v", v)
	}
}

type ConnectionSplunk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionSplunk) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeSplunk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeSplunk string

const (
	PqModeSplunkSmart  PqModeSplunk = "smart"
	PqModeSplunkAlways PqModeSplunk = "always"
)

func (e PqModeSplunk) ToPointer() *PqModeSplunk {
	return &e
}
func (e *PqModeSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeSplunk: %v", v)
	}
}

// PqCompressionSplunk - Codec to use to compress the persisted data
type PqCompressionSplunk string

const (
	PqCompressionSplunkNone PqCompressionSplunk = "none"
	PqCompressionSplunkGzip PqCompressionSplunk = "gzip"
)

func (e PqCompressionSplunk) ToPointer() *PqCompressionSplunk {
	return &e
}
func (e *PqCompressionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionSplunk: %v", v)
	}
}

type PqSplunk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeSplunk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionSplunk `default:"none" json:"compress"`
}

func (p PqSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqSplunk) GetMode() *PqModeSplunk {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqSplunk) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqSplunk) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqSplunk) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqSplunk) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqSplunk) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqSplunk) GetCompress() *PqCompressionSplunk {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputMinimumTLSVersionSplunk - Minimum TLS version to accept from connections
type InputMinimumTLSVersionSplunk string

const (
	InputMinimumTLSVersionSplunkTlSv1  InputMinimumTLSVersionSplunk = "TLSv1"
	InputMinimumTLSVersionSplunkTlSv11 InputMinimumTLSVersionSplunk = "TLSv1.1"
	InputMinimumTLSVersionSplunkTlSv12 InputMinimumTLSVersionSplunk = "TLSv1.2"
	InputMinimumTLSVersionSplunkTlSv13 InputMinimumTLSVersionSplunk = "TLSv1.3"
)

func (e InputMinimumTLSVersionSplunk) ToPointer() *InputMinimumTLSVersionSplunk {
	return &e
}
func (e *InputMinimumTLSVersionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionSplunk: %v", v)
	}
}

// InputMaximumTLSVersionSplunk - Maximum TLS version to accept from connections
type InputMaximumTLSVersionSplunk string

const (
	InputMaximumTLSVersionSplunkTlSv1  InputMaximumTLSVersionSplunk = "TLSv1"
	InputMaximumTLSVersionSplunkTlSv11 InputMaximumTLSVersionSplunk = "TLSv1.1"
	InputMaximumTLSVersionSplunkTlSv12 InputMaximumTLSVersionSplunk = "TLSv1.2"
	InputMaximumTLSVersionSplunkTlSv13 InputMaximumTLSVersionSplunk = "TLSv1.3"
)

func (e InputMaximumTLSVersionSplunk) ToPointer() *InputMaximumTLSVersionSplunk {
	return &e
}
func (e *InputMaximumTLSVersionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionSplunk: %v", v)
	}
}

type TLSSettingsServerSideSplunk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *InputMinimumTLSVersionSplunk `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *InputMaximumTLSVersionSplunk `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideSplunk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideSplunk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideSplunk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideSplunk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideSplunk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideSplunk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideSplunk) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideSplunk) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideSplunk) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideSplunk) GetMinVersion() *InputMinimumTLSVersionSplunk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideSplunk) GetMaxVersion() *InputMaximumTLSVersionSplunk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumSplunk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumSplunk) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumSplunk) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokenSplunk struct {
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
}

func (o *AuthTokenSplunk) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokenSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

// InputMaxS2SVersion - The highest S2S protocol version to advertise during handshake
type InputMaxS2SVersion string

const (
	InputMaxS2SVersionV3 InputMaxS2SVersion = "v3"
	InputMaxS2SVersionV4 InputMaxS2SVersion = "v4"
)

func (e InputMaxS2SVersion) ToPointer() *InputMaxS2SVersion {
	return &e
}
func (e *InputMaxS2SVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v3":
		fallthrough
	case "v4":
		*e = InputMaxS2SVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaxS2SVersion: %v", v)
	}
}

// InputCompressionSplunk - Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
type InputCompressionSplunk string

const (
	InputCompressionSplunkDisabled InputCompressionSplunk = "disabled"
	InputCompressionSplunkAuto     InputCompressionSplunk = "auto"
	InputCompressionSplunkAlways   InputCompressionSplunk = "always"
)

func (e InputCompressionSplunk) ToPointer() *InputCompressionSplunk {
	return &e
}
func (e *InputCompressionSplunk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "disabled":
		fallthrough
	case "auto":
		fallthrough
	case "always":
		*e = InputCompressionSplunk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCompressionSplunk: %v", v)
	}
}

type InputSplunk struct {
	// Unique ID for this input
	ID       *string          `json:"id,omitempty"`
	Type     *InputTypeSplunk `json:"type,omitempty"`
	Disabled *bool            `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionSplunk `json:"connections,omitempty"`
	Pq          *PqSplunk          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64                      `json:"port"`
	TLS  *TLSSettingsServerSideSplunk `json:"tls,omitempty"`
	// Regex matching IP addresses that are allowed to establish a connection
	IPWhitelistRegex *string `default:"/.*/" json:"ipWhitelistRegex"`
	// Maximum number of active connections allowed per Worker Process. Use 0 for unlimited.
	MaxActiveCxn *float64 `default:"1000" json:"maxActiveCxn"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. After this time, the connection will be closed. Leave at 0 for no inactive socket monitoring.
	SocketIdleTimeout *float64 `default:"0" json:"socketIdleTimeout"`
	// How long the server will wait after initiating a closure for a client to close its end of the connection. If the client doesn't close the connection within this time, the server will forcefully terminate the socket to prevent resource leaks and ensure efficient connection cleanup and system stability. Leave at 0 for no inactive socket monitoring.
	SocketEndingMaxWait *float64 `default:"30" json:"socketEndingMaxWait"`
	// The maximum duration a socket can remain open, even if active. This helps manage resources and mitigate issues caused by TCP pinning. Set to 0 to disable.
	SocketMaxLifespan *float64 `default:"0" json:"socketMaxLifespan"`
	// Enable if the connection is proxied by a device that supports proxy protocol v1 or v2
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Fields to add to events from this input
	Metadata []MetadatumSplunk `json:"metadata,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64 `default:"10000" json:"staleChannelFlushMs"`
	// Shared secrets to be provided by any Splunk forwarder. If empty, unauthorized access is permitted.
	AuthTokens []AuthTokenSplunk `json:"authTokens,omitempty"`
	// The highest S2S protocol version to advertise during handshake
	MaxS2Sversion *InputMaxS2SVersion `default:"v3" json:"maxS2Sversion"`
	Description   *string             `json:"description,omitempty"`
	// Event Breakers will determine events' time zone from UF-provided metadata, when TZ can't be inferred from the raw event
	UseFwdTimezone *bool `default:"true" json:"useFwdTimezone"`
	// Drop Splunk control fields such as `crcSalt` and `_savedPort`. If disabled, control fields are stored in the internal field `__ctrlFields`.
	DropControlFields *bool `default:"true" json:"dropControlFields"`
	// Extract and process Splunk-generated metrics as Cribl metrics
	ExtractMetrics *bool `default:"false" json:"extractMetrics"`
	// Controls whether to support reading compressed data from a forwarder. Select 'Automatic' to match the forwarder's configuration, or 'Disabled' to reject compressed connections.
	Compress *InputCompressionSplunk `default:"disabled" json:"compress"`
	Status   *TFStatus               `json:"status,omitempty"`
}

func (i InputSplunk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputSplunk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputSplunk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputSplunk) GetType() *InputTypeSplunk {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputSplunk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputSplunk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputSplunk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputSplunk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputSplunk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputSplunk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputSplunk) GetConnections() []ConnectionSplunk {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputSplunk) GetPq() *PqSplunk {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputSplunk) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputSplunk) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputSplunk) GetTLS() *TLSSettingsServerSideSplunk {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputSplunk) GetIPWhitelistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPWhitelistRegex
}

func (o *InputSplunk) GetMaxActiveCxn() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveCxn
}

func (o *InputSplunk) GetSocketIdleTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketIdleTimeout
}

func (o *InputSplunk) GetSocketEndingMaxWait() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketEndingMaxWait
}

func (o *InputSplunk) GetSocketMaxLifespan() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketMaxLifespan
}

func (o *InputSplunk) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputSplunk) GetMetadata() []MetadatumSplunk {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputSplunk) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputSplunk) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputSplunk) GetAuthTokens() []AuthTokenSplunk {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputSplunk) GetMaxS2Sversion() *InputMaxS2SVersion {
	if o == nil {
		return nil
	}
	return o.MaxS2Sversion
}

func (o *InputSplunk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputSplunk) GetUseFwdTimezone() *bool {
	if o == nil {
		return nil
	}
	return o.UseFwdTimezone
}

func (o *InputSplunk) GetDropControlFields() *bool {
	if o == nil {
		return nil
	}
	return o.DropControlFields
}

func (o *InputSplunk) GetExtractMetrics() *bool {
	if o == nil {
		return nil
	}
	return o.ExtractMetrics
}

func (o *InputSplunk) GetCompress() *InputCompressionSplunk {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputSplunk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeHTTP string

const (
	InputTypeHTTPHTTP InputTypeHTTP = "http"
)

func (e InputTypeHTTP) ToPointer() *InputTypeHTTP {
	return &e
}
func (e *InputTypeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "http":
		*e = InputTypeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeHTTP: %v", v)
	}
}

type ConnectionHTTP struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionHTTP) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeHTTP - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeHTTP string

const (
	PqModeHTTPSmart  PqModeHTTP = "smart"
	PqModeHTTPAlways PqModeHTTP = "always"
)

func (e PqModeHTTP) ToPointer() *PqModeHTTP {
	return &e
}
func (e *PqModeHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeHTTP: %v", v)
	}
}

// PqCompressionHTTP - Codec to use to compress the persisted data
type PqCompressionHTTP string

const (
	PqCompressionHTTPNone PqCompressionHTTP = "none"
	PqCompressionHTTPGzip PqCompressionHTTP = "gzip"
)

func (e PqCompressionHTTP) ToPointer() *PqCompressionHTTP {
	return &e
}
func (e *PqCompressionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionHTTP: %v", v)
	}
}

type PqHTTP struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeHTTP `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionHTTP `default:"none" json:"compress"`
}

func (p PqHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqHTTP) GetMode() *PqModeHTTP {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqHTTP) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqHTTP) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqHTTP) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqHTTP) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqHTTP) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqHTTP) GetCompress() *PqCompressionHTTP {
	if o == nil {
		return nil
	}
	return o.Compress
}

// MinimumTLSVersionHTTP - Minimum TLS version to accept from connections
type MinimumTLSVersionHTTP string

const (
	MinimumTLSVersionHTTPTlSv1  MinimumTLSVersionHTTP = "TLSv1"
	MinimumTLSVersionHTTPTlSv11 MinimumTLSVersionHTTP = "TLSv1.1"
	MinimumTLSVersionHTTPTlSv12 MinimumTLSVersionHTTP = "TLSv1.2"
	MinimumTLSVersionHTTPTlSv13 MinimumTLSVersionHTTP = "TLSv1.3"
)

func (e MinimumTLSVersionHTTP) ToPointer() *MinimumTLSVersionHTTP {
	return &e
}
func (e *MinimumTLSVersionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MinimumTLSVersionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MinimumTLSVersionHTTP: %v", v)
	}
}

// MaximumTLSVersionHTTP - Maximum TLS version to accept from connections
type MaximumTLSVersionHTTP string

const (
	MaximumTLSVersionHTTPTlSv1  MaximumTLSVersionHTTP = "TLSv1"
	MaximumTLSVersionHTTPTlSv11 MaximumTLSVersionHTTP = "TLSv1.1"
	MaximumTLSVersionHTTPTlSv12 MaximumTLSVersionHTTP = "TLSv1.2"
	MaximumTLSVersionHTTPTlSv13 MaximumTLSVersionHTTP = "TLSv1.3"
)

func (e MaximumTLSVersionHTTP) ToPointer() *MaximumTLSVersionHTTP {
	return &e
}
func (e *MaximumTLSVersionHTTP) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = MaximumTLSVersionHTTP(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MaximumTLSVersionHTTP: %v", v)
	}
}

type TLSSettingsServerSideHTTP struct {
	Disabled *bool `default:"true" json:"disabled"`
	// The name of the predefined certificate
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on server containing the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Passphrase to use to decrypt private key
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on server containing certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Path on server containing CA certificates to use. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Require clients to present their certificates. Used to perform client authentication using SSL certs.
	RequestCert        *bool `default:"false" json:"requestCert"`
	RejectUnauthorized any   `json:"rejectUnauthorized,omitempty"`
	CommonNameRegex    any   `json:"commonNameRegex,omitempty"`
	// Minimum TLS version to accept from connections
	MinVersion *MinimumTLSVersionHTTP `json:"minVersion,omitempty"`
	// Maximum TLS version to accept from connections
	MaxVersion *MaximumTLSVersionHTTP `json:"maxVersion,omitempty"`
}

func (t TLSSettingsServerSideHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *TLSSettingsServerSideHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *TLSSettingsServerSideHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *TLSSettingsServerSideHTTP) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *TLSSettingsServerSideHTTP) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *TLSSettingsServerSideHTTP) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *TLSSettingsServerSideHTTP) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *TLSSettingsServerSideHTTP) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *TLSSettingsServerSideHTTP) GetRequestCert() *bool {
	if o == nil {
		return nil
	}
	return o.RequestCert
}

func (o *TLSSettingsServerSideHTTP) GetRejectUnauthorized() any {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *TLSSettingsServerSideHTTP) GetCommonNameRegex() any {
	if o == nil {
		return nil
	}
	return o.CommonNameRegex
}

func (o *TLSSettingsServerSideHTTP) GetMinVersion() *MinimumTLSVersionHTTP {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *TLSSettingsServerSideHTTP) GetMaxVersion() *MaximumTLSVersionHTTP {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputMetadatumHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputMetadatumHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtMetadatumHTTP struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *AuthTokensExtMetadatumHTTP) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *AuthTokensExtMetadatumHTTP) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type AuthTokensExtHTTP struct {
	// Shared secret to be provided by any client (Authorization: <token>).
	Token       string  `json:"token"`
	Description *string `json:"description,omitempty"`
	// Fields to add to events referencing this token
	Metadata []AuthTokensExtMetadatumHTTP `json:"metadata,omitempty"`
}

func (o *AuthTokensExtHTTP) GetToken() string {
	if o == nil {
		return ""
	}
	return o.Token
}

func (o *AuthTokensExtHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *AuthTokensExtHTTP) GetMetadata() []AuthTokensExtMetadatumHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

type InputHTTP struct {
	// Unique ID for this input
	ID       *string        `json:"id,omitempty"`
	Type     *InputTypeHTTP `json:"type,omitempty"`
	Disabled *bool          `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionHTTP `json:"connections,omitempty"`
	Pq          *PqHTTP          `json:"pq,omitempty"`
	// Address to bind on. Defaults to 0.0.0.0 (all addresses).
	Host *string `default:"0.0.0.0" json:"host"`
	// Port to listen on
	Port float64 `json:"port"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokens []string                   `json:"authTokens,omitempty"`
	TLS        *TLSSettingsServerSideHTTP `json:"tls,omitempty"`
	// Maximum number of active requests per Worker Process. Use 0 for unlimited.
	MaxActiveReq *float64 `default:"256" json:"maxActiveReq"`
	// Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited).
	MaxRequestsPerSocket *int64 `default:"0" json:"maxRequestsPerSocket"`
	// Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address
	EnableProxyHeader *bool `default:"false" json:"enableProxyHeader"`
	// Add request headers to events, in the __headers field
	CaptureHeaders *bool `default:"false" json:"captureHeaders"`
	// How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc.
	ActivityLogSampleRate *float64 `default:"100" json:"activityLogSampleRate"`
	// How long to wait for an incoming request to complete before aborting it. Use 0 to disable.
	RequestTimeout *float64 `default:"0" json:"requestTimeout"`
	// How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0.
	SocketTimeout *float64 `default:"0" json:"socketTimeout"`
	// After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.).
	KeepAliveTimeout *float64 `default:"5" json:"keepAliveTimeout"`
	// Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy
	EnableHealthCheck *bool `default:"false" json:"enableHealthCheck"`
	// Messages from matched IP addresses will be processed, unless also matched by the denylist
	IPAllowlistRegex *string `default:"/.*/" json:"ipAllowlistRegex"`
	// Messages from matched IP addresses will be ignored. This takes precedence over the allowlist.
	IPDenylistRegex *string `default:"/^\\$/" json:"ipDenylistRegex"`
	// Absolute path on which to listen for the Cribl HTTP API requests. At the moment, only _bulk (default /cribl/_bulk) is available. Use empty string to disable.
	CriblAPI *string `default:"/cribl" json:"criblAPI"`
	// Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable.
	ElasticAPI *string `default:"/elastic" json:"elasticAPI"`
	// Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable.
	SplunkHecAPI  *string `default:"/services/collector" json:"splunkHecAPI"`
	SplunkHecAcks *bool   `default:"false" json:"splunkHecAcks"`
	// Fields to add to events from this input
	Metadata []InputMetadatumHTTP `json:"metadata,omitempty"`
	// Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted.
	AuthTokensExt []AuthTokensExtHTTP `json:"authTokensExt,omitempty"`
	Description   *string             `json:"description,omitempty"`
	Status        *TFStatus           `json:"status,omitempty"`
}

func (i InputHTTP) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputHTTP) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputHTTP) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputHTTP) GetType() *InputTypeHTTP {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputHTTP) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputHTTP) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputHTTP) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputHTTP) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputHTTP) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputHTTP) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputHTTP) GetConnections() []ConnectionHTTP {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputHTTP) GetPq() *PqHTTP {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputHTTP) GetHost() *string {
	if o == nil {
		return nil
	}
	return o.Host
}

func (o *InputHTTP) GetPort() float64 {
	if o == nil {
		return 0.0
	}
	return o.Port
}

func (o *InputHTTP) GetAuthTokens() []string {
	if o == nil {
		return nil
	}
	return o.AuthTokens
}

func (o *InputHTTP) GetTLS() *TLSSettingsServerSideHTTP {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputHTTP) GetMaxActiveReq() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxActiveReq
}

func (o *InputHTTP) GetMaxRequestsPerSocket() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxRequestsPerSocket
}

func (o *InputHTTP) GetEnableProxyHeader() *bool {
	if o == nil {
		return nil
	}
	return o.EnableProxyHeader
}

func (o *InputHTTP) GetCaptureHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.CaptureHeaders
}

func (o *InputHTTP) GetActivityLogSampleRate() *float64 {
	if o == nil {
		return nil
	}
	return o.ActivityLogSampleRate
}

func (o *InputHTTP) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputHTTP) GetSocketTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SocketTimeout
}

func (o *InputHTTP) GetKeepAliveTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.KeepAliveTimeout
}

func (o *InputHTTP) GetEnableHealthCheck() *bool {
	if o == nil {
		return nil
	}
	return o.EnableHealthCheck
}

func (o *InputHTTP) GetIPAllowlistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPAllowlistRegex
}

func (o *InputHTTP) GetIPDenylistRegex() *string {
	if o == nil {
		return nil
	}
	return o.IPDenylistRegex
}

func (o *InputHTTP) GetCriblAPI() *string {
	if o == nil {
		return nil
	}
	return o.CriblAPI
}

func (o *InputHTTP) GetElasticAPI() *string {
	if o == nil {
		return nil
	}
	return o.ElasticAPI
}

func (o *InputHTTP) GetSplunkHecAPI() *string {
	if o == nil {
		return nil
	}
	return o.SplunkHecAPI
}

func (o *InputHTTP) GetSplunkHecAcks() *bool {
	if o == nil {
		return nil
	}
	return o.SplunkHecAcks
}

func (o *InputHTTP) GetMetadata() []InputMetadatumHTTP {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputHTTP) GetAuthTokensExt() []AuthTokensExtHTTP {
	if o == nil {
		return nil
	}
	return o.AuthTokensExt
}

func (o *InputHTTP) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputHTTP) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeMsk string

const (
	InputTypeMskMsk InputTypeMsk = "msk"
)

func (e InputTypeMsk) ToPointer() *InputTypeMsk {
	return &e
}
func (e *InputTypeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "msk":
		*e = InputTypeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeMsk: %v", v)
	}
}

type ConnectionMsk struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionMsk) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeMsk - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeMsk string

const (
	PqModeMskSmart  PqModeMsk = "smart"
	PqModeMskAlways PqModeMsk = "always"
)

func (e PqModeMsk) ToPointer() *PqModeMsk {
	return &e
}
func (e *PqModeMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeMsk: %v", v)
	}
}

// PqCompressionMsk - Codec to use to compress the persisted data
type PqCompressionMsk string

const (
	PqCompressionMskNone PqCompressionMsk = "none"
	PqCompressionMskGzip PqCompressionMsk = "gzip"
)

func (e PqCompressionMsk) ToPointer() *PqCompressionMsk {
	return &e
}
func (e *PqCompressionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionMsk: %v", v)
	}
}

type PqMsk struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeMsk `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionMsk `default:"none" json:"compress"`
}

func (p PqMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqMsk) GetMode() *PqModeMsk {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqMsk) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqMsk) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqMsk) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqMsk) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqMsk) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqMsk) GetCompress() *PqCompressionMsk {
	if o == nil {
		return nil
	}
	return o.Compress
}

type MetadatumMsk struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumMsk) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumMsk) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputAuthMsk - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthMsk struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAuthMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAuthMsk) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputKafkaSchemaRegistryMinimumTLSVersionMsk - Minimum TLS version to use when connecting
type InputKafkaSchemaRegistryMinimumTLSVersionMsk string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionMskTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionMsk = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionMsk) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionMsk {
	return &e
}
func (e *InputKafkaSchemaRegistryMinimumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMinimumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMinimumTLSVersionMsk: %v", v)
	}
}

// InputKafkaSchemaRegistryMaximumTLSVersionMsk - Maximum TLS version to use when connecting
type InputKafkaSchemaRegistryMaximumTLSVersionMsk string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionMskTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionMsk = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionMsk) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionMsk {
	return &e
}
func (e *InputKafkaSchemaRegistryMaximumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMaximumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMaximumTLSVersionMsk: %v", v)
	}
}

type InputKafkaSchemaRegistryTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideMsk) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationMsk struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthMsk                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideMsk `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetAuth() *InputAuthMsk {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *InputKafkaSchemaRegistryAuthenticationMsk) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideMsk {
	if o == nil {
		return nil
	}
	return o.TLS
}

// InputAuthenticationMethodMsk - AWS authentication method. Choose Auto to use IAM roles.
type InputAuthenticationMethodMsk string

const (
	InputAuthenticationMethodMskAuto   InputAuthenticationMethodMsk = "auto"
	InputAuthenticationMethodMskManual InputAuthenticationMethodMsk = "manual"
	InputAuthenticationMethodMskSecret InputAuthenticationMethodMsk = "secret"
)

func (e InputAuthenticationMethodMsk) ToPointer() *InputAuthenticationMethodMsk {
	return &e
}
func (e *InputAuthenticationMethodMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "auto":
		fallthrough
	case "manual":
		fallthrough
	case "secret":
		*e = InputAuthenticationMethodMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAuthenticationMethodMsk: %v", v)
	}
}

// InputSignatureVersionMsk - Signature version to use for signing MSK cluster requests
type InputSignatureVersionMsk string

const (
	InputSignatureVersionMskV2 InputSignatureVersionMsk = "v2"
	InputSignatureVersionMskV4 InputSignatureVersionMsk = "v4"
)

func (e InputSignatureVersionMsk) ToPointer() *InputSignatureVersionMsk {
	return &e
}
func (e *InputSignatureVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = InputSignatureVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSignatureVersionMsk: %v", v)
	}
}

// InputMinimumTLSVersionMsk - Minimum TLS version to use when connecting
type InputMinimumTLSVersionMsk string

const (
	InputMinimumTLSVersionMskTlSv1  InputMinimumTLSVersionMsk = "TLSv1"
	InputMinimumTLSVersionMskTlSv11 InputMinimumTLSVersionMsk = "TLSv1.1"
	InputMinimumTLSVersionMskTlSv12 InputMinimumTLSVersionMsk = "TLSv1.2"
	InputMinimumTLSVersionMskTlSv13 InputMinimumTLSVersionMsk = "TLSv1.3"
)

func (e InputMinimumTLSVersionMsk) ToPointer() *InputMinimumTLSVersionMsk {
	return &e
}
func (e *InputMinimumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionMsk: %v", v)
	}
}

// InputMaximumTLSVersionMsk - Maximum TLS version to use when connecting
type InputMaximumTLSVersionMsk string

const (
	InputMaximumTLSVersionMskTlSv1  InputMaximumTLSVersionMsk = "TLSv1"
	InputMaximumTLSVersionMskTlSv11 InputMaximumTLSVersionMsk = "TLSv1.1"
	InputMaximumTLSVersionMskTlSv12 InputMaximumTLSVersionMsk = "TLSv1.2"
	InputMaximumTLSVersionMskTlSv13 InputMaximumTLSVersionMsk = "TLSv1.3"
)

func (e InputMaximumTLSVersionMsk) ToPointer() *InputMaximumTLSVersionMsk {
	return &e
}
func (e *InputMaximumTLSVersionMsk) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionMsk(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionMsk: %v", v)
	}
}

type InputTLSSettingsClientSideMsk struct {
	Disabled *bool `default:"false" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputMinimumTLSVersionMsk `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputMaximumTLSVersionMsk `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTLSSettingsClientSideMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTLSSettingsClientSideMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputTLSSettingsClientSideMsk) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputTLSSettingsClientSideMsk) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputTLSSettingsClientSideMsk) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputTLSSettingsClientSideMsk) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputTLSSettingsClientSideMsk) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputTLSSettingsClientSideMsk) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputTLSSettingsClientSideMsk) GetMinVersion() *InputMinimumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputTLSSettingsClientSideMsk) GetMaxVersion() *InputMaximumTLSVersionMsk {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputMsk struct {
	// Unique ID for this input
	ID       *string       `json:"id,omitempty"`
	Type     *InputTypeMsk `json:"type,omitempty"`
	Disabled *bool         `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionMsk `json:"connections,omitempty"`
	Pq          *PqMsk          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `default:"true" json:"fromBeginning"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// Fields to add to events from this input
	Metadata            []MetadatumMsk                             `json:"metadata,omitempty"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationMsk `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *InputAuthenticationMethodMsk `default:"auto" json:"awsAuthenticationMethod"`
	AwsSecretKey            *string                       `json:"awsSecretKey,omitempty"`
	// Region where the MSK cluster is located
	Region string `json:"region"`
	// MSK cluster service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to MSK cluster-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Signature version to use for signing MSK cluster requests
	SignatureVersion *InputSignatureVersionMsk `default:"v4" json:"signatureVersion"`
	// Reuse connections between requests, which can improve performance
	ReuseConnections *bool `default:"true" json:"reuseConnections"`
	// Reject certificates that cannot be verified against a valid CA, such as self-signed certificates
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Use Assume Role credentials to access MSK
	EnableAssumeRole *bool `default:"false" json:"enableAssumeRole"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours).
	DurationSeconds *float64                       `default:"3600" json:"durationSeconds"`
	TLS             *InputTLSSettingsClientSideMsk `json:"tls,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	Description     *string  `json:"description,omitempty"`
	AwsAPIKey       *string  `json:"awsApiKey,omitempty"`
	// Select or create a stored secret that references your access key and secret key
	AwsSecret *string   `json:"awsSecret,omitempty"`
	Status    *TFStatus `json:"status,omitempty"`
}

func (i InputMsk) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputMsk) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputMsk) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputMsk) GetType() *InputTypeMsk {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputMsk) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputMsk) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputMsk) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputMsk) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputMsk) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputMsk) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputMsk) GetConnections() []ConnectionMsk {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputMsk) GetPq() *PqMsk {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputMsk) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputMsk) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputMsk) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputMsk) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputMsk) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputMsk) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputMsk) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputMsk) GetMetadata() []MetadatumMsk {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputMsk) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationMsk {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputMsk) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputMsk) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputMsk) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputMsk) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputMsk) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputMsk) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputMsk) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputMsk) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputMsk) GetAwsAuthenticationMethod() *InputAuthenticationMethodMsk {
	if o == nil {
		return nil
	}
	return o.AwsAuthenticationMethod
}

func (o *InputMsk) GetAwsSecretKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecretKey
}

func (o *InputMsk) GetRegion() string {
	if o == nil {
		return ""
	}
	return o.Region
}

func (o *InputMsk) GetEndpoint() *string {
	if o == nil {
		return nil
	}
	return o.Endpoint
}

func (o *InputMsk) GetSignatureVersion() *InputSignatureVersionMsk {
	if o == nil {
		return nil
	}
	return o.SignatureVersion
}

func (o *InputMsk) GetReuseConnections() *bool {
	if o == nil {
		return nil
	}
	return o.ReuseConnections
}

func (o *InputMsk) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputMsk) GetEnableAssumeRole() *bool {
	if o == nil {
		return nil
	}
	return o.EnableAssumeRole
}

func (o *InputMsk) GetAssumeRoleArn() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleArn
}

func (o *InputMsk) GetAssumeRoleExternalID() *string {
	if o == nil {
		return nil
	}
	return o.AssumeRoleExternalID
}

func (o *InputMsk) GetDurationSeconds() *float64 {
	if o == nil {
		return nil
	}
	return o.DurationSeconds
}

func (o *InputMsk) GetTLS() *InputTLSSettingsClientSideMsk {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputMsk) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputMsk) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputMsk) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputMsk) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputMsk) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputMsk) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputMsk) GetAwsAPIKey() *string {
	if o == nil {
		return nil
	}
	return o.AwsAPIKey
}

func (o *InputMsk) GetAwsSecret() *string {
	if o == nil {
		return nil
	}
	return o.AwsSecret
}

func (o *InputMsk) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeKafka string

const (
	InputTypeKafkaKafka InputTypeKafka = "kafka"
)

func (e InputTypeKafka) ToPointer() *InputTypeKafka {
	return &e
}
func (e *InputTypeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = InputTypeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeKafka: %v", v)
	}
}

type ConnectionKafka struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionKafka) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// PqModeKafka - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type PqModeKafka string

const (
	PqModeKafkaSmart  PqModeKafka = "smart"
	PqModeKafkaAlways PqModeKafka = "always"
)

func (e PqModeKafka) ToPointer() *PqModeKafka {
	return &e
}
func (e *PqModeKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = PqModeKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqModeKafka: %v", v)
	}
}

// PqCompressionKafka - Codec to use to compress the persisted data
type PqCompressionKafka string

const (
	PqCompressionKafkaNone PqCompressionKafka = "none"
	PqCompressionKafkaGzip PqCompressionKafka = "gzip"
)

func (e PqCompressionKafka) ToPointer() *PqCompressionKafka {
	return &e
}
func (e *PqCompressionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = PqCompressionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for PqCompressionKafka: %v", v)
	}
}

type PqKafka struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *PqModeKafka `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *PqCompressionKafka `default:"none" json:"compress"`
}

func (p PqKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqKafka) GetMode() *PqModeKafka {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqKafka) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqKafka) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqKafka) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqKafka) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqKafka) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqKafka) GetCompress() *PqCompressionKafka {
	if o == nil {
		return nil
	}
	return o.Compress
}

// InputAuthKafka - Credentials to use when authenticating with the schema registry using basic HTTP authentication
type InputAuthKafka struct {
	// Enable authentication
	Disabled *bool `default:"true" json:"disabled"`
	// Select or create a secret that references your credentials
	CredentialsSecret *string `json:"credentialsSecret,omitempty"`
}

func (i InputAuthKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAuthKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAuthKafka) GetCredentialsSecret() *string {
	if o == nil {
		return nil
	}
	return o.CredentialsSecret
}

// InputKafkaSchemaRegistryMinimumTLSVersionKafka - Minimum TLS version to use when connecting
type InputKafkaSchemaRegistryMinimumTLSVersionKafka string

const (
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv1  InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv11 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.1"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv12 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.2"
	InputKafkaSchemaRegistryMinimumTLSVersionKafkaTlSv13 InputKafkaSchemaRegistryMinimumTLSVersionKafka = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMinimumTLSVersionKafka) ToPointer() *InputKafkaSchemaRegistryMinimumTLSVersionKafka {
	return &e
}
func (e *InputKafkaSchemaRegistryMinimumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMinimumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMinimumTLSVersionKafka: %v", v)
	}
}

// InputKafkaSchemaRegistryMaximumTLSVersionKafka - Maximum TLS version to use when connecting
type InputKafkaSchemaRegistryMaximumTLSVersionKafka string

const (
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv1  InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv11 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.1"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv12 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.2"
	InputKafkaSchemaRegistryMaximumTLSVersionKafkaTlSv13 InputKafkaSchemaRegistryMaximumTLSVersionKafka = "TLSv1.3"
)

func (e InputKafkaSchemaRegistryMaximumTLSVersionKafka) ToPointer() *InputKafkaSchemaRegistryMaximumTLSVersionKafka {
	return &e
}
func (e *InputKafkaSchemaRegistryMaximumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaSchemaRegistryMaximumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaSchemaRegistryMaximumTLSVersionKafka: %v", v)
	}
}

type InputKafkaSchemaRegistryTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaSchemaRegistryMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaSchemaRegistryMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (i InputKafkaSchemaRegistryTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMinVersion() *InputKafkaSchemaRegistryMinimumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputKafkaSchemaRegistryTLSSettingsClientSideKafka) GetMaxVersion() *InputKafkaSchemaRegistryMaximumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type InputKafkaSchemaRegistryAuthenticationKafka struct {
	// Enable Schema Registry
	Disabled *bool `default:"true" json:"disabled"`
	// URL for accessing the Confluent Schema Registry. Example: http://localhost:8081. To connect over TLS, use https instead of http.
	SchemaRegistryURL *string `default:"http://localhost:8081" json:"schemaRegistryURL"`
	// Maximum time to wait for a Schema Registry connection to complete successfully
	ConnectionTimeout *float64 `default:"30000" json:"connectionTimeout"`
	// Maximum time to wait for the Schema Registry to respond to a request
	RequestTimeout *float64 `default:"30000" json:"requestTimeout"`
	// Maximum number of times to try fetching schemas from the Schema Registry
	MaxRetries *float64 `default:"1" json:"maxRetries"`
	// Credentials to use when authenticating with the schema registry using basic HTTP authentication
	Auth *InputAuthKafka                                     `json:"auth,omitempty"`
	TLS  *InputKafkaSchemaRegistryTLSSettingsClientSideKafka `json:"tls,omitempty"`
}

func (i InputKafkaSchemaRegistryAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafkaSchemaRegistryAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetSchemaRegistryURL() *string {
	if o == nil {
		return nil
	}
	return o.SchemaRegistryURL
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetAuth() *InputAuthKafka {
	if o == nil {
		return nil
	}
	return o.Auth
}

func (o *InputKafkaSchemaRegistryAuthenticationKafka) GetTLS() *InputKafkaSchemaRegistryTLSSettingsClientSideKafka {
	if o == nil {
		return nil
	}
	return o.TLS
}

// InputSASLMechanismKafka - SASL authentication mechanism to use.
type InputSASLMechanismKafka string

const (
	InputSASLMechanismKafkaPlain       InputSASLMechanismKafka = "plain"
	InputSASLMechanismKafkaScramSha256 InputSASLMechanismKafka = "scram-sha-256"
	InputSASLMechanismKafkaScramSha512 InputSASLMechanismKafka = "scram-sha-512"
	InputSASLMechanismKafkaKerberos    InputSASLMechanismKafka = "kerberos"
)

func (e InputSASLMechanismKafka) ToPointer() *InputSASLMechanismKafka {
	return &e
}
func (e *InputSASLMechanismKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = InputSASLMechanismKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputSASLMechanismKafka: %v", v)
	}
}

// InputAuthenticationKafka - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputAuthenticationKafka struct {
	// Enable Authentication
	Disabled *bool `default:"true" json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *InputSASLMechanismKafka `default:"plain" json:"mechanism"`
}

func (i InputAuthenticationKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputAuthenticationKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputAuthenticationKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputAuthenticationKafka) GetMechanism() *InputSASLMechanismKafka {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

// InputMinimumTLSVersionKafka - Minimum TLS version to use when connecting
type InputMinimumTLSVersionKafka string

const (
	InputMinimumTLSVersionKafkaTlSv1  InputMinimumTLSVersionKafka = "TLSv1"
	InputMinimumTLSVersionKafkaTlSv11 InputMinimumTLSVersionKafka = "TLSv1.1"
	InputMinimumTLSVersionKafkaTlSv12 InputMinimumTLSVersionKafka = "TLSv1.2"
	InputMinimumTLSVersionKafkaTlSv13 InputMinimumTLSVersionKafka = "TLSv1.3"
)

func (e InputMinimumTLSVersionKafka) ToPointer() *InputMinimumTLSVersionKafka {
	return &e
}
func (e *InputMinimumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMinimumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMinimumTLSVersionKafka: %v", v)
	}
}

// InputMaximumTLSVersionKafka - Maximum TLS version to use when connecting
type InputMaximumTLSVersionKafka string

const (
	InputMaximumTLSVersionKafkaTlSv1  InputMaximumTLSVersionKafka = "TLSv1"
	InputMaximumTLSVersionKafkaTlSv11 InputMaximumTLSVersionKafka = "TLSv1.1"
	InputMaximumTLSVersionKafkaTlSv12 InputMaximumTLSVersionKafka = "TLSv1.2"
	InputMaximumTLSVersionKafkaTlSv13 InputMaximumTLSVersionKafka = "TLSv1.3"
)

func (e InputMaximumTLSVersionKafka) ToPointer() *InputMaximumTLSVersionKafka {
	return &e
}
func (e *InputMaximumTLSVersionKafka) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputMaximumTLSVersionKafka(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputMaximumTLSVersionKafka: %v", v)
	}
}

type InputTLSSettingsClientSideKafka struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another
	//                     trusted CA (e.g., the system's CA). Defaults to Yes. Overrides the toggle from Advanced Settings, when also present.
	RejectUnauthorized *bool `default:"true" json:"rejectUnauthorized"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputMinimumTLSVersionKafka `json:"minVersion,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputMaximumTLSVersionKafka `json:"maxVersion,omitempty"`
}

func (i InputTLSSettingsClientSideKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputTLSSettingsClientSideKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputTLSSettingsClientSideKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputTLSSettingsClientSideKafka) GetRejectUnauthorized() *bool {
	if o == nil {
		return nil
	}
	return o.RejectUnauthorized
}

func (o *InputTLSSettingsClientSideKafka) GetServername() *string {
	if o == nil {
		return nil
	}
	return o.Servername
}

func (o *InputTLSSettingsClientSideKafka) GetCertificateName() *string {
	if o == nil {
		return nil
	}
	return o.CertificateName
}

func (o *InputTLSSettingsClientSideKafka) GetCaPath() *string {
	if o == nil {
		return nil
	}
	return o.CaPath
}

func (o *InputTLSSettingsClientSideKafka) GetPrivKeyPath() *string {
	if o == nil {
		return nil
	}
	return o.PrivKeyPath
}

func (o *InputTLSSettingsClientSideKafka) GetCertPath() *string {
	if o == nil {
		return nil
	}
	return o.CertPath
}

func (o *InputTLSSettingsClientSideKafka) GetPassphrase() *string {
	if o == nil {
		return nil
	}
	return o.Passphrase
}

func (o *InputTLSSettingsClientSideKafka) GetMinVersion() *InputMinimumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MinVersion
}

func (o *InputTLSSettingsClientSideKafka) GetMaxVersion() *InputMaximumTLSVersionKafka {
	if o == nil {
		return nil
	}
	return o.MaxVersion
}

type MetadatumKafka struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *MetadatumKafka) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *MetadatumKafka) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputKafka struct {
	// Unique ID for this input
	ID       *string         `json:"id,omitempty"`
	Type     *InputTypeKafka `json:"type,omitempty"`
	Disabled *bool           `default:"false" json:"disabled"`
	// Pipeline to process data from this Source before sending it through the Routes
	Pipeline *string `json:"pipeline,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionKafka `json:"connections,omitempty"`
	Pq          *PqKafka          `json:"pq,omitempty"`
	// Enter each Kafka bootstrap server you want to use. Specify the hostname and port (such as mykafkabroker:9092) or just the hostname (in which case @{product} will assign port 9092).
	Brokers []string `json:"brokers"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string `json:"topics,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `default:"Cribl" json:"groupId"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning       *bool                                        `default:"true" json:"fromBeginning"`
	KafkaSchemaRegistry *InputKafkaSchemaRegistryAuthenticationKafka `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *float64 `default:"10000" json:"connectionTimeout"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *float64 `default:"60000" json:"requestTimeout"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data
	MaxRetries *float64 `default:"5" json:"maxRetries"`
	// The maximum wait time for a retry, in milliseconds. Default (and minimum) is 30,000 ms (30 seconds); maximum is 180,000 ms (180 seconds).
	MaxBackOff *float64 `default:"30000" json:"maxBackOff"`
	// Initial value used to calculate the retry, in milliseconds. Maximum is 600,000 ms (10 minutes).
	InitialBackoff *float64 `default:"300" json:"initialBackoff"`
	// Set the backoff multiplier (2-20) to control the retry frequency for failed messages. For faster retries, use a lower multiplier. For slower retries with more delay between attempts, use a higher multiplier. The multiplier is used in an exponential backoff formula; see the Kafka [documentation](https://kafka.js.org/docs/retry-detailed) for details.
	BackoffRate *float64 `default:"2" json:"backoffRate"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *float64 `default:"10000" json:"authenticationTimeout"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *float64 `default:"10000" json:"reauthenticationThreshold"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputAuthenticationKafka        `json:"sasl,omitempty"`
	TLS  *InputTLSSettingsClientSideKafka `json:"tls,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *float64 `default:"30000" json:"sessionTimeout"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *float64 `default:"60000" json:"rebalanceTimeout"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *float64 `default:"3000" json:"heartbeatInterval"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *float64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *float64 `json:"autoCommitThreshold,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *float64 `default:"1048576" json:"maxBytesPerPartition"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *float64 `default:"10485760" json:"maxBytes"`
	// Maximum number of network errors before the consumer recreates a socket.
	MaxSocketErrors *float64 `default:"0" json:"maxSocketErrors"`
	// Fields to add to events from this input
	Metadata    []MetadatumKafka `json:"metadata,omitempty"`
	Description *string          `json:"description,omitempty"`
	Status      *TFStatus        `json:"status,omitempty"`
}

func (i InputKafka) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputKafka) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputKafka) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

func (o *InputKafka) GetType() *InputTypeKafka {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputKafka) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputKafka) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputKafka) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputKafka) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputKafka) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputKafka) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputKafka) GetConnections() []ConnectionKafka {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputKafka) GetPq() *PqKafka {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputKafka) GetBrokers() []string {
	if o == nil {
		return []string{}
	}
	return o.Brokers
}

func (o *InputKafka) GetTopics() []string {
	if o == nil {
		return nil
	}
	return o.Topics
}

func (o *InputKafka) GetGroupID() *string {
	if o == nil {
		return nil
	}
	return o.GroupID
}

func (o *InputKafka) GetFromBeginning() *bool {
	if o == nil {
		return nil
	}
	return o.FromBeginning
}

func (o *InputKafka) GetKafkaSchemaRegistry() *InputKafkaSchemaRegistryAuthenticationKafka {
	if o == nil {
		return nil
	}
	return o.KafkaSchemaRegistry
}

func (o *InputKafka) GetConnectionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.ConnectionTimeout
}

func (o *InputKafka) GetRequestTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RequestTimeout
}

func (o *InputKafka) GetMaxRetries() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxRetries
}

func (o *InputKafka) GetMaxBackOff() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBackOff
}

func (o *InputKafka) GetInitialBackoff() *float64 {
	if o == nil {
		return nil
	}
	return o.InitialBackoff
}

func (o *InputKafka) GetBackoffRate() *float64 {
	if o == nil {
		return nil
	}
	return o.BackoffRate
}

func (o *InputKafka) GetAuthenticationTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.AuthenticationTimeout
}

func (o *InputKafka) GetReauthenticationThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.ReauthenticationThreshold
}

func (o *InputKafka) GetSasl() *InputAuthenticationKafka {
	if o == nil {
		return nil
	}
	return o.Sasl
}

func (o *InputKafka) GetTLS() *InputTLSSettingsClientSideKafka {
	if o == nil {
		return nil
	}
	return o.TLS
}

func (o *InputKafka) GetSessionTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.SessionTimeout
}

func (o *InputKafka) GetRebalanceTimeout() *float64 {
	if o == nil {
		return nil
	}
	return o.RebalanceTimeout
}

func (o *InputKafka) GetHeartbeatInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.HeartbeatInterval
}

func (o *InputKafka) GetAutoCommitInterval() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitInterval
}

func (o *InputKafka) GetAutoCommitThreshold() *float64 {
	if o == nil {
		return nil
	}
	return o.AutoCommitThreshold
}

func (o *InputKafka) GetMaxBytesPerPartition() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytesPerPartition
}

func (o *InputKafka) GetMaxBytes() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBytes
}

func (o *InputKafka) GetMaxSocketErrors() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxSocketErrors
}

func (o *InputKafka) GetMetadata() []MetadatumKafka {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputKafka) GetDescription() *string {
	if o == nil {
		return nil
	}
	return o.Description
}

func (o *InputKafka) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputTypeCollection string

const (
	InputTypeCollectionCollection InputTypeCollection = "collection"
)

func (e InputTypeCollection) ToPointer() *InputTypeCollection {
	return &e
}
func (e *InputTypeCollection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputTypeCollection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputTypeCollection: %v", v)
	}
}

type ConnectionCollection struct {
	Pipeline *string `json:"pipeline,omitempty"`
	Output   string  `json:"output"`
}

func (o *ConnectionCollection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *ConnectionCollection) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

// ModeCollection - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type ModeCollection string

const (
	ModeCollectionSmart  ModeCollection = "smart"
	ModeCollectionAlways ModeCollection = "always"
)

func (e ModeCollection) ToPointer() *ModeCollection {
	return &e
}
func (e *ModeCollection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = ModeCollection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ModeCollection: %v", v)
	}
}

// CompressionCollection - Codec to use to compress the persisted data
type CompressionCollection string

const (
	CompressionCollectionNone CompressionCollection = "none"
	CompressionCollectionGzip CompressionCollection = "gzip"
)

func (e CompressionCollection) ToPointer() *CompressionCollection {
	return &e
}
func (e *CompressionCollection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = CompressionCollection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CompressionCollection: %v", v)
	}
}

type PqCollection struct {
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *ModeCollection `default:"always" json:"mode"`
	// The maximum number of events to hold in memory before writing the events to disk
	MaxBufferSize *float64 `default:"1000" json:"maxBufferSize"`
	// The number of events to send downstream before committing that Stream has read them
	CommitFrequency *float64 `default:"42" json:"commitFrequency"`
	// The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc.
	MaxFileSize *string `default:"1 MB" json:"maxFileSize"`
	// The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `default:"5GB" json:"maxSize"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>
	Path *string `default:"\\$CRIBL_HOME/state/queues" json:"path"`
	// Codec to use to compress the persisted data
	Compress *CompressionCollection `default:"none" json:"compress"`
}

func (p PqCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *PqCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *PqCollection) GetMode() *ModeCollection {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *PqCollection) GetMaxBufferSize() *float64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *PqCollection) GetCommitFrequency() *float64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *PqCollection) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *PqCollection) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *PqCollection) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

func (o *PqCollection) GetCompress() *CompressionCollection {
	if o == nil {
		return nil
	}
	return o.Compress
}

type InputPreprocessCollection struct {
	Disabled *bool `default:"true" json:"disabled"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Arguments to be added to the custom command
	Args []string `json:"args,omitempty"`
}

func (i InputPreprocessCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputPreprocessCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *InputPreprocessCollection) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputPreprocessCollection) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputPreprocessCollection) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

type InputMetadatumCollection struct {
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputMetadatumCollection) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputMetadatumCollection) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

type InputCollection struct {
	// Unique ID for this input
	ID       string               `json:"id"`
	Type     *InputTypeCollection `default:"collection" json:"type"`
	Disabled *bool                `default:"false" json:"disabled"`
	// Pipeline to process results
	Pipeline *string `json:"pipeline,omitempty"`
	// Send events to normal routing and event processing. Disable to select a specific Pipeline/Destination combination.
	SendToRoutes *bool `default:"true" json:"sendToRoutes"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers).
	PqEnabled *bool `default:"false" json:"pqEnabled"`
	// Tags for filtering and grouping in @{product}
	Streamtags []string `json:"streamtags,omitempty"`
	// Direct connections to Destinations, and optionally via a Pipeline or a Pack
	Connections []ConnectionCollection `json:"connections,omitempty"`
	Pq          *PqCollection          `json:"pq,omitempty"`
	// A list of event-breaking rulesets that will be applied, in order, to the input data stream
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// How long (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel before flushing the data stream out, as is, to the Pipelines
	StaleChannelFlushMs *float64                   `default:"10000" json:"staleChannelFlushMs"`
	Preprocess          *InputPreprocessCollection `json:"preprocess,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Accepts values with multiple-byte units, such as KB, MB, and GB. (Example: 42 MB) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string `default:"0" json:"throttleRatePerSec"`
	// Fields to add to events from this input
	Metadata []InputMetadatumCollection `json:"metadata,omitempty"`
	// Destination to send results to
	Output *string   `json:"output,omitempty"`
	Status *TFStatus `json:"status,omitempty"`
}

func (i InputCollection) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(i, "", false)
}

func (i *InputCollection) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &i, "", false, true); err != nil {
		return err
	}
	return nil
}

func (o *InputCollection) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCollection) GetType() *InputTypeCollection {
	if o == nil {
		return nil
	}
	return o.Type
}

func (o *InputCollection) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCollection) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCollection) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCollection) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCollection) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCollection) GetConnections() []ConnectionCollection {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCollection) GetPq() *PqCollection {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCollection) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCollection) GetStaleChannelFlushMs() *float64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCollection) GetPreprocess() *InputPreprocessCollection {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCollection) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *InputCollection) GetMetadata() []InputMetadatumCollection {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCollection) GetOutput() *string {
	if o == nil {
		return nil
	}
	return o.Output
}

func (o *InputCollection) GetStatus() *TFStatus {
	if o == nil {
		return nil
	}
	return o.Status
}

type InputType string

const (
	InputTypeInputCollection           InputType = "InputCollection"
	InputTypeInputKafka                InputType = "InputKafka"
	InputTypeInputMsk                  InputType = "InputMsk"
	InputTypeInputHTTP                 InputType = "InputHttp"
	InputTypeInputSplunk               InputType = "InputSplunk"
	InputTypeInputSplunkSearch         InputType = "InputSplunkSearch"
	InputTypeInputSplunkHec            InputType = "InputSplunkHec"
	InputTypeInputAzureBlob            InputType = "InputAzureBlob"
	InputTypeInputElastic              InputType = "InputElastic"
	InputTypeInputConfluentCloud       InputType = "InputConfluentCloud"
	InputTypeInputGrafana              InputType = "InputGrafana"
	InputTypeInputLoki                 InputType = "InputLoki"
	InputTypeInputPrometheusRw         InputType = "InputPrometheusRw"
	InputTypeInputPrometheus           InputType = "InputPrometheus"
	InputTypeInputEdgePrometheus       InputType = "InputEdgePrometheus"
	InputTypeInputOffice365Mgmt        InputType = "InputOffice365Mgmt"
	InputTypeInputOffice365Service     InputType = "InputOffice365Service"
	InputTypeInputOffice365MsgTrace    InputType = "InputOffice365MsgTrace"
	InputTypeInputEventhub             InputType = "InputEventhub"
	InputTypeInputExec                 InputType = "InputExec"
	InputTypeInputFirehose             InputType = "InputFirehose"
	InputTypeInputGooglePubsub         InputType = "InputGooglePubsub"
	InputTypeInputCribl                InputType = "InputCribl"
	InputTypeInputCriblTCP             InputType = "InputCriblTcp"
	InputTypeInputCriblHTTP            InputType = "InputCriblHttp"
	InputTypeInputTcpjson              InputType = "InputTcpjson"
	InputTypeInputSystemMetrics        InputType = "InputSystemMetrics"
	InputTypeInputSystemState          InputType = "InputSystemState"
	InputTypeInputKubeMetrics          InputType = "InputKubeMetrics"
	InputTypeInputKubeLogs             InputType = "InputKubeLogs"
	InputTypeInputKubeEvents           InputType = "InputKubeEvents"
	InputTypeInputWindowsMetrics       InputType = "InputWindowsMetrics"
	InputTypeInputCrowdstrike          InputType = "InputCrowdstrike"
	InputTypeInputDatadogAgent         InputType = "InputDatadogAgent"
	InputTypeInputDatagen              InputType = "InputDatagen"
	InputTypeInputHTTPRaw              InputType = "InputHttpRaw"
	InputTypeInputKinesis              InputType = "InputKinesis"
	InputTypeInputCriblmetrics         InputType = "InputCriblmetrics"
	InputTypeInputMetrics              InputType = "InputMetrics"
	InputTypeInputS3                   InputType = "InputS3"
	InputTypeInputS3Inventory          InputType = "InputS3Inventory"
	InputTypeInputSnmp                 InputType = "InputSnmp"
	InputTypeInputOpenTelemetry        InputType = "InputOpenTelemetry"
	InputTypeInputModelDrivenTelemetry InputType = "InputModelDrivenTelemetry"
	InputTypeInputSqs                  InputType = "InputSqs"
	InputTypeInputSyslog               InputType = "InputSyslog"
	InputTypeInputFile                 InputType = "InputFile"
	InputTypeInputTCP                  InputType = "InputTcp"
	InputTypeInputAppscope             InputType = "InputAppscope"
	InputTypeInputWef                  InputType = "InputWef"
	InputTypeInputWinEventLogs         InputType = "InputWinEventLogs"
	InputTypeInputRawUDP               InputType = "InputRawUdp"
	InputTypeInputJournalFiles         InputType = "InputJournalFiles"
	InputTypeInputWiz                  InputType = "InputWiz"
	InputTypeInputNetflow              InputType = "InputNetflow"
	InputTypeInputSecurityLake         InputType = "InputSecurityLake"
	InputTypeInputZscalerHec           InputType = "InputZscalerHec"
)

type Input struct {
	InputCollection           *InputCollection           `queryParam:"inline"`
	InputKafka                *InputKafka                `queryParam:"inline"`
	InputMsk                  *InputMsk                  `queryParam:"inline"`
	InputHTTP                 *InputHTTP                 `queryParam:"inline"`
	InputSplunk               *InputSplunk               `queryParam:"inline"`
	InputSplunkSearch         *InputSplunkSearch         `queryParam:"inline"`
	InputSplunkHec            *InputSplunkHec            `queryParam:"inline"`
	InputAzureBlob            *InputAzureBlob            `queryParam:"inline"`
	InputElastic              *InputElastic              `queryParam:"inline"`
	InputConfluentCloud       *InputConfluentCloud       `queryParam:"inline"`
	InputGrafana              *InputGrafana              `queryParam:"inline"`
	InputLoki                 *InputLoki                 `queryParam:"inline"`
	InputPrometheusRw         *InputPrometheusRw         `queryParam:"inline"`
	InputPrometheus           *InputPrometheus           `queryParam:"inline"`
	InputEdgePrometheus       *InputEdgePrometheus       `queryParam:"inline"`
	InputOffice365Mgmt        *InputOffice365Mgmt        `queryParam:"inline"`
	InputOffice365Service     *InputOffice365Service     `queryParam:"inline"`
	InputOffice365MsgTrace    *InputOffice365MsgTrace    `queryParam:"inline"`
	InputEventhub             *InputEventhub             `queryParam:"inline"`
	InputExec                 *InputExec                 `queryParam:"inline"`
	InputFirehose             *InputFirehose             `queryParam:"inline"`
	InputGooglePubsub         *InputGooglePubsub         `queryParam:"inline"`
	InputCribl                *InputCribl                `queryParam:"inline"`
	InputCriblTCP             *InputCriblTCP             `queryParam:"inline"`
	InputCriblHTTP            *InputCriblHTTP            `queryParam:"inline"`
	InputTcpjson              *InputTcpjson              `queryParam:"inline"`
	InputSystemMetrics        *InputSystemMetrics        `queryParam:"inline"`
	InputSystemState          *InputSystemState          `queryParam:"inline"`
	InputKubeMetrics          *InputKubeMetrics          `queryParam:"inline"`
	InputKubeLogs             *InputKubeLogs             `queryParam:"inline"`
	InputKubeEvents           *InputKubeEvents           `queryParam:"inline"`
	InputWindowsMetrics       *InputWindowsMetrics       `queryParam:"inline"`
	InputCrowdstrike          *InputCrowdstrike          `queryParam:"inline"`
	InputDatadogAgent         *InputDatadogAgent         `queryParam:"inline"`
	InputDatagen              *InputDatagen              `queryParam:"inline"`
	InputHTTPRaw              *InputHTTPRaw              `queryParam:"inline"`
	InputKinesis              *InputKinesis              `queryParam:"inline"`
	InputCriblmetrics         *InputCriblmetrics         `queryParam:"inline"`
	InputMetrics              *InputMetrics              `queryParam:"inline"`
	InputS3                   *InputS3                   `queryParam:"inline"`
	InputS3Inventory          *InputS3Inventory          `queryParam:"inline"`
	InputSnmp                 *InputSnmp                 `queryParam:"inline"`
	InputOpenTelemetry        *InputOpenTelemetry        `queryParam:"inline"`
	InputModelDrivenTelemetry *InputModelDrivenTelemetry `queryParam:"inline"`
	InputSqs                  *InputSqs                  `queryParam:"inline"`
	InputSyslog               *InputSyslog               `queryParam:"inline"`
	InputFile                 *InputFile                 `queryParam:"inline"`
	InputTCP                  *InputTCP                  `queryParam:"inline"`
	InputAppscope             *InputAppscope             `queryParam:"inline"`
	InputWef                  *InputWef                  `queryParam:"inline"`
	InputWinEventLogs         *InputWinEventLogs         `queryParam:"inline"`
	InputRawUDP               *InputRawUDP               `queryParam:"inline"`
	InputJournalFiles         *InputJournalFiles         `queryParam:"inline"`
	InputWiz                  *InputWiz                  `queryParam:"inline"`
	InputNetflow              *InputNetflow              `queryParam:"inline"`
	InputSecurityLake         *InputSecurityLake         `queryParam:"inline"`
	InputZscalerHec           *InputZscalerHec           `queryParam:"inline"`

	Type InputType
}

func CreateInputInputCollection(inputCollection InputCollection) Input {
	typ := InputTypeInputCollection

	return Input{
		InputCollection: &inputCollection,
		Type:            typ,
	}
}

func CreateInputInputKafka(inputKafka InputKafka) Input {
	typ := InputTypeInputKafka

	return Input{
		InputKafka: &inputKafka,
		Type:       typ,
	}
}

func CreateInputInputMsk(inputMsk InputMsk) Input {
	typ := InputTypeInputMsk

	return Input{
		InputMsk: &inputMsk,
		Type:     typ,
	}
}

func CreateInputInputHTTP(inputHTTP InputHTTP) Input {
	typ := InputTypeInputHTTP

	return Input{
		InputHTTP: &inputHTTP,
		Type:      typ,
	}
}

func CreateInputInputSplunk(inputSplunk InputSplunk) Input {
	typ := InputTypeInputSplunk

	return Input{
		InputSplunk: &inputSplunk,
		Type:        typ,
	}
}

func CreateInputInputSplunkSearch(inputSplunkSearch InputSplunkSearch) Input {
	typ := InputTypeInputSplunkSearch

	return Input{
		InputSplunkSearch: &inputSplunkSearch,
		Type:              typ,
	}
}

func CreateInputInputSplunkHec(inputSplunkHec InputSplunkHec) Input {
	typ := InputTypeInputSplunkHec

	return Input{
		InputSplunkHec: &inputSplunkHec,
		Type:           typ,
	}
}

func CreateInputInputAzureBlob(inputAzureBlob InputAzureBlob) Input {
	typ := InputTypeInputAzureBlob

	return Input{
		InputAzureBlob: &inputAzureBlob,
		Type:           typ,
	}
}

func CreateInputInputElastic(inputElastic InputElastic) Input {
	typ := InputTypeInputElastic

	return Input{
		InputElastic: &inputElastic,
		Type:         typ,
	}
}

func CreateInputInputConfluentCloud(inputConfluentCloud InputConfluentCloud) Input {
	typ := InputTypeInputConfluentCloud

	return Input{
		InputConfluentCloud: &inputConfluentCloud,
		Type:                typ,
	}
}

func CreateInputInputGrafana(inputGrafana InputGrafana) Input {
	typ := InputTypeInputGrafana

	return Input{
		InputGrafana: &inputGrafana,
		Type:         typ,
	}
}

func CreateInputInputLoki(inputLoki InputLoki) Input {
	typ := InputTypeInputLoki

	return Input{
		InputLoki: &inputLoki,
		Type:      typ,
	}
}

func CreateInputInputPrometheusRw(inputPrometheusRw InputPrometheusRw) Input {
	typ := InputTypeInputPrometheusRw

	return Input{
		InputPrometheusRw: &inputPrometheusRw,
		Type:              typ,
	}
}

func CreateInputInputPrometheus(inputPrometheus InputPrometheus) Input {
	typ := InputTypeInputPrometheus

	return Input{
		InputPrometheus: &inputPrometheus,
		Type:            typ,
	}
}

func CreateInputInputEdgePrometheus(inputEdgePrometheus InputEdgePrometheus) Input {
	typ := InputTypeInputEdgePrometheus

	return Input{
		InputEdgePrometheus: &inputEdgePrometheus,
		Type:                typ,
	}
}

func CreateInputInputOffice365Mgmt(inputOffice365Mgmt InputOffice365Mgmt) Input {
	typ := InputTypeInputOffice365Mgmt

	return Input{
		InputOffice365Mgmt: &inputOffice365Mgmt,
		Type:               typ,
	}
}

func CreateInputInputOffice365Service(inputOffice365Service InputOffice365Service) Input {
	typ := InputTypeInputOffice365Service

	return Input{
		InputOffice365Service: &inputOffice365Service,
		Type:                  typ,
	}
}

func CreateInputInputOffice365MsgTrace(inputOffice365MsgTrace InputOffice365MsgTrace) Input {
	typ := InputTypeInputOffice365MsgTrace

	return Input{
		InputOffice365MsgTrace: &inputOffice365MsgTrace,
		Type:                   typ,
	}
}

func CreateInputInputEventhub(inputEventhub InputEventhub) Input {
	typ := InputTypeInputEventhub

	return Input{
		InputEventhub: &inputEventhub,
		Type:          typ,
	}
}

func CreateInputInputExec(inputExec InputExec) Input {
	typ := InputTypeInputExec

	return Input{
		InputExec: &inputExec,
		Type:      typ,
	}
}

func CreateInputInputFirehose(inputFirehose InputFirehose) Input {
	typ := InputTypeInputFirehose

	return Input{
		InputFirehose: &inputFirehose,
		Type:          typ,
	}
}

func CreateInputInputGooglePubsub(inputGooglePubsub InputGooglePubsub) Input {
	typ := InputTypeInputGooglePubsub

	return Input{
		InputGooglePubsub: &inputGooglePubsub,
		Type:              typ,
	}
}

func CreateInputInputCribl(inputCribl InputCribl) Input {
	typ := InputTypeInputCribl

	return Input{
		InputCribl: &inputCribl,
		Type:       typ,
	}
}

func CreateInputInputCriblTCP(inputCriblTCP InputCriblTCP) Input {
	typ := InputTypeInputCriblTCP

	return Input{
		InputCriblTCP: &inputCriblTCP,
		Type:          typ,
	}
}

func CreateInputInputCriblHTTP(inputCriblHTTP InputCriblHTTP) Input {
	typ := InputTypeInputCriblHTTP

	return Input{
		InputCriblHTTP: &inputCriblHTTP,
		Type:           typ,
	}
}

func CreateInputInputTcpjson(inputTcpjson InputTcpjson) Input {
	typ := InputTypeInputTcpjson

	return Input{
		InputTcpjson: &inputTcpjson,
		Type:         typ,
	}
}

func CreateInputInputSystemMetrics(inputSystemMetrics InputSystemMetrics) Input {
	typ := InputTypeInputSystemMetrics

	return Input{
		InputSystemMetrics: &inputSystemMetrics,
		Type:               typ,
	}
}

func CreateInputInputSystemState(inputSystemState InputSystemState) Input {
	typ := InputTypeInputSystemState

	return Input{
		InputSystemState: &inputSystemState,
		Type:             typ,
	}
}

func CreateInputInputKubeMetrics(inputKubeMetrics InputKubeMetrics) Input {
	typ := InputTypeInputKubeMetrics

	return Input{
		InputKubeMetrics: &inputKubeMetrics,
		Type:             typ,
	}
}

func CreateInputInputKubeLogs(inputKubeLogs InputKubeLogs) Input {
	typ := InputTypeInputKubeLogs

	return Input{
		InputKubeLogs: &inputKubeLogs,
		Type:          typ,
	}
}

func CreateInputInputKubeEvents(inputKubeEvents InputKubeEvents) Input {
	typ := InputTypeInputKubeEvents

	return Input{
		InputKubeEvents: &inputKubeEvents,
		Type:            typ,
	}
}

func CreateInputInputWindowsMetrics(inputWindowsMetrics InputWindowsMetrics) Input {
	typ := InputTypeInputWindowsMetrics

	return Input{
		InputWindowsMetrics: &inputWindowsMetrics,
		Type:                typ,
	}
}

func CreateInputInputCrowdstrike(inputCrowdstrike InputCrowdstrike) Input {
	typ := InputTypeInputCrowdstrike

	return Input{
		InputCrowdstrike: &inputCrowdstrike,
		Type:             typ,
	}
}

func CreateInputInputDatadogAgent(inputDatadogAgent InputDatadogAgent) Input {
	typ := InputTypeInputDatadogAgent

	return Input{
		InputDatadogAgent: &inputDatadogAgent,
		Type:              typ,
	}
}

func CreateInputInputDatagen(inputDatagen InputDatagen) Input {
	typ := InputTypeInputDatagen

	return Input{
		InputDatagen: &inputDatagen,
		Type:         typ,
	}
}

func CreateInputInputHTTPRaw(inputHTTPRaw InputHTTPRaw) Input {
	typ := InputTypeInputHTTPRaw

	return Input{
		InputHTTPRaw: &inputHTTPRaw,
		Type:         typ,
	}
}

func CreateInputInputKinesis(inputKinesis InputKinesis) Input {
	typ := InputTypeInputKinesis

	return Input{
		InputKinesis: &inputKinesis,
		Type:         typ,
	}
}

func CreateInputInputCriblmetrics(inputCriblmetrics InputCriblmetrics) Input {
	typ := InputTypeInputCriblmetrics

	return Input{
		InputCriblmetrics: &inputCriblmetrics,
		Type:              typ,
	}
}

func CreateInputInputMetrics(inputMetrics InputMetrics) Input {
	typ := InputTypeInputMetrics

	return Input{
		InputMetrics: &inputMetrics,
		Type:         typ,
	}
}

func CreateInputInputS3(inputS3 InputS3) Input {
	typ := InputTypeInputS3

	return Input{
		InputS3: &inputS3,
		Type:    typ,
	}
}

func CreateInputInputS3Inventory(inputS3Inventory InputS3Inventory) Input {
	typ := InputTypeInputS3Inventory

	return Input{
		InputS3Inventory: &inputS3Inventory,
		Type:             typ,
	}
}

func CreateInputInputSnmp(inputSnmp InputSnmp) Input {
	typ := InputTypeInputSnmp

	return Input{
		InputSnmp: &inputSnmp,
		Type:      typ,
	}
}

func CreateInputInputOpenTelemetry(inputOpenTelemetry InputOpenTelemetry) Input {
	typ := InputTypeInputOpenTelemetry

	return Input{
		InputOpenTelemetry: &inputOpenTelemetry,
		Type:               typ,
	}
}

func CreateInputInputModelDrivenTelemetry(inputModelDrivenTelemetry InputModelDrivenTelemetry) Input {
	typ := InputTypeInputModelDrivenTelemetry

	return Input{
		InputModelDrivenTelemetry: &inputModelDrivenTelemetry,
		Type:                      typ,
	}
}

func CreateInputInputSqs(inputSqs InputSqs) Input {
	typ := InputTypeInputSqs

	return Input{
		InputSqs: &inputSqs,
		Type:     typ,
	}
}

func CreateInputInputSyslog(inputSyslog InputSyslog) Input {
	typ := InputTypeInputSyslog

	return Input{
		InputSyslog: &inputSyslog,
		Type:        typ,
	}
}

func CreateInputInputFile(inputFile InputFile) Input {
	typ := InputTypeInputFile

	return Input{
		InputFile: &inputFile,
		Type:      typ,
	}
}

func CreateInputInputTCP(inputTCP InputTCP) Input {
	typ := InputTypeInputTCP

	return Input{
		InputTCP: &inputTCP,
		Type:     typ,
	}
}

func CreateInputInputAppscope(inputAppscope InputAppscope) Input {
	typ := InputTypeInputAppscope

	return Input{
		InputAppscope: &inputAppscope,
		Type:          typ,
	}
}

func CreateInputInputWef(inputWef InputWef) Input {
	typ := InputTypeInputWef

	return Input{
		InputWef: &inputWef,
		Type:     typ,
	}
}

func CreateInputInputWinEventLogs(inputWinEventLogs InputWinEventLogs) Input {
	typ := InputTypeInputWinEventLogs

	return Input{
		InputWinEventLogs: &inputWinEventLogs,
		Type:              typ,
	}
}

func CreateInputInputRawUDP(inputRawUDP InputRawUDP) Input {
	typ := InputTypeInputRawUDP

	return Input{
		InputRawUDP: &inputRawUDP,
		Type:        typ,
	}
}

func CreateInputInputJournalFiles(inputJournalFiles InputJournalFiles) Input {
	typ := InputTypeInputJournalFiles

	return Input{
		InputJournalFiles: &inputJournalFiles,
		Type:              typ,
	}
}

func CreateInputInputWiz(inputWiz InputWiz) Input {
	typ := InputTypeInputWiz

	return Input{
		InputWiz: &inputWiz,
		Type:     typ,
	}
}

func CreateInputInputNetflow(inputNetflow InputNetflow) Input {
	typ := InputTypeInputNetflow

	return Input{
		InputNetflow: &inputNetflow,
		Type:         typ,
	}
}

func CreateInputInputSecurityLake(inputSecurityLake InputSecurityLake) Input {
	typ := InputTypeInputSecurityLake

	return Input{
		InputSecurityLake: &inputSecurityLake,
		Type:              typ,
	}
}

func CreateInputInputZscalerHec(inputZscalerHec InputZscalerHec) Input {
	typ := InputTypeInputZscalerHec

	return Input{
		InputZscalerHec: &inputZscalerHec,
		Type:            typ,
	}
}

func (u *Input) UnmarshalJSON(data []byte) error {

	var inputCribl InputCribl = InputCribl{}
	if err := utils.UnmarshalJSON(data, &inputCribl, "", true, true); err == nil {
		u.InputCribl = &inputCribl
		u.Type = InputTypeInputCribl
		return nil
	}

	var inputDatagen InputDatagen = InputDatagen{}
	if err := utils.UnmarshalJSON(data, &inputDatagen, "", true, true); err == nil {
		u.InputDatagen = &inputDatagen
		u.Type = InputTypeInputDatagen
		return nil
	}

	var inputKubeEvents InputKubeEvents = InputKubeEvents{}
	if err := utils.UnmarshalJSON(data, &inputKubeEvents, "", true, true); err == nil {
		u.InputKubeEvents = &inputKubeEvents
		u.Type = InputTypeInputKubeEvents
		return nil
	}

	var inputCriblmetrics InputCriblmetrics = InputCriblmetrics{}
	if err := utils.UnmarshalJSON(data, &inputCriblmetrics, "", true, true); err == nil {
		u.InputCriblmetrics = &inputCriblmetrics
		u.Type = InputTypeInputCriblmetrics
		return nil
	}

	var inputKubeMetrics InputKubeMetrics = InputKubeMetrics{}
	if err := utils.UnmarshalJSON(data, &inputKubeMetrics, "", true, true); err == nil {
		u.InputKubeMetrics = &inputKubeMetrics
		u.Type = InputTypeInputKubeMetrics
		return nil
	}

	var inputSystemState InputSystemState = InputSystemState{}
	if err := utils.UnmarshalJSON(data, &inputSystemState, "", true, true); err == nil {
		u.InputSystemState = &inputSystemState
		u.Type = InputTypeInputSystemState
		return nil
	}

	var inputCollection InputCollection = InputCollection{}
	if err := utils.UnmarshalJSON(data, &inputCollection, "", true, true); err == nil {
		u.InputCollection = &inputCollection
		u.Type = InputTypeInputCollection
		return nil
	}

	var inputModelDrivenTelemetry InputModelDrivenTelemetry = InputModelDrivenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputModelDrivenTelemetry, "", true, true); err == nil {
		u.InputModelDrivenTelemetry = &inputModelDrivenTelemetry
		u.Type = InputTypeInputModelDrivenTelemetry
		return nil
	}

	var inputWindowsMetrics InputWindowsMetrics = InputWindowsMetrics{}
	if err := utils.UnmarshalJSON(data, &inputWindowsMetrics, "", true, true); err == nil {
		u.InputWindowsMetrics = &inputWindowsMetrics
		u.Type = InputTypeInputWindowsMetrics
		return nil
	}

	var inputSystemMetrics InputSystemMetrics = InputSystemMetrics{}
	if err := utils.UnmarshalJSON(data, &inputSystemMetrics, "", true, true); err == nil {
		u.InputSystemMetrics = &inputSystemMetrics
		u.Type = InputTypeInputSystemMetrics
		return nil
	}

	var inputJournalFiles InputJournalFiles = InputJournalFiles{}
	if err := utils.UnmarshalJSON(data, &inputJournalFiles, "", true, true); err == nil {
		u.InputJournalFiles = &inputJournalFiles
		u.Type = InputTypeInputJournalFiles
		return nil
	}

	var inputSnmp InputSnmp = InputSnmp{}
	if err := utils.UnmarshalJSON(data, &inputSnmp, "", true, true); err == nil {
		u.InputSnmp = &inputSnmp
		u.Type = InputTypeInputSnmp
		return nil
	}

	var inputWinEventLogs InputWinEventLogs = InputWinEventLogs{}
	if err := utils.UnmarshalJSON(data, &inputWinEventLogs, "", true, true); err == nil {
		u.InputWinEventLogs = &inputWinEventLogs
		u.Type = InputTypeInputWinEventLogs
		return nil
	}

	var inputRawUDP InputRawUDP = InputRawUDP{}
	if err := utils.UnmarshalJSON(data, &inputRawUDP, "", true, true); err == nil {
		u.InputRawUDP = &inputRawUDP
		u.Type = InputTypeInputRawUDP
		return nil
	}

	var inputExec InputExec = InputExec{}
	if err := utils.UnmarshalJSON(data, &inputExec, "", true, true); err == nil {
		u.InputExec = &inputExec
		u.Type = InputTypeInputExec
		return nil
	}

	var inputKubeLogs InputKubeLogs = InputKubeLogs{}
	if err := utils.UnmarshalJSON(data, &inputKubeLogs, "", true, true); err == nil {
		u.InputKubeLogs = &inputKubeLogs
		u.Type = InputTypeInputKubeLogs
		return nil
	}

	var inputMetrics InputMetrics = InputMetrics{}
	if err := utils.UnmarshalJSON(data, &inputMetrics, "", true, true); err == nil {
		u.InputMetrics = &inputMetrics
		u.Type = InputTypeInputMetrics
		return nil
	}

	var inputCriblTCP InputCriblTCP = InputCriblTCP{}
	if err := utils.UnmarshalJSON(data, &inputCriblTCP, "", true, true); err == nil {
		u.InputCriblTCP = &inputCriblTCP
		u.Type = InputTypeInputCriblTCP
		return nil
	}

	var inputNetflow InputNetflow = InputNetflow{}
	if err := utils.UnmarshalJSON(data, &inputNetflow, "", true, true); err == nil {
		u.InputNetflow = &inputNetflow
		u.Type = InputTypeInputNetflow
		return nil
	}

	var inputGooglePubsub InputGooglePubsub = InputGooglePubsub{}
	if err := utils.UnmarshalJSON(data, &inputGooglePubsub, "", true, true); err == nil {
		u.InputGooglePubsub = &inputGooglePubsub
		u.Type = InputTypeInputGooglePubsub
		return nil
	}

	var inputTcpjson InputTcpjson = InputTcpjson{}
	if err := utils.UnmarshalJSON(data, &inputTcpjson, "", true, true); err == nil {
		u.InputTcpjson = &inputTcpjson
		u.Type = InputTypeInputTcpjson
		return nil
	}

	var inputOffice365Service InputOffice365Service = InputOffice365Service{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Service, "", true, true); err == nil {
		u.InputOffice365Service = &inputOffice365Service
		u.Type = InputTypeInputOffice365Service
		return nil
	}

	var inputWiz InputWiz = InputWiz{}
	if err := utils.UnmarshalJSON(data, &inputWiz, "", true, true); err == nil {
		u.InputWiz = &inputWiz
		u.Type = InputTypeInputWiz
		return nil
	}

	var inputTCP InputTCP = InputTCP{}
	if err := utils.UnmarshalJSON(data, &inputTCP, "", true, true); err == nil {
		u.InputTCP = &inputTCP
		u.Type = InputTypeInputTCP
		return nil
	}

	var inputCriblHTTP InputCriblHTTP = InputCriblHTTP{}
	if err := utils.UnmarshalJSON(data, &inputCriblHTTP, "", true, true); err == nil {
		u.InputCriblHTTP = &inputCriblHTTP
		u.Type = InputTypeInputCriblHTTP
		return nil
	}

	var inputFirehose InputFirehose = InputFirehose{}
	if err := utils.UnmarshalJSON(data, &inputFirehose, "", true, true); err == nil {
		u.InputFirehose = &inputFirehose
		u.Type = InputTypeInputFirehose
		return nil
	}

	var inputOffice365Mgmt InputOffice365Mgmt = InputOffice365Mgmt{}
	if err := utils.UnmarshalJSON(data, &inputOffice365Mgmt, "", true, true); err == nil {
		u.InputOffice365Mgmt = &inputOffice365Mgmt
		u.Type = InputTypeInputOffice365Mgmt
		return nil
	}

	var inputFile InputFile = InputFile{}
	if err := utils.UnmarshalJSON(data, &inputFile, "", true, true); err == nil {
		u.InputFile = &inputFile
		u.Type = InputTypeInputFile
		return nil
	}

	var inputDatadogAgent InputDatadogAgent = InputDatadogAgent{}
	if err := utils.UnmarshalJSON(data, &inputDatadogAgent, "", true, true); err == nil {
		u.InputDatadogAgent = &inputDatadogAgent
		u.Type = InputTypeInputDatadogAgent
		return nil
	}

	var inputSplunk InputSplunk = InputSplunk{}
	if err := utils.UnmarshalJSON(data, &inputSplunk, "", true, true); err == nil {
		u.InputSplunk = &inputSplunk
		u.Type = InputTypeInputSplunk
		return nil
	}

	var inputWef InputWef = InputWef{}
	if err := utils.UnmarshalJSON(data, &inputWef, "", true, true); err == nil {
		u.InputWef = &inputWef
		u.Type = InputTypeInputWef
		return nil
	}

	var inputAppscope InputAppscope = InputAppscope{}
	if err := utils.UnmarshalJSON(data, &inputAppscope, "", true, true); err == nil {
		u.InputAppscope = &inputAppscope
		u.Type = InputTypeInputAppscope
		return nil
	}

	var inputHTTP InputHTTP = InputHTTP{}
	if err := utils.UnmarshalJSON(data, &inputHTTP, "", true, true); err == nil {
		u.InputHTTP = &inputHTTP
		u.Type = InputTypeInputHTTP
		return nil
	}

	var inputAzureBlob InputAzureBlob = InputAzureBlob{}
	if err := utils.UnmarshalJSON(data, &inputAzureBlob, "", true, true); err == nil {
		u.InputAzureBlob = &inputAzureBlob
		u.Type = InputTypeInputAzureBlob
		return nil
	}

	var inputHTTPRaw InputHTTPRaw = InputHTTPRaw{}
	if err := utils.UnmarshalJSON(data, &inputHTTPRaw, "", true, true); err == nil {
		u.InputHTTPRaw = &inputHTTPRaw
		u.Type = InputTypeInputHTTPRaw
		return nil
	}

	var inputZscalerHec InputZscalerHec = InputZscalerHec{}
	if err := utils.UnmarshalJSON(data, &inputZscalerHec, "", true, true); err == nil {
		u.InputZscalerHec = &inputZscalerHec
		u.Type = InputTypeInputZscalerHec
		return nil
	}

	var inputSqs InputSqs = InputSqs{}
	if err := utils.UnmarshalJSON(data, &inputSqs, "", true, true); err == nil {
		u.InputSqs = &inputSqs
		u.Type = InputTypeInputSqs
		return nil
	}

	var inputKinesis InputKinesis = InputKinesis{}
	if err := utils.UnmarshalJSON(data, &inputKinesis, "", true, true); err == nil {
		u.InputKinesis = &inputKinesis
		u.Type = InputTypeInputKinesis
		return nil
	}

	var inputConfluentCloud InputConfluentCloud = InputConfluentCloud{}
	if err := utils.UnmarshalJSON(data, &inputConfluentCloud, "", true, true); err == nil {
		u.InputConfluentCloud = &inputConfluentCloud
		u.Type = InputTypeInputConfluentCloud
		return nil
	}

	var inputEventhub InputEventhub = InputEventhub{}
	if err := utils.UnmarshalJSON(data, &inputEventhub, "", true, true); err == nil {
		u.InputEventhub = &inputEventhub
		u.Type = InputTypeInputEventhub
		return nil
	}

	var inputKafka InputKafka = InputKafka{}
	if err := utils.UnmarshalJSON(data, &inputKafka, "", true, true); err == nil {
		u.InputKafka = &inputKafka
		u.Type = InputTypeInputKafka
		return nil
	}

	var inputElastic InputElastic = InputElastic{}
	if err := utils.UnmarshalJSON(data, &inputElastic, "", true, true); err == nil {
		u.InputElastic = &inputElastic
		u.Type = InputTypeInputElastic
		return nil
	}

	var inputOffice365MsgTrace InputOffice365MsgTrace = InputOffice365MsgTrace{}
	if err := utils.UnmarshalJSON(data, &inputOffice365MsgTrace, "", true, true); err == nil {
		u.InputOffice365MsgTrace = &inputOffice365MsgTrace
		u.Type = InputTypeInputOffice365MsgTrace
		return nil
	}

	var inputSplunkHec InputSplunkHec = InputSplunkHec{}
	if err := utils.UnmarshalJSON(data, &inputSplunkHec, "", true, true); err == nil {
		u.InputSplunkHec = &inputSplunkHec
		u.Type = InputTypeInputSplunkHec
		return nil
	}

	var inputCrowdstrike InputCrowdstrike = InputCrowdstrike{}
	if err := utils.UnmarshalJSON(data, &inputCrowdstrike, "", true, true); err == nil {
		u.InputCrowdstrike = &inputCrowdstrike
		u.Type = InputTypeInputCrowdstrike
		return nil
	}

	var inputLoki InputLoki = InputLoki{}
	if err := utils.UnmarshalJSON(data, &inputLoki, "", true, true); err == nil {
		u.InputLoki = &inputLoki
		u.Type = InputTypeInputLoki
		return nil
	}

	var inputPrometheusRw InputPrometheusRw = InputPrometheusRw{}
	if err := utils.UnmarshalJSON(data, &inputPrometheusRw, "", true, true); err == nil {
		u.InputPrometheusRw = &inputPrometheusRw
		u.Type = InputTypeInputPrometheusRw
		return nil
	}

	var inputSecurityLake InputSecurityLake = InputSecurityLake{}
	if err := utils.UnmarshalJSON(data, &inputSecurityLake, "", true, true); err == nil {
		u.InputSecurityLake = &inputSecurityLake
		u.Type = InputTypeInputSecurityLake
		return nil
	}

	var inputS3 InputS3 = InputS3{}
	if err := utils.UnmarshalJSON(data, &inputS3, "", true, true); err == nil {
		u.InputS3 = &inputS3
		u.Type = InputTypeInputS3
		return nil
	}

	var inputPrometheus InputPrometheus = InputPrometheus{}
	if err := utils.UnmarshalJSON(data, &inputPrometheus, "", true, true); err == nil {
		u.InputPrometheus = &inputPrometheus
		u.Type = InputTypeInputPrometheus
		return nil
	}

	var inputS3Inventory InputS3Inventory = InputS3Inventory{}
	if err := utils.UnmarshalJSON(data, &inputS3Inventory, "", true, true); err == nil {
		u.InputS3Inventory = &inputS3Inventory
		u.Type = InputTypeInputS3Inventory
		return nil
	}

	var inputEdgePrometheus InputEdgePrometheus = InputEdgePrometheus{}
	if err := utils.UnmarshalJSON(data, &inputEdgePrometheus, "", true, true); err == nil {
		u.InputEdgePrometheus = &inputEdgePrometheus
		u.Type = InputTypeInputEdgePrometheus
		return nil
	}

	var inputOpenTelemetry InputOpenTelemetry = InputOpenTelemetry{}
	if err := utils.UnmarshalJSON(data, &inputOpenTelemetry, "", true, true); err == nil {
		u.InputOpenTelemetry = &inputOpenTelemetry
		u.Type = InputTypeInputOpenTelemetry
		return nil
	}

	var inputSplunkSearch InputSplunkSearch = InputSplunkSearch{}
	if err := utils.UnmarshalJSON(data, &inputSplunkSearch, "", true, true); err == nil {
		u.InputSplunkSearch = &inputSplunkSearch
		u.Type = InputTypeInputSplunkSearch
		return nil
	}

	var inputMsk InputMsk = InputMsk{}
	if err := utils.UnmarshalJSON(data, &inputMsk, "", true, true); err == nil {
		u.InputMsk = &inputMsk
		u.Type = InputTypeInputMsk
		return nil
	}

	var inputSyslog InputSyslog = InputSyslog{}
	if err := utils.UnmarshalJSON(data, &inputSyslog, "", true, true); err == nil {
		u.InputSyslog = &inputSyslog
		u.Type = InputTypeInputSyslog
		return nil
	}

	var inputGrafana InputGrafana = InputGrafana{}
	if err := utils.UnmarshalJSON(data, &inputGrafana, "", true, true); err == nil {
		u.InputGrafana = &inputGrafana
		u.Type = InputTypeInputGrafana
		return nil
	}

	return fmt.Errorf("could not unmarshal `%s` into any supported union types for Input", string(data))
}

func (u Input) MarshalJSON() ([]byte, error) {
	if u.InputCollection != nil {
		return utils.MarshalJSON(u.InputCollection, "", true)
	}

	if u.InputKafka != nil {
		return utils.MarshalJSON(u.InputKafka, "", true)
	}

	if u.InputMsk != nil {
		return utils.MarshalJSON(u.InputMsk, "", true)
	}

	if u.InputHTTP != nil {
		return utils.MarshalJSON(u.InputHTTP, "", true)
	}

	if u.InputSplunk != nil {
		return utils.MarshalJSON(u.InputSplunk, "", true)
	}

	if u.InputSplunkSearch != nil {
		return utils.MarshalJSON(u.InputSplunkSearch, "", true)
	}

	if u.InputSplunkHec != nil {
		return utils.MarshalJSON(u.InputSplunkHec, "", true)
	}

	if u.InputAzureBlob != nil {
		return utils.MarshalJSON(u.InputAzureBlob, "", true)
	}

	if u.InputElastic != nil {
		return utils.MarshalJSON(u.InputElastic, "", true)
	}

	if u.InputConfluentCloud != nil {
		return utils.MarshalJSON(u.InputConfluentCloud, "", true)
	}

	if u.InputGrafana != nil {
		return utils.MarshalJSON(u.InputGrafana, "", true)
	}

	if u.InputLoki != nil {
		return utils.MarshalJSON(u.InputLoki, "", true)
	}

	if u.InputPrometheusRw != nil {
		return utils.MarshalJSON(u.InputPrometheusRw, "", true)
	}

	if u.InputPrometheus != nil {
		return utils.MarshalJSON(u.InputPrometheus, "", true)
	}

	if u.InputEdgePrometheus != nil {
		return utils.MarshalJSON(u.InputEdgePrometheus, "", true)
	}

	if u.InputOffice365Mgmt != nil {
		return utils.MarshalJSON(u.InputOffice365Mgmt, "", true)
	}

	if u.InputOffice365Service != nil {
		return utils.MarshalJSON(u.InputOffice365Service, "", true)
	}

	if u.InputOffice365MsgTrace != nil {
		return utils.MarshalJSON(u.InputOffice365MsgTrace, "", true)
	}

	if u.InputEventhub != nil {
		return utils.MarshalJSON(u.InputEventhub, "", true)
	}

	if u.InputExec != nil {
		return utils.MarshalJSON(u.InputExec, "", true)
	}

	if u.InputFirehose != nil {
		return utils.MarshalJSON(u.InputFirehose, "", true)
	}

	if u.InputGooglePubsub != nil {
		return utils.MarshalJSON(u.InputGooglePubsub, "", true)
	}

	if u.InputCribl != nil {
		return utils.MarshalJSON(u.InputCribl, "", true)
	}

	if u.InputCriblTCP != nil {
		return utils.MarshalJSON(u.InputCriblTCP, "", true)
	}

	if u.InputCriblHTTP != nil {
		return utils.MarshalJSON(u.InputCriblHTTP, "", true)
	}

	if u.InputTcpjson != nil {
		return utils.MarshalJSON(u.InputTcpjson, "", true)
	}

	if u.InputSystemMetrics != nil {
		return utils.MarshalJSON(u.InputSystemMetrics, "", true)
	}

	if u.InputSystemState != nil {
		return utils.MarshalJSON(u.InputSystemState, "", true)
	}

	if u.InputKubeMetrics != nil {
		return utils.MarshalJSON(u.InputKubeMetrics, "", true)
	}

	if u.InputKubeLogs != nil {
		return utils.MarshalJSON(u.InputKubeLogs, "", true)
	}

	if u.InputKubeEvents != nil {
		return utils.MarshalJSON(u.InputKubeEvents, "", true)
	}

	if u.InputWindowsMetrics != nil {
		return utils.MarshalJSON(u.InputWindowsMetrics, "", true)
	}

	if u.InputCrowdstrike != nil {
		return utils.MarshalJSON(u.InputCrowdstrike, "", true)
	}

	if u.InputDatadogAgent != nil {
		return utils.MarshalJSON(u.InputDatadogAgent, "", true)
	}

	if u.InputDatagen != nil {
		return utils.MarshalJSON(u.InputDatagen, "", true)
	}

	if u.InputHTTPRaw != nil {
		return utils.MarshalJSON(u.InputHTTPRaw, "", true)
	}

	if u.InputKinesis != nil {
		return utils.MarshalJSON(u.InputKinesis, "", true)
	}

	if u.InputCriblmetrics != nil {
		return utils.MarshalJSON(u.InputCriblmetrics, "", true)
	}

	if u.InputMetrics != nil {
		return utils.MarshalJSON(u.InputMetrics, "", true)
	}

	if u.InputS3 != nil {
		return utils.MarshalJSON(u.InputS3, "", true)
	}

	if u.InputS3Inventory != nil {
		return utils.MarshalJSON(u.InputS3Inventory, "", true)
	}

	if u.InputSnmp != nil {
		return utils.MarshalJSON(u.InputSnmp, "", true)
	}

	if u.InputOpenTelemetry != nil {
		return utils.MarshalJSON(u.InputOpenTelemetry, "", true)
	}

	if u.InputModelDrivenTelemetry != nil {
		return utils.MarshalJSON(u.InputModelDrivenTelemetry, "", true)
	}

	if u.InputSqs != nil {
		return utils.MarshalJSON(u.InputSqs, "", true)
	}

	if u.InputSyslog != nil {
		return utils.MarshalJSON(u.InputSyslog, "", true)
	}

	if u.InputFile != nil {
		return utils.MarshalJSON(u.InputFile, "", true)
	}

	if u.InputTCP != nil {
		return utils.MarshalJSON(u.InputTCP, "", true)
	}

	if u.InputAppscope != nil {
		return utils.MarshalJSON(u.InputAppscope, "", true)
	}

	if u.InputWef != nil {
		return utils.MarshalJSON(u.InputWef, "", true)
	}

	if u.InputWinEventLogs != nil {
		return utils.MarshalJSON(u.InputWinEventLogs, "", true)
	}

	if u.InputRawUDP != nil {
		return utils.MarshalJSON(u.InputRawUDP, "", true)
	}

	if u.InputJournalFiles != nil {
		return utils.MarshalJSON(u.InputJournalFiles, "", true)
	}

	if u.InputWiz != nil {
		return utils.MarshalJSON(u.InputWiz, "", true)
	}

	if u.InputNetflow != nil {
		return utils.MarshalJSON(u.InputNetflow, "", true)
	}

	if u.InputSecurityLake != nil {
		return utils.MarshalJSON(u.InputSecurityLake, "", true)
	}

	if u.InputZscalerHec != nil {
		return utils.MarshalJSON(u.InputZscalerHec, "", true)
	}

	return nil, errors.New("could not marshal union type Input: all fields are null")
}
